{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization and Topic Models\n",
    "* Text Summarization and Information Extraction\n",
    "* Important Concepts\n",
    "* Keyphrase Extractions\n",
    "    1. Collocations\n",
    "    2. Weighted Tag-Based Phrase Extraction\n",
    "* Topic Modeling on Research Papers\n",
    "    1. The Main Objective\n",
    "    2. Data Retrieval\n",
    "    3. Load and View Dataset\n",
    "    4. Basic Text Wrangling\n",
    "* Topic Models with Gensim\n",
    "    1. Text Representation with Feature Engineering\n",
    "    2. Latent Semantic Indexing\n",
    "    3. Implementing LSI Topic Models from Scratch\n",
    "    4. Latent Dirichlet Allocation\n",
    "    5. LDA Models with MALLET\n",
    "    6. LDA Tuning: Finding the Optimal Number of Topics\n",
    "    7. Interpreting Topic Model Results\n",
    "    8. Predicting Topics for New Research Papers\n",
    "* Topic Models with Scikit-Learn\n",
    "    1. Text Representation with Feature Engineering\n",
    "    2. Latent Semantic Indexing\n",
    "    3. Latent Dirichlet Allocation\n",
    "    4. Non-Negative Matrix Factorization\n",
    "    5. Predicting Topics for New Research Papers\n",
    "    6. Visualizing Topic Models\n",
    "* Automated Document Summarization\n",
    "    1. Text Wrangling\n",
    "    2. Text Representation with Feature Engineering\n",
    "    3. Latent Semantic Analysis\n",
    "    4. TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if spacy doesn't run\n",
    "#!pip3 install spacy\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if nltk error\n",
    "#import nltk\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "#!pip3 install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top k singular values and return corresponding U, S, & V matrices\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    u,s,vt = svds(matrix, k=singular_count)\n",
    "    return u,s,vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyphrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ] \n",
      " alice adventures wonderland lewis carroll\n"
     ]
    }
   ],
   "source": [
    "## Collocations\n",
    "from nltk.corpus import gutenberg\n",
    "import text_normalizer as tn\n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "\n",
    "# load corpus\n",
    "alice = gutenberg.sents(fileids='carroll-alice.txt')\n",
    "alice = [' '.join(ts) for ts in alice]\n",
    "norm_alice = list(filter(None,\n",
    "                         tn.normalize_corpus(alice, text_lemmatization=False)))\n",
    "\n",
    "# print and compare first line\n",
    "print(alice[0], '\\n', norm_alice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (2, 3, 4)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_ngrams(sequence, n):\n",
    "    return list(\n",
    "            zip(*(sequence[index:]\n",
    "                  for index in range(n))))\n",
    "\n",
    "# test function\n",
    "compute_ngrams([1,2,3,4], 2) # bi-grams\n",
    "compute_ngrams([1,2,3,4], 3) # tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to flatten corpus into one big string of text\n",
    "def flatten_corpus(corpus):\n",
    "    return ' '.join([document.strip()\n",
    "                    for document in corpus])\n",
    "\n",
    "# get top n-grams for corpus of text\n",
    "def get_top_ngrams(corpus, ngram_val=1, limit=5):\n",
    "    corpus = flatten_corpus(corpus)\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "    \n",
    "    ngrams = compute_ngrams(tokens, ngram_val)\n",
    "    ngrams_freq_dist = nltk.FreqDist(ngrams)\n",
    "    sorted_ngrams_fd = sorted(ngrams_freq_dist.items(),\n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    sorted_ngrams = sorted_ngrams_fd[0:limit]\n",
    "    sorted_ngrams = [(' '.join(text), freq)\n",
    "                     for text, freq in sorted_ngrams]\n",
    "    return sorted_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said alice', 123),\n",
       " ('mock turtle', 56),\n",
       " ('march hare', 31),\n",
       " ('said king', 29),\n",
       " ('thought alice', 26),\n",
       " ('white rabbit', 22),\n",
       " ('said hatter', 22),\n",
       " ('said mock', 20),\n",
       " ('said caterpillar', 18),\n",
       " ('said gryphon', 18)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 bigrams\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=2, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said mock turtle', 20),\n",
       " ('said march hare', 10),\n",
       " ('poor little thing', 6),\n",
       " ('little golden key', 5),\n",
       " ('certainly said alice', 5),\n",
       " ('white kid gloves', 5),\n",
       " ('march hare said', 5),\n",
       " ('mock turtle said', 5),\n",
       " ('know said alice', 4),\n",
       " ('might well say', 4)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 trigrams\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=3, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.collocations.BigramCollocationFinder at 0x7f7ab93cb438>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use NLTK's collocation finders\n",
    "# bigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "\n",
    "finder = BigramCollocationFinder.from_documents([item.split() for item in norm_alice])\n",
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'alice'),\n",
       " ('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'king'),\n",
       " ('thought', 'alice'),\n",
       " ('said', 'hatter'),\n",
       " ('white', 'rabbit'),\n",
       " ('said', 'mock'),\n",
       " ('said', 'caterpillar'),\n",
       " ('said', 'gryphon')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "# raw frequencies\n",
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abide', 'figures'),\n",
       " ('acceptance', 'elegant'),\n",
       " ('accounting', 'tastes'),\n",
       " ('accustomed', 'usurpation'),\n",
       " ('act', 'crawling'),\n",
       " ('adjourn', 'immediate'),\n",
       " ('adoption', 'energetic'),\n",
       " ('affair', 'trusts'),\n",
       " ('agony', 'terror'),\n",
       " ('alarmed', 'proposal')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "\n",
    "finder = TrigramCollocationFinder.from_documents([item.split() for item in norm_alice])\n",
    "\n",
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('said', 'march', 'hare'),\n",
       " ('poor', 'little', 'thing'),\n",
       " ('little', 'golden', 'key'),\n",
       " ('march', 'hare', 'said'),\n",
       " ('mock', 'turtle', 'said'),\n",
       " ('white', 'kid', 'gloves'),\n",
       " ('beau', 'ootiful', 'soo'),\n",
       " ('certainly', 'said', 'alice'),\n",
       " ('might', 'well', 'say')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw frequencies\n",
    "finder.nbest(trigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('apple', 'roast', 'turkey'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherry', 'tart', 'custard'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Weighted Tag-Based Phrase Extraction\n",
    "data = open('elephants.txt', 'r+').readlines()\n",
    "sentences = nltk.sent_tokenize(data[0])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are large mammals of the family Elephantidae and the order Proboscidea.',\n",
       " 'Three species are currently recognised: the African bush elephant (Loxodonta africana), the African forest elephant (L. cyclotis), and the Asian elephant (Elephas maximus).',\n",
       " 'Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first three lines\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are large mammals of the family Elephantidae and the order Proboscidea',\n",
       " 'Three species are currently recognised the African bush elephant Loxodonta africana the African forest elephant L cyclotis and the Asian elephant Elephas maximus',\n",
       " 'Elephants are scattered throughout subSaharan Africa South Asia and Southeast Asia']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_sentences = tn.normalize_corpus(sentences, text_lower_case=False, text_stemming=False,\n",
    "                                     text_lemmatization=False, stopword_removal=False)\n",
    "norm_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def get_chunks(sentences, grammar=r'NP: {<DT>? <JJ>* <NN.*>+}', stopword_list=stopwords):\n",
    "    all_chunks = []\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tagged_sents = [nltk.pos_tag(nltk.word_tokenize(sentence))]\n",
    "        chunks = [chunker.parse(tagged_sent)\n",
    "                     for tagged_sent in tagged_sents]\n",
    "        wtc_sents = [nltk.chunk.tree2conlltags(chunk)\n",
    "                        for chunk in chunks]\n",
    "        flattened_chunks = list(itertools.chain.from_iterable(wtc_sent for wtc_sent in wtc_sents))\n",
    "        valid_chunks_tagged = [(status, [wtc for wtc in chunk])\n",
    "                                    for status, chunk in itertools.groupby(flattened_chunks,\n",
    "                                                      lambda word_pos_chunk: \n",
    "                                                      word_pos_chunk[2] != 'O')]\n",
    "        valid_chunks = [' '.join(word.lower()\n",
    "                                 for word, tag, chunk in wtc_group\n",
    "                                     if word.lower() not in stopword_list)\n",
    "                                        for status, wtc_group in valid_chunks_tagged if status]\n",
    "        all_chunks.append(valid_chunks)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elephants', 'large mammals', 'family elephantidae', 'order proboscidea'],\n",
       " ['species',\n",
       "  'african bush elephant loxodonta',\n",
       "  'african forest elephant l cyclotis',\n",
       "  'asian elephant elephas maximus'],\n",
       " ['elephants', 'subsaharan africa south asia', 'southeast asia'],\n",
       " ['elephantidae',\n",
       "  'family',\n",
       "  'order proboscidea',\n",
       "  'extinct members',\n",
       "  'order',\n",
       "  'deinotheres gomphotheres mammoths',\n",
       "  'mastodons'],\n",
       " ['elephants',\n",
       "  'several distinctive features',\n",
       "  'long trunk',\n",
       "  'proboscis',\n",
       "  'many purposes',\n",
       "  'water',\n",
       "  'grasping objects'],\n",
       " ['incisors', 'tusks', 'weapons', 'tools', 'objects'],\n",
       " ['elephants', 'flaps', 'body temperature'],\n",
       " ['pillarlike legs', 'great weight'],\n",
       " ['african elephants',\n",
       "  'ears',\n",
       "  'backs',\n",
       "  'asian elephants',\n",
       "  'ears',\n",
       "  'convex',\n",
       "  'level backs'],\n",
       " ['elephants', 'different habitats', 'savannahs forests deserts', 'marshes'],\n",
       " ['water'],\n",
       " ['keystone species', 'impact', 'environments'],\n",
       " ['animals',\n",
       "  'distance',\n",
       "  'elephants',\n",
       "  'predators',\n",
       "  'lions tigers hyenas',\n",
       "  'wild dogs',\n",
       "  'young elephants',\n",
       "  'calves'],\n",
       " ['elephants', 'fissionfusion society', 'multiple family groups'],\n",
       " ['females cows',\n",
       "  'family groups',\n",
       "  'female',\n",
       "  'calves',\n",
       "  'several related females'],\n",
       " ['groups', 'individual known', 'matriarch', 'cow'],\n",
       " ['males bulls', 'family groups', 'males'],\n",
       " ['adult',\n",
       "  'family groups',\n",
       "  'mate',\n",
       "  'enter state',\n",
       "  'increased testosterone',\n",
       "  'aggression',\n",
       "  'musth',\n",
       "  'dominance',\n",
       "  'reproductive success'],\n",
       " ['calves', 'centre', 'attention', 'family groups', 'mothers', 'years'],\n",
       " ['elephants', 'years', 'wild'],\n",
       " ['touch sight smell',\n",
       "  'sound elephants',\n",
       "  'infrasound',\n",
       "  'seismic communication',\n",
       "  'long distances'],\n",
       " ['elephant intelligence', 'primates', 'cetaceans'],\n",
       " ['selfawareness', 'dead individuals', 'kind'],\n",
       " ['african elephants',\n",
       "  'international union',\n",
       "  'conservation',\n",
       "  'nature iucn',\n",
       "  'asian elephant'],\n",
       " ['threats', 'populations', 'ivory trade', 'animals', 'ivory tusks'],\n",
       " ['threats', 'elephants', 'habitat destruction', 'conflicts', 'local people'],\n",
       " ['elephants', 'animals', 'asia'],\n",
       " ['past', 'war today', 'display', 'zoos', 'entertainment', 'circuses'],\n",
       " ['elephants', 'art folklore religion literature', 'popular culture']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = get_chunks(norm_sentences)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "def get_tfidf_weighted_keyphrases(sentences, grammar=r'NP: {<DT>? <JJ>* <NN.*>+}', top_n=10):\n",
    "    valid_chunks = get_chunks(sentences, grammar=grammar)\n",
    "    \n",
    "    dictionary = corpora.Dictionary(valid_chunks)\n",
    "    corpus = [dictionary.doc2bow(chunk) for chunk in valid_chunks]\n",
    "    \n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    weighted_phrases = {dictionary.get(idx): value for doc in corpus_tfidf for idx, value in doc}\n",
    "    weighted_phrases = sorted(weighted_phrases.items(),\n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    weighted_phrases = [(term, round(wt,3)) for term, wt in weighted_phrases]\n",
    "    \n",
    "    return weighted_phrases[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water', 1.0),\n",
       " ('asia', 0.807),\n",
       " ('wild', 0.764),\n",
       " ('great weight', 0.707),\n",
       " ('pillarlike legs', 0.707),\n",
       " ('southeast asia', 0.693),\n",
       " ('subsaharan africa south asia', 0.693),\n",
       " ('body temperature', 0.693),\n",
       " ('flaps', 0.693),\n",
       " ('fissionfusion society', 0.693),\n",
       " ('multiple family groups', 0.693),\n",
       " ('art folklore religion literature', 0.693),\n",
       " ('popular culture', 0.693),\n",
       " ('ears', 0.681),\n",
       " ('males', 0.653),\n",
       " ('males bulls', 0.653),\n",
       " ('family elephantidae', 0.607),\n",
       " ('large mammals', 0.607),\n",
       " ('years', 0.607),\n",
       " ('environments', 0.577),\n",
       " ('impact', 0.577),\n",
       " ('keystone species', 0.577),\n",
       " ('cetaceans', 0.577),\n",
       " ('elephant intelligence', 0.577),\n",
       " ('primates', 0.577),\n",
       " ('dead individuals', 0.577),\n",
       " ('kind', 0.577),\n",
       " ('selfawareness', 0.577),\n",
       " ('different habitats', 0.57),\n",
       " ('marshes', 0.57)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 30 tf-idf weighted keyphrases\n",
    "get_tfidf_weighted_keyphrases(sentences=norm_sentences, top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('african bush elephant', 0.261),\n",
       " ('including', 0.141),\n",
       " ('family', 0.137),\n",
       " ('cow', 0.124),\n",
       " ('forests', 0.108),\n",
       " ('female', 0.103),\n",
       " ('asia', 0.102),\n",
       " ('objects', 0.098),\n",
       " ('sight', 0.098),\n",
       " ('ivory', 0.098),\n",
       " ('tigers', 0.098),\n",
       " ('males', 0.088),\n",
       " ('folklore', 0.087),\n",
       " ('religion', 0.087),\n",
       " ('known', 0.087),\n",
       " ('larger ears', 0.085),\n",
       " ('water', 0.075),\n",
       " ('highly recognisable', 0.075),\n",
       " ('breathing lifting', 0.074),\n",
       " ('flaps', 0.073),\n",
       " ('africa', 0.072),\n",
       " ('gomphotheres', 0.072),\n",
       " ('animals tend', 0.071),\n",
       " ('success', 0.071),\n",
       " ('south', 0.07)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "key_words = keywords(data[0], ratio=1.0, scores=True, lemmatize=True)\n",
    "[(item, round(score,3)) for item, score in key_words][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling on Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Retrieval\n",
    "#!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset\n",
    "#!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nips11', 'nips10', 'nips03', 'README_yann', 'MATLAB_NOTES', 'nips08', 'nips00', 'nips06', 'nips05', 'nips12', 'nips02', 'nips04', 'idx', 'orig', 'nips07', 'nips09', 'nips01', 'RAW_DATA_NOTES']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load and View Dataset\n",
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# read all texts into a list\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814 \n",
      "NEU1OMO1PHIC NETWORKS BASED \n",
      "ON SPARSE OPTICAL ORTHOGONAL CODES \n",
      "Mario P. Vecchi and Jawad A. Salehl \n",
      "Bell Communications Research \n",
      "435 South Street \n",
      "Morristown, NJ 07960-1961 \n",
      "Abstract \n",
      "A family of neuromorphic networks specifically designed for communications \n",
      "and optical signal processing applications is presented. The information is encoded \n",
      "utilizing sparse Optical Orthogonal Code sequences on the basis of unipolar, binary \n",
      "(0, 1) signals. The generalized synaptic connectivity matrix is also unipolar, and \n",
      "clipped to binary (0, 1) values. In addition to high-capacity associative memory, \n",
      "the resulting neural networks can be used to implement general functions, such as \n",
      "code filtering, code mapping, code joining, code shifting and code projecting. \n",
      "1 Introduction \n",
      "Synthetic neural nets [1,2] represent an active and growing research field. Fundamental \n",
      "issues, as well as practical implementations with electronic and optical devices are being \n",
      "studied. In addition, several lea\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 40 s, sys: 0 ns, total: 40 s\n",
      "Wall time: 40.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Basic Text Wrangling\n",
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "        \n",
    "    return norm_papers\n",
    "\n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu1', 'omo1', 'phic', 'network', 'based', 'sparse', 'optical', 'orthogonal', 'code', 'mario', 'vecchi', 'jawad', 'salehl', 'bell', 'communication', 'research', 'south', 'street', 'morristown', 'nj', 'abstract', 'family', 'neuromorphic', 'network', 'specifically', 'designed', 'communication', 'optical', 'signal', 'processing', 'application', 'presented', 'information', 'encoded', 'utilizing', 'sparse', 'optical', 'orthogonal', 'code', 'sequence', 'basis', 'unipolar', 'binary', 'signal', 'generalized', 'synaptic', 'connectivity', 'matrix', 'also', 'unipolar']\n"
     ]
    }
   ],
   "source": [
    "# viewing a processed paper\n",
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neu1', 'omo1', 'phic', 'network', 'based', 'sparse', 'optical', 'orthogonal', 'code', 'mario', 'vecchi', 'jawad', 'salehl', 'bell', 'communication', 'research', 'south', 'street', 'morristown', 'nj_abstract', 'family', 'neuromorphic', 'network', 'specifically', 'designed', 'communication', 'optical', 'signal_processing', 'application', 'presented', 'information', 'encoded', 'utilizing', 'sparse', 'optical', 'orthogonal', 'code', 'sequence', 'basis', 'unipolar', 'binary', 'signal', 'generalized', 'synaptic', 'connectivity', 'matrix', 'also', 'unipolar', 'clipped', 'binary']\n"
     ]
    }
   ],
   "source": [
    "## Text Representation with Feature Engineering\n",
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, \n",
    "                               threshold=20, delimiter=b'_') # higher threshold fewer phrases\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "# sample demonstration\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '2f'), (1, '2our'), (2, '3the'), (3, '82o'), (4, '86ch'), (5, '_b'), (6, '_t'), (7, '_u'), (8, '_v'), (9, '_ym'), (10, '_z'), (11, 'ability'), (12, 'absence'), (13, 'ac'), (14, 'acad_sci')]\n",
      "Total Vocabulary Size 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# create a dictionary representation of the documents\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# filer out words that occur less than 20 documents, or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 1), (8, 1), (13, 2), (20, 1), (24, 1), (34, 2), (46, 2), (52, 1), (56, 1), (57, 2), (58, 2), (66, 1), (76, 3), (77, 1), (83, 1), (86, 1), (87, 1), (100, 1), (101, 1), (103, 1), (105, 2), (108, 1), (113, 1), (117, 1), (118, 2), (119, 1), (126, 1), (130, 1), (132, 1), (138, 2), (148, 2), (155, 1), (169, 2), (172, 1), (173, 3), (177, 2), (185, 2), (186, 2), (189, 2), (190, 1), (200, 1), (210, 3), (211, 1), (217, 1), (218, 3), (222, 4), (227, 5), (231, 2), (240, 2), (245, 1)]\n"
     ]
    }
   ],
   "source": [
    "# transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('absence', 1), ('accurately', 1), ('addition', 2), ('american_institute', 1), ('application', 1), ('available', 2), ('body', 2), ('channel', 1), ('class', 1), ('clear', 2), ('clearly', 2), ('combination', 1), ('computational', 3), ('computer', 1), ('condition', 1), ('connected', 1), ('connectivity', 1), ('corresponding', 1), ('corresponds', 1), ('cross', 1), ('cycle', 2), ('defined', 1), ('design', 1), ('determined', 1), ('developed', 2), ('development', 1), ('directly', 1), ('discussion', 1), ('distinct', 1), ('easily', 2), ('end', 2), ('established', 1), ('far', 2), ('feedback', 1), ('fiber', 3), ('filter', 2), ('functional', 2), ('fundamental', 2), ('generally', 2), ('generate', 1), ('hard', 1), ('iii', 3), ('ij', 1), ('importance', 1), ('important', 3), ('indicated', 4), ('intensity', 5), ('interesting', 2), ('le', 2), ('line', 1)]\n"
     ]
    }
   ],
   "source": [
    "# viewing actual terms and their counts\n",
    "print([(dictionary[idx], freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "# total papers in the corpus\n",
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 0 ns, total: 2min 34s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Semantic Indexing\n",
    "TOTAL_TOPICS = 10\n",
    "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS, \n",
    "                                 onepass=True, chunksize=1740, power_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n",
      "\n",
      "Topic #2:\n",
      "0.487*\"neuron\" + 0.396*\"cell\" + -0.257*\"state\" + 0.191*\"response\" + -0.187*\"training\" + 0.170*\"stimulus\" + 0.117*\"activity\" + -0.109*\"class\" + 0.099*\"spike\" + 0.097*\"pattern\" + 0.096*\"circuit\" + 0.096*\"synaptic\" + -0.095*\"vector\" + 0.090*\"signal\" + 0.090*\"firing\" + 0.088*\"visual\" + -0.084*\"classifier\" + -0.083*\"action\" + -0.078*\"word\" + 0.078*\"cortical\"\n",
      "\n",
      "Topic #3:\n",
      "-0.627*\"state\" + 0.395*\"image\" + -0.219*\"neuron\" + 0.209*\"feature\" + -0.188*\"action\" + 0.137*\"unit\" + 0.131*\"object\" + -0.130*\"control\" + 0.129*\"training\" + -0.109*\"policy\" + 0.103*\"classifier\" + 0.090*\"class\" + -0.081*\"step\" + -0.081*\"dynamic\" + 0.080*\"classification\" + 0.078*\"layer\" + 0.076*\"recognition\" + -0.074*\"reinforcement_learning\" + 0.069*\"representation\" + 0.068*\"pattern\"\n",
      "\n",
      "Topic #4:\n",
      "-0.686*\"unit\" + 0.433*\"image\" + -0.182*\"pattern\" + -0.131*\"layer\" + -0.123*\"hidden_unit\" + -0.121*\"net\" + -0.114*\"training\" + 0.112*\"feature\" + -0.109*\"activation\" + -0.107*\"rule\" + 0.097*\"neuron\" + -0.078*\"word\" + 0.070*\"pixel\" + -0.070*\"connection\" + 0.067*\"object\" + 0.065*\"state\" + 0.060*\"distribution\" + 0.059*\"face\" + -0.057*\"architecture\" + 0.055*\"estimate\"\n",
      "\n",
      "Topic #5:\n",
      "-0.428*\"image\" + -0.348*\"state\" + 0.266*\"neuron\" + -0.264*\"unit\" + 0.181*\"training\" + 0.174*\"class\" + -0.168*\"object\" + 0.167*\"classifier\" + -0.147*\"action\" + -0.122*\"visual\" + 0.117*\"vector\" + 0.115*\"node\" + 0.105*\"distribution\" + -0.103*\"motion\" + -0.099*\"feature\" + 0.097*\"classification\" + -0.097*\"control\" + -0.095*\"task\" + -0.087*\"cell\" + -0.083*\"representation\"\n",
      "\n",
      "Topic #6:\n",
      "-0.660*\"cell\" + 0.508*\"neuron\" + 0.213*\"image\" + 0.103*\"chip\" + 0.097*\"unit\" + -0.093*\"response\" + 0.090*\"object\" + -0.083*\"rat\" + -0.076*\"distribution\" + 0.070*\"circuit\" + -0.069*\"probability\" + -0.064*\"stimulus\" + 0.061*\"memory\" + 0.058*\"analog\" + 0.058*\"activation\" + -0.055*\"class\" + 0.053*\"bit\" + 0.052*\"net\" + -0.051*\"cortical\" + -0.050*\"firing\"\n",
      "\n",
      "Topic #7:\n",
      "-0.353*\"word\" + 0.281*\"unit\" + -0.272*\"training\" + -0.257*\"classifier\" + -0.177*\"recognition\" + 0.159*\"distribution\" + -0.152*\"feature\" + -0.144*\"state\" + -0.142*\"pattern\" + 0.141*\"vector\" + -0.128*\"cell\" + -0.128*\"task\" + 0.122*\"approximation\" + 0.121*\"variable\" + 0.110*\"equation\" + -0.107*\"classification\" + 0.106*\"noise\" + -0.103*\"class\" + 0.101*\"matrix\" + -0.098*\"neuron\"\n",
      "\n",
      "Topic #8:\n",
      "-0.303*\"pattern\" + 0.243*\"signal\" + 0.236*\"control\" + 0.202*\"training\" + -0.181*\"rule\" + -0.178*\"state\" + 0.167*\"noise\" + -0.166*\"class\" + 0.162*\"word\" + -0.155*\"cell\" + -0.154*\"feature\" + 0.147*\"motion\" + 0.140*\"task\" + -0.127*\"node\" + -0.124*\"neuron\" + 0.116*\"target\" + 0.114*\"circuit\" + -0.114*\"probability\" + -0.110*\"classifier\" + -0.109*\"image\"\n",
      "\n",
      "Topic #9:\n",
      "-0.472*\"node\" + -0.254*\"circuit\" + 0.214*\"word\" + -0.201*\"chip\" + 0.190*\"neuron\" + 0.172*\"stimulus\" + -0.160*\"classifier\" + -0.152*\"current\" + 0.147*\"feature\" + -0.146*\"voltage\" + 0.145*\"distribution\" + -0.141*\"control\" + -0.124*\"rule\" + -0.110*\"layer\" + -0.105*\"analog\" + -0.091*\"tree\" + 0.084*\"response\" + 0.080*\"state\" + 0.079*\"probability\" + 0.079*\"estimate\"\n",
      "\n",
      "Topic #10:\n",
      "0.518*\"word\" + -0.254*\"training\" + 0.236*\"vector\" + -0.222*\"task\" + -0.194*\"pattern\" + -0.156*\"classifier\" + 0.149*\"node\" + 0.146*\"recognition\" + -0.139*\"control\" + 0.138*\"sequence\" + -0.126*\"rule\" + 0.125*\"circuit\" + 0.123*\"cell\" + -0.113*\"action\" + -0.105*\"neuron\" + 0.094*\"hmm\" + 0.093*\"character\" + 0.088*\"chip\" + 0.088*\"matrix\" + 0.085*\"structure\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.487), ('cell', 0.396), ('response', 0.191), ('stimulus', 0.17), ('activity', 0.117), ('spike', 0.099), ('pattern', 0.097), ('circuit', 0.096), ('synaptic', 0.096), ('signal', 0.09), ('firing', 0.09), ('visual', 0.088), ('cortical', 0.078)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.257), ('training', -0.187), ('class', -0.109), ('vector', -0.095), ('classifier', -0.084), ('action', -0.083), ('word', -0.078)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.395), ('feature', 0.209), ('unit', 0.137), ('object', 0.131), ('training', 0.129), ('classifier', 0.103), ('class', 0.09), ('classification', 0.08), ('layer', 0.078), ('recognition', 0.076), ('representation', 0.069), ('pattern', 0.068)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.627), ('neuron', -0.219), ('action', -0.188), ('control', -0.13), ('policy', -0.109), ('step', -0.081), ('dynamic', -0.081), ('reinforcement_learning', -0.074)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.433), ('feature', 0.112), ('neuron', 0.097), ('pixel', 0.07), ('object', 0.067), ('state', 0.065), ('distribution', 0.06), ('face', 0.059), ('estimate', 0.055)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -0.686), ('pattern', -0.182), ('layer', -0.131), ('hidden_unit', -0.123), ('net', -0.121), ('training', -0.114), ('activation', -0.109), ('rule', -0.107), ('word', -0.078), ('connection', -0.07), ('architecture', -0.057)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.266), ('training', 0.181), ('class', 0.174), ('classifier', 0.167), ('vector', 0.117), ('node', 0.115), ('distribution', 0.105), ('classification', 0.097)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.428), ('state', -0.348), ('unit', -0.264), ('object', -0.168), ('action', -0.147), ('visual', -0.122), ('motion', -0.103), ('feature', -0.099), ('control', -0.097), ('task', -0.095), ('cell', -0.087), ('representation', -0.083)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('neuron', 0.508), ('image', 0.213), ('chip', 0.103), ('unit', 0.097), ('object', 0.09), ('circuit', 0.07), ('memory', 0.061), ('analog', 0.058), ('activation', 0.058), ('bit', 0.053), ('net', 0.052)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -0.66), ('response', -0.093), ('rat', -0.083), ('distribution', -0.076), ('probability', -0.069), ('stimulus', -0.064), ('class', -0.055), ('cortical', -0.051), ('firing', -0.05)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.281), ('distribution', 0.159), ('vector', 0.141), ('approximation', 0.122), ('variable', 0.121), ('equation', 0.11), ('noise', 0.106), ('matrix', 0.101)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.353), ('training', -0.272), ('classifier', -0.257), ('recognition', -0.177), ('feature', -0.152), ('state', -0.144), ('pattern', -0.142), ('cell', -0.128), ('task', -0.128), ('classification', -0.107), ('class', -0.103), ('neuron', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('signal', 0.243), ('control', 0.236), ('training', 0.202), ('noise', 0.167), ('word', 0.162), ('motion', 0.147), ('task', 0.14), ('target', 0.116), ('circuit', 0.114)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('pattern', -0.303), ('rule', -0.181), ('state', -0.178), ('class', -0.166), ('cell', -0.155), ('feature', -0.154), ('node', -0.127), ('neuron', -0.124), ('probability', -0.114), ('classifier', -0.11), ('image', -0.109)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.214), ('neuron', 0.19), ('stimulus', 0.172), ('feature', 0.147), ('distribution', 0.145), ('response', 0.084), ('state', 0.08), ('probability', 0.079), ('estimate', 0.079)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -0.472), ('circuit', -0.254), ('chip', -0.201), ('classifier', -0.16), ('current', -0.152), ('voltage', -0.146), ('control', -0.141), ('rule', -0.124), ('layer', -0.11), ('analog', -0.105), ('tree', -0.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.518), ('vector', 0.236), ('node', 0.149), ('recognition', 0.146), ('sequence', 0.138), ('circuit', 0.125), ('cell', 0.123), ('hmm', 0.094), ('character', 0.093), ('chip', 0.088), ('matrix', 0.088), ('structure', 0.085)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('training', -0.254), ('task', -0.222), ('pattern', -0.194), ('classifier', -0.156), ('control', -0.139), ('rule', -0.126), ('action', -0.113), ('neuron', -0.105)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt,3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt,3)))\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get U, S, VT matrices from topic model\n",
    "term_topic = lsi_bow.projection.u\n",
    "singular_values = lsi_bow.projection.s\n",
    "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0  0.025 -0.011 -0.001  0.011  0.026  0.015  0.030 -0.025 -0.016  0.073\n",
       "1  0.021  0.028 -0.004  0.003 -0.003 -0.000 -0.008  0.009  0.008 -0.014\n",
       "2  0.027  0.007  0.006  0.017  0.017  0.035 -0.008 -0.001 -0.079  0.075\n",
       "3  0.016  0.017 -0.013  0.008  0.024  0.028  0.000 -0.019  0.008 -0.006\n",
       "4  0.018  0.030 -0.003  0.001  0.006 -0.031 -0.005 -0.001  0.001  0.004"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document topic matrix for our LSI model\n",
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T8', 'T1', 'T4']\n",
      "Paper Summary:\n",
      "412 \n",
      "CAPACITY FOR PATTERNS AND SEQUENCES IN KANERVA'S SDM \n",
      "AS COMPARED TO OTHER ASSOCIATIVE MEMORY MODELS \n",
      "James D. Keeler \n",
      "Chemistry Department, Stanford University, Stanford, CA 94305 \n",
      "and RIACS, NASA-AMES 230-5 Moffett Field, CA 94035. \n",
      "e.rnail: jdk hydra.riacs. edu \n",
      "ABSTRACT \n",
      "The information capacity of Kanerva's Sparse, Distributed Memory (SDM) and Hopfield-type \n",
      "neural networks is investigated. Under the approximations used here, it is shown that the to- \n",
      "tal information stored in these s\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T8', 'T1', 'T2']\n",
      "Paper Summary:\n",
      "68 Baird \n",
      "Associative Memory in a Simple Model of \n",
      "Oscillating Cortex \n",
      "Bill Baird \n",
      "Dept Molecular and Cell Biology, \n",
      "U.C.Berkeley, Berkeley, Ca. 94720 \n",
      "ABSTRACT \n",
      "A generic model of oscillating cortex, which assumes \"minimal\" \n",
      "coupling justified by known anatomy, is shown to function as an \n",
      "sociative memory, using previously developed theory. The network \n",
      "has explicit excitatory neurons with local inhibitory interneuron \n",
      "feedback that forms a set of nonlinear oscillators coupled only by \n",
      "long ran\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T10', 'T4', 'T9']\n",
      "Paper Summary:\n",
      "Interpretation of Artificial Neural Networks: \n",
      "Mapping Knowledge-Based Neural Networks into Rules \n",
      "Geoffrey Towell Jude W. Shavlik \n",
      "Computer Sciences Department \n",
      "University of Wisconsin \n",
      "Madison, WI 53706 \n",
      "Abstract \n",
      "We propose and empirically evaluate a method for the extraction of expert- \n",
      "comprehensible rules from trained neural networks. Our method operates in \n",
      "the context of a three-step process for learning that uses rule-based domain \n",
      "knowledge in combination with neural networks. Empirica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.\n",
    "                      columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7756, 1740)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Implementing LSI Topic Models from Scratch\n",
    "td_matrix = gensim.matutils.corpus2dense(corpus=bow_corpus, num_terms=len(dictionary))\n",
    "print(td_matrix.shape)\n",
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['3the', 'ability', 'absence', ..., 'smola', 'mozer_jordan',\n",
       "       'kearns_solla'], dtype='<U28')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = np.array(list(dictionary.values()))\n",
    "print('Total vocabulary size:', len(vocabulary))\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "u, s, vt = svds(td_matrix, k=TOTAL_TOPICS, maxiter=10000)\n",
    "term_topic = u\n",
    "singular_values = s\n",
    "topic_document = vt\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7756)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_weights = term_topic.transpose() * singular_values[:,None]\n",
    "tt_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('training', 92.619), ('task', 80.732), ('pattern', 70.619), ('classifier', 56.987), ('control', 50.675), ('rule', 45.926), ('action', 41.202), ('neuron', 38.195)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -188.486), ('vector', -85.973), ('node', -54.38), ('recognition', -53.231), ('sequence', -50.35), ('circuit', -45.396), ('cell', -44.811), ('hmm', -34.085), ('character', -34.022), ('chip', -32.162), ('matrix', -32.093), ('structure', -30.993)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('node', 173.276), ('circuit', 92.999), ('chip', 73.593), ('classifier', 58.718), ('current', 55.844), ('voltage', 53.489), ('control', 51.709), ('rule', 45.295), ('layer', 40.265), ('analog', 38.343), ('tree', 33.483)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -78.351), ('neuron', -69.792), ('stimulus', -63.233), ('feature', -53.819), ('distribution', -53.119), ('response', -30.954), ('state', -29.343), ('probability', -29.1), ('estimate', -28.908)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('pattern', 116.972), ('rule', 69.783), ('state', 68.605), ('class', 64.259), ('cell', 59.979), ('feature', 59.607), ('node', 49.175), ('neuron', 47.998), ('probability', 43.813), ('classifier', 42.612), ('image', 42.061)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('signal', -93.805), ('control', -91.041), ('training', -77.88), ('noise', -64.397), ('word', -62.392), ('motion', -56.699), ('task', -53.882), ('target', -44.765), ('circuit', -44.129)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('word', 147.792), ('training', 113.693), ('classifier', 107.386), ('recognition', 73.948), ('feature', 63.454), ('state', 60.126), ('pattern', 59.561), ('cell', 53.767), ('task', 53.693), ('classification', 44.936), ('class', 43.161), ('neuron', 41.093)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -117.727), ('distribution', -66.72), ('vector', -58.881), ('approximation', -50.931), ('variable', -50.83), ('equation', -46.229), ('noise', -44.247), ('matrix', -42.214)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('cell', 285.803), ('response', 40.216), ('rat', 35.975), ('distribution', 33.085), ('probability', 29.79), ('stimulus', 27.789), ('class', 24.02), ('cortical', 22.185), ('firing', 21.66)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -220.116), ('image', -92.391), ('chip', -44.422), ('unit', -41.922), ('object', -39.001), ('circuit', -30.444), ('memory', -26.475), ('analog', -25.207), ('activation', -24.953), ('bit', -22.997), ('net', -22.699)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('image', 209.794), ('state', 170.207), ('unit', 129.108), ('object', 82.185), ('action', 72.136), ('visual', 59.502), ('motion', 50.605), ('feature', 48.665), ('control', 47.427), ('task', 46.496), ('cell', 42.366), ('representation', 40.564)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -130.054), ('training', -88.668), ('class', -85.213), ('classifier', -81.92), ('vector', -57.532), ('node', -56.341), ('distribution', -51.622), ('classification', -47.645)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('image', 215.857), ('feature', 55.647), ('neuron', 48.495), ('pixel', 35.095), ('object', 33.585), ('state', 32.544), ('distribution', 29.977), ('face', 29.256), ('estimate', 27.555)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -341.829), ('pattern', -90.771), ('layer', -65.337), ('hidden_unit', -61.12), ('net', -60.035), ('training', -56.742), ('activation', -54.268), ('rule', -53.377), ('word', -38.903), ('connection', -34.618), ('architecture', -28.439)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('image', 229.287), ('feature', 121.397), ('unit', 79.44), ('object', 76.204), ('training', 75.153), ('classifier', 59.872), ('class', 52.527), ('classification', 46.696), ('layer', 45.149), ('recognition', 44.192), ('representation', 40.179), ('pattern', 39.252)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -364.388), ('neuron', -127.022), ('action', -109.245), ('control', -75.369), ('policy', -63.103), ('step', -47.226), ('dynamic', -46.907), ('reinforcement_learning', -42.747)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('state', 161.465), ('training', 117.319), ('class', 68.732), ('vector', 59.558), ('classifier', 52.589), ('action', 52.113), ('word', 49.239)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -306.151), ('cell', -249.243), ('response', -119.758), ('stimulus', -106.762), ('activity', -73.499), ('spike', -62.039), ('pattern', -60.957), ('circuit', -60.602), ('synaptic', -60.282), ('signal', -56.665), ('firing', -56.597), ('visual', -55.571), ('cortical', -48.867)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: []\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -260.793), ('state', -258.146), ('training', -227.312), ('neuron', -215.681), ('pattern', -197.232), ('image', -175.735), ('vector', -170.154), ('feature', -151.547), ('cell', -148.138), ('layer', -133.593), ('task', -122.389), ('class', -117.849), ('probability', -110.526), ('signal', -108.232), ('step', -105.202), ('response', -104.465), ('representation', -103.255), ('noise', -100.573), ('rule', -99.611), ('distribution', -98.973)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(tt_weights), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([tt_weights[row, columns]\n",
    "                                 for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weights[n]\n",
    "    term_weights = sorted([(t,w) for t, w in zip(terms, weights)], key=lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T3', 'T10', 'T7']\n",
      "Paper Summary:\n",
      "412 \n",
      "CAPACITY FOR PATTERNS AND SEQUENCES IN KANERVA'S SDM \n",
      "AS COMPARED TO OTHER ASSOCIATIVE MEMORY MODELS \n",
      "James D. Keeler \n",
      "Chemistry Department, Stanford University, Stanford, CA 94305 \n",
      "and RIACS, NASA-AMES 230-5 Moffett Field, CA 94035. \n",
      "e.rnail: jdk hydra.riacs. edu \n",
      "ABSTRACT \n",
      "The information capacity of Kanerva's Sparse, Distributed Memory (SDM) and Hopfield-type \n",
      "neural networks is investigated. Under the approximations used here, it is shown that the to- \n",
      "tal information stored in these s\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T3', 'T10', 'T9']\n",
      "Paper Summary:\n",
      "68 Baird \n",
      "Associative Memory in a Simple Model of \n",
      "Oscillating Cortex \n",
      "Bill Baird \n",
      "Dept Molecular and Cell Biology, \n",
      "U.C.Berkeley, Berkeley, Ca. 94720 \n",
      "ABSTRACT \n",
      "A generic model of oscillating cortex, which assumes \"minimal\" \n",
      "coupling justified by known anatomy, is shown to function as an \n",
      "sociative memory, using previously developed theory. The network \n",
      "has explicit excitatory neurons with local inhibitory interneuron \n",
      "feedback that forms a set of nonlinear oscillators coupled only by \n",
      "long ran\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T1', 'T7', 'T2']\n",
      "Paper Summary:\n",
      "Interpretation of Artificial Neural Networks: \n",
      "Mapping Knowledge-Based Neural Networks into Rules \n",
      "Geoffrey Towell Jude W. Shavlik \n",
      "Computer Sciences Department \n",
      "University of Wisconsin \n",
      "Madison, WI 53706 \n",
      "Abstract \n",
      "We propose and empirically evaluate a method for the extraction of expert- \n",
      "comprehensible rules from trained neural networks. Our method operates in \n",
      "the context of a three-step process for learning that uses rule-based domain \n",
      "knowledge in combination with neural networks. Empirica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.\n",
    "                      columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 0 ns, total: 2min 34s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Dirichlet Allocation\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, \n",
    "                                   chunksize=1740, alpha='auto', eta='auto', random_state=42, \n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.012*\"classifier\" + 0.010*\"class\" + 0.010*\"classification\" + 0.009*\"training\" + 0.008*\"feature\" + 0.006*\"pattern\" + 0.006*\"vector\" + 0.005*\"tree\" + 0.004*\"probability\" + 0.004*\"test\" + 0.004*\"expert\" + 0.004*\"cluster\" + 0.004*\"clustering\" + 0.004*\"training_set\" + 0.004*\"distance\" + 0.004*\"node\" + 0.003*\"sample\" + 0.003*\"table\" + 0.003*\"technique\" + 0.003*\"application\"\n",
      "\n",
      "Topic #2:\n",
      "0.017*\"cell\" + 0.017*\"unit\" + 0.016*\"pattern\" + 0.010*\"layer\" + 0.007*\"activity\" + 0.006*\"connection\" + 0.005*\"synaptic\" + 0.004*\"synapsis\" + 0.004*\"activation\" + 0.004*\"simulation\" + 0.004*\"rule\" + 0.004*\"rat\" + 0.004*\"kernel\" + 0.004*\"perturbation\" + 0.004*\"active\" + 0.004*\"training\" + 0.003*\"hidden_unit\" + 0.003*\"effect\" + 0.003*\"memory\" + 0.003*\"region\"\n",
      "\n",
      "Topic #3:\n",
      "0.016*\"training\" + 0.015*\"unit\" + 0.009*\"word\" + 0.008*\"recognition\" + 0.007*\"net\" + 0.007*\"layer\" + 0.007*\"task\" + 0.007*\"trained\" + 0.007*\"hidden_unit\" + 0.006*\"feature\" + 0.006*\"pattern\" + 0.006*\"speech\" + 0.006*\"architecture\" + 0.004*\"representation\" + 0.004*\"character\" + 0.004*\"sequence\" + 0.004*\"context\" + 0.003*\"experiment\" + 0.003*\"training_set\" + 0.003*\"frame\"\n",
      "\n",
      "Topic #4:\n",
      "0.021*\"neuron\" + 0.014*\"circuit\" + 0.011*\"chip\" + 0.010*\"current\" + 0.009*\"cell\" + 0.008*\"voltage\" + 0.007*\"analog\" + 0.006*\"signal\" + 0.005*\"synaptic\" + 0.005*\"channel\" + 0.005*\"response\" + 0.005*\"synapse\" + 0.004*\"neural\" + 0.004*\"threshold\" + 0.004*\"synapsis\" + 0.004*\"frequency\" + 0.004*\"bit\" + 0.004*\"pulse\" + 0.003*\"implementation\" + 0.003*\"connection\"\n",
      "\n",
      "Topic #5:\n",
      "0.019*\"neuron\" + 0.009*\"signal\" + 0.009*\"dynamic\" + 0.009*\"noise\" + 0.007*\"state\" + 0.007*\"spike\" + 0.007*\"equation\" + 0.005*\"solution\" + 0.004*\"neural\" + 0.004*\"rate\" + 0.004*\"eq\" + 0.004*\"phase\" + 0.004*\"rule\" + 0.003*\"fixed_point\" + 0.003*\"correlation\" + 0.003*\"distribution\" + 0.003*\"matrix\" + 0.003*\"delay\" + 0.003*\"constant\" + 0.003*\"energy\"\n",
      "\n",
      "Topic #6:\n",
      "0.049*\"image\" + 0.013*\"object\" + 0.011*\"feature\" + 0.010*\"pixel\" + 0.008*\"face\" + 0.006*\"filter\" + 0.006*\"visual\" + 0.006*\"view\" + 0.005*\"representation\" + 0.004*\"surface\" + 0.004*\"region\" + 0.004*\"local\" + 0.004*\"scale\" + 0.004*\"scene\" + 0.004*\"ica\" + 0.004*\"recognition\" + 0.003*\"position\" + 0.003*\"shape\" + 0.003*\"linear\" + 0.003*\"location\"\n",
      "\n",
      "Topic #7:\n",
      "0.012*\"rule\" + 0.011*\"node\" + 0.010*\"memory\" + 0.009*\"pattern\" + 0.008*\"vector\" + 0.008*\"unit\" + 0.007*\"structure\" + 0.006*\"representation\" + 0.006*\"sequence\" + 0.004*\"state\" + 0.004*\"matrix\" + 0.004*\"activation\" + 0.004*\"symbol\" + 0.004*\"graph\" + 0.004*\"attractor\" + 0.003*\"capacity\" + 0.003*\"similarity\" + 0.003*\"language\" + 0.003*\"level\" + 0.003*\"element\"\n",
      "\n",
      "Topic #8:\n",
      "0.007*\"distribution\" + 0.006*\"vector\" + 0.006*\"training\" + 0.005*\"approximation\" + 0.005*\"linear\" + 0.005*\"estimate\" + 0.005*\"probability\" + 0.004*\"variable\" + 0.004*\"class\" + 0.004*\"sample\" + 0.004*\"matrix\" + 0.004*\"let\" + 0.004*\"gaussian\" + 0.003*\"equation\" + 0.003*\"bound\" + 0.003*\"prior\" + 0.003*\"optimal\" + 0.003*\"noise\" + 0.003*\"consider\" + 0.003*\"prediction\"\n",
      "\n",
      "Topic #9:\n",
      "0.012*\"stimulus\" + 0.011*\"response\" + 0.011*\"cell\" + 0.008*\"visual\" + 0.008*\"neuron\" + 0.007*\"motion\" + 0.007*\"unit\" + 0.006*\"activity\" + 0.006*\"map\" + 0.005*\"direction\" + 0.005*\"pattern\" + 0.004*\"cortical\" + 0.004*\"spatial\" + 0.004*\"orientation\" + 0.004*\"receptive_field\" + 0.004*\"cortex\" + 0.004*\"location\" + 0.004*\"et_al\" + 0.004*\"signal\" + 0.004*\"field\"\n",
      "\n",
      "Topic #10:\n",
      "0.030*\"state\" + 0.012*\"control\" + 0.010*\"action\" + 0.007*\"step\" + 0.006*\"task\" + 0.006*\"policy\" + 0.005*\"controller\" + 0.005*\"trajectory\" + 0.005*\"reinforcement_learning\" + 0.004*\"optimal\" + 0.004*\"environment\" + 0.004*\"dynamic\" + 0.004*\"robot\" + 0.003*\"training\" + 0.003*\"goal\" + 0.003*\"current\" + 0.003*\"transition\" + 0.003*\"adaptive\" + 0.003*\"reward\" + 0.003*\"sequence\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view topics in trained topic model\n",
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -1.0976687786641732\n"
     ]
    }
   ],
   "source": [
    "# view overall mean coherence score of model\n",
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('distribution', 0.007), ('vector', 0.006), ('training', 0.006), ('approximation', 0.005), ('linear', 0.005), ('estimate', 0.005), ('probability', 0.005), ('variable', 0.004), ('class', 0.004), ('sample', 0.004), ('matrix', 0.004), ('let', 0.004), ('gaussian', 0.004), ('equation', 0.003), ('bound', 0.003), ('prior', 0.003), ('optimal', 0.003), ('noise', 0.003), ('consider', 0.003), ('prediction', 0.003)]\n",
      "\n",
      "Topic #2:\n",
      "[('stimulus', 0.012), ('response', 0.011), ('cell', 0.011), ('visual', 0.008), ('neuron', 0.008), ('motion', 0.007), ('unit', 0.007), ('activity', 0.006), ('map', 0.006), ('direction', 0.005), ('pattern', 0.005), ('cortical', 0.004), ('spatial', 0.004), ('orientation', 0.004), ('receptive_field', 0.004), ('cortex', 0.004), ('location', 0.004), ('et_al', 0.004), ('signal', 0.004), ('field', 0.004)]\n",
      "\n",
      "Topic #3:\n",
      "[('classifier', 0.012), ('class', 0.01), ('classification', 0.01), ('training', 0.009), ('feature', 0.008), ('pattern', 0.006), ('vector', 0.006), ('tree', 0.005), ('probability', 0.004), ('test', 0.004), ('expert', 0.004), ('cluster', 0.004), ('clustering', 0.004), ('training_set', 0.004), ('distance', 0.004), ('node', 0.004), ('sample', 0.003), ('table', 0.003), ('technique', 0.003), ('application', 0.003)]\n",
      "\n",
      "Topic #4:\n",
      "[('training', 0.016), ('unit', 0.015), ('word', 0.009), ('recognition', 0.008), ('net', 0.007), ('layer', 0.007), ('task', 0.007), ('trained', 0.007), ('hidden_unit', 0.007), ('feature', 0.006), ('pattern', 0.006), ('speech', 0.006), ('architecture', 0.006), ('representation', 0.004), ('character', 0.004), ('sequence', 0.004), ('context', 0.004), ('experiment', 0.003), ('training_set', 0.003), ('frame', 0.003)]\n",
      "\n",
      "Topic #5:\n",
      "[('neuron', 0.021), ('circuit', 0.014), ('chip', 0.011), ('current', 0.01), ('cell', 0.009), ('voltage', 0.008), ('analog', 0.007), ('signal', 0.006), ('synaptic', 0.005), ('channel', 0.005), ('response', 0.005), ('synapse', 0.005), ('neural', 0.004), ('threshold', 0.004), ('synapsis', 0.004), ('frequency', 0.004), ('bit', 0.004), ('pulse', 0.004), ('implementation', 0.003), ('connection', 0.003)]\n",
      "\n",
      "Topic #6:\n",
      "[('state', 0.03), ('control', 0.012), ('action', 0.01), ('step', 0.007), ('task', 0.006), ('policy', 0.006), ('controller', 0.005), ('trajectory', 0.005), ('reinforcement_learning', 0.005), ('optimal', 0.004), ('environment', 0.004), ('dynamic', 0.004), ('robot', 0.004), ('training', 0.003), ('goal', 0.003), ('current', 0.003), ('transition', 0.003), ('adaptive', 0.003), ('reward', 0.003), ('sequence', 0.003)]\n",
      "\n",
      "Topic #7:\n",
      "[('neuron', 0.019), ('signal', 0.009), ('dynamic', 0.009), ('noise', 0.009), ('state', 0.007), ('spike', 0.007), ('equation', 0.007), ('solution', 0.005), ('neural', 0.004), ('rate', 0.004), ('eq', 0.004), ('phase', 0.004), ('rule', 0.004), ('fixed_point', 0.003), ('correlation', 0.003), ('distribution', 0.003), ('matrix', 0.003), ('delay', 0.003), ('constant', 0.003), ('energy', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('image', 0.049), ('object', 0.013), ('feature', 0.011), ('pixel', 0.01), ('face', 0.008), ('filter', 0.006), ('visual', 0.006), ('view', 0.006), ('representation', 0.005), ('surface', 0.004), ('region', 0.004), ('local', 0.004), ('scale', 0.004), ('scene', 0.004), ('ica', 0.004), ('recognition', 0.004), ('position', 0.003), ('shape', 0.003), ('linear', 0.003), ('location', 0.003)]\n",
      "\n",
      "Topic #9:\n",
      "[('cell', 0.017), ('unit', 0.017), ('pattern', 0.016), ('layer', 0.01), ('activity', 0.007), ('connection', 0.006), ('synaptic', 0.005), ('synapsis', 0.004), ('activation', 0.004), ('simulation', 0.004), ('rule', 0.004), ('rat', 0.004), ('kernel', 0.004), ('perturbation', 0.004), ('active', 0.004), ('training', 0.004), ('hidden_unit', 0.003), ('effect', 0.003), ('memory', 0.003), ('region', 0.003)]\n",
      "\n",
      "Topic #10:\n",
      "[('rule', 0.012), ('node', 0.011), ('memory', 0.01), ('pattern', 0.009), ('vector', 0.008), ('unit', 0.008), ('structure', 0.007), ('representation', 0.006), ('sequence', 0.006), ('state', 0.004), ('matrix', 0.004), ('activation', 0.004), ('symbol', 0.004), ('graph', 0.004), ('attractor', 0.004), ('capacity', 0.003), ('similarity', 0.003), ('language', 0.003), ('level', 0.003), ('element', 0.003)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output of topic models as tuples of terms and weights\n",
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt,3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['distribution', 'vector', 'training', 'approximation', 'linear', 'estimate', 'probability', 'variable', 'class', 'sample', 'matrix', 'let', 'gaussian', 'equation', 'bound', 'prior', 'optimal', 'noise', 'consider', 'prediction']\n",
      "\n",
      "Topic #2:\n",
      "['stimulus', 'response', 'cell', 'visual', 'neuron', 'motion', 'unit', 'activity', 'map', 'direction', 'pattern', 'cortical', 'spatial', 'orientation', 'receptive_field', 'cortex', 'location', 'et_al', 'signal', 'field']\n",
      "\n",
      "Topic #3:\n",
      "['classifier', 'class', 'classification', 'training', 'feature', 'pattern', 'vector', 'tree', 'probability', 'test', 'expert', 'cluster', 'clustering', 'training_set', 'distance', 'node', 'sample', 'table', 'technique', 'application']\n",
      "\n",
      "Topic #4:\n",
      "['training', 'unit', 'word', 'recognition', 'net', 'layer', 'task', 'trained', 'hidden_unit', 'feature', 'pattern', 'speech', 'architecture', 'representation', 'character', 'sequence', 'context', 'experiment', 'training_set', 'frame']\n",
      "\n",
      "Topic #5:\n",
      "['neuron', 'circuit', 'chip', 'current', 'cell', 'voltage', 'analog', 'signal', 'synaptic', 'channel', 'response', 'synapse', 'neural', 'threshold', 'synapsis', 'frequency', 'bit', 'pulse', 'implementation', 'connection']\n",
      "\n",
      "Topic #6:\n",
      "['state', 'control', 'action', 'step', 'task', 'policy', 'controller', 'trajectory', 'reinforcement_learning', 'optimal', 'environment', 'dynamic', 'robot', 'training', 'goal', 'current', 'transition', 'adaptive', 'reward', 'sequence']\n",
      "\n",
      "Topic #7:\n",
      "['neuron', 'signal', 'dynamic', 'noise', 'state', 'spike', 'equation', 'solution', 'neural', 'rate', 'eq', 'phase', 'rule', 'fixed_point', 'correlation', 'distribution', 'matrix', 'delay', 'constant', 'energy']\n",
      "\n",
      "Topic #8:\n",
      "['image', 'object', 'feature', 'pixel', 'face', 'filter', 'visual', 'view', 'representation', 'surface', 'region', 'local', 'scale', 'scene', 'ica', 'recognition', 'position', 'shape', 'linear', 'location']\n",
      "\n",
      "Topic #9:\n",
      "['cell', 'unit', 'pattern', 'layer', 'activity', 'connection', 'synaptic', 'synapsis', 'activation', 'simulation', 'rule', 'rat', 'kernel', 'perturbation', 'active', 'training', 'hidden_unit', 'effect', 'memory', 'region']\n",
      "\n",
      "Topic #10:\n",
      "['rule', 'node', 'memory', 'pattern', 'vector', 'unit', 'structure', 'representation', 'sequence', 'state', 'matrix', 'activation', 'symbol', 'graph', 'attractor', 'capacity', 'similarity', 'language', 'level', 'element']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view topics as a list of terms without weights, understand context or theme of each topic\n",
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.48502663515630856\n",
      "Avg. Coherence Score (UMass): -1.0976687786641732\n",
      "Model Perplexity: -7.799324763924073\n"
     ]
    }
   ],
   "source": [
    "# use perplexity and coherence scores as measures to evaluate topic model\n",
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams, \n",
    "                                                      dictionary=dictionary, coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams, \n",
    "                                                         dictionary=dictionary, coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA Models with MALLET\n",
    "# download MALLET framework\n",
    "# !wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract contents from archive\n",
    "# !unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['image', 'feature', 'object', 'local', 'region', 'pixel', 'representation', 'distance', 'view', 'map', 'face', 'vector', 'surface', 'transformation', 'shape', 'edge', 'location', 'scale', 'structure', 'position']\n",
      "\n",
      "Topic #2:\n",
      "['circuit', 'chip', 'current', 'memory', 'bit', 'analog', 'neuron', 'voltage', 'signal', 'code', 'implementation', 'design', 'neural', 'operation', 'parallel', 'channel', 'computation', 'element', 'processor', 'application']\n",
      "\n",
      "Topic #3:\n",
      "['training', 'classification', 'word', 'classifier', 'class', 'feature', 'test', 'recognition', 'trained', 'experiment', 'training_set', 'speech', 'pattern', 'table', 'test_set', 'character', 'accuracy', 'task', 'vector', 'rate']\n",
      "\n",
      "Topic #4:\n",
      "['class', 'bound', 'size', 'linear', 'theorem', 'kernel', 'approximation', 'complexity', 'probability', 'theory', 'distribution', 'training', 'loss', 'threshold', 'optimal', 'defined', 'machine', 'polynomial', 'proof', 'hypothesis']\n",
      "\n",
      "Topic #5:\n",
      "['distribution', 'probability', 'variable', 'gaussian', 'estimate', 'prior', 'mixture', 'density', 'variance', 'sample', 'estimation', 'approximation', 'component', 'bayesian', 'likelihood', 'log', 'step', 'prediction', 'structure', 'statistical']\n",
      "\n",
      "Topic #6:\n",
      "['response', 'signal', 'visual', 'stimulus', 'motion', 'filter', 'direction', 'receptive_field', 'target', 'spatial', 'subject', 'frequency', 'field', 'eye', 'unit', 'map', 'orientation', 'velocity', 'location', 'temporal']\n",
      "\n",
      "Topic #7:\n",
      "['unit', 'node', 'layer', 'pattern', 'hidden_unit', 'rule', 'net', 'sequence', 'training', 'activation', 'architecture', 'representation', 'task', 'structure', 'recurrent', 'module', 'connection', 'connectionist', 'trained', 'learn']\n",
      "\n",
      "Topic #8:\n",
      "['equation', 'vector', 'matrix', 'noise', 'solution', 'dynamic', 'linear', 'convergence', 'nonlinear', 'gradient', 'rate', 'eq', 'state', 'optimal', 'energy', 'constraint', 'rule', 'optimization', 'line', 'minimum']\n",
      "\n",
      "Topic #9:\n",
      "['state', 'control', 'action', 'step', 'task', 'trajectory', 'policy', 'environment', 'controller', 'reinforcement_learning', 'path', 'goal', 'optimal', 'robot', 'dynamic', 'current', 'transition', 'move', 'search', 'change']\n",
      "\n",
      "Topic #10:\n",
      "['neuron', 'cell', 'pattern', 'activity', 'spike', 'synaptic', 'connection', 'response', 'neural', 'firing', 'effect', 'et_al', 'simulation', 'cortical', 'synapsis', 'type', 'stimulus', 'threshold', 'behavior', 'layer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MALLET_PATH = 'mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus,\n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary, \n",
    "                                              iterations=500, workers=16)\n",
    "\n",
    "topics=[[(term, round(wt,3)) \n",
    "         for term, wt in lda_mallet.show_topic(n, topn=20)]\n",
    "             for n in range(0, TOTAL_TOPICS)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.5203420492780962\n",
      "Avg. Coherence Score (UMass): -1.0040475460488156\n",
      "Model Perplexity: -8.53533\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using perplexity and coherence metrics\n",
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams, \n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, \n",
    "                                                                corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams, \n",
    "                                                                dictionary=dictionary, \n",
    "                                                                coherence='u_mass')\n",
    "\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.53533\n",
    "perplexity = -8.53533\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 29/29 [1:45:42<00:00, 218.70s/it]\n"
     ]
    }
   ],
   "source": [
    "## LDA Tuning: Finding the Optimal Number of Topics\n",
    "from tqdm import tqdm\n",
    "\n",
    "# iterate and build several models with differing number of topics\n",
    "# select one that has highest coherence score\n",
    "def topic_model_coherence_generator(corpus, texts, dictionary, start_topic_count=2, \n",
    "                                    end_topic_count=10, step=1, cpus=1):\n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, \n",
    "                                                            corpus=corpus, num_topics=topic_nums, \n",
    "                                                            id2word=dictionary, iterations=500, \n",
    "                                                            workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, \n",
    "                                                                     corpus=corpus, texts=texts, \n",
    "                                                                     dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores\n",
    "\n",
    "#lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, \n",
    "#                                                               texts=norm_corpus_bigrams, \n",
    "#                                                               dictionary=dictionary, \n",
    "#                                                               start_topic_count=2, \n",
    "#                                                               end_topic_count=30, step=1, \n",
    "#                                                               cpus=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import numpy\n",
    "\n",
    "# save model for later use\n",
    "#filename = 'lda_models.sav'\n",
    "#pickle.dump(lda_models, open(filename, 'wb'))\n",
    "\n",
    "# save coherence scores\n",
    "#np.savetxt(\"coherence_scores.csv\", coherence_scores, delimiter=\",\")#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and scores\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "filename = 'lda_models.sav'\n",
    "loaded_ldas = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "coherence_scores = np.genfromtxt('coherence_scores.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>0.5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0.5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "26                28           0.5421\n",
       "24                26           0.5405\n",
       "23                25           0.5378\n",
       "15                17           0.5369\n",
       "17                19           0.5361\n",
       "20                22           0.5357\n",
       "9                 11           0.5340\n",
       "13                15           0.5305\n",
       "11                13           0.5294\n",
       "6                  8           0.5293"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1), \n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot graph showing number of topics per model and corresponding coherence scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2,31,1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_ax, y_ax,c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "x1 = plt.xlabel('Number of Topics')\n",
    "y1 = plt.ylabel('Coherence Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on graph, choose optimal number of topics as 20\n",
    "# retrieve best model\n",
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['linear', 'nonlinear', 'vector', 'approximation', 'prediction', 'estimate', 'estimation', 'local', 'dimensional', 'regression', 'kernel', 'rbf', 'matrix', 'time_series', 'operator', 'gaussian', 'technique', 'sample', 'basis_function', 'dimension']\n",
      "\n",
      "Topic #2:\n",
      "['cell', 'response', 'stimulus', 'receptive_field', 'visual', 'cortical', 'spatial', 'cortex', 'orientation', 'activity', 'contrast', 'pattern', 'center', 'neuron', 'region', 'correlation', 'effect', 'property', 'connection', 'area']\n",
      "\n",
      "Topic #3:\n",
      "['neuron', 'cell', 'spike', 'synaptic', 'activity', 'firing', 'neural', 'synapsis', 'response', 'frequency', 'et_al', 'threshold', 'brain', 'rate', 'pattern', 'phase', 'current', 'oscillator', 'neuronal', 'fig']\n",
      "\n",
      "Topic #4:\n",
      "['word', 'recognition', 'speech', 'sequence', 'training', 'character', 'context', 'hmm', 'letter', 'frame', 'speaker', 'feature', 'state', 'speech_recognition', 'phoneme', 'trained', 'digit', 'window', 'segmentation', 'acoustic']\n",
      "\n",
      "Topic #5:\n",
      "['representation', 'task', 'human', 'target', 'subject', 'similarity', 'trial', 'effect', 'study', 'theory', 'cue', 'component', 'location', 'experiment', 'feature', 'condition', 'structure', 'pair', 'item', 'response']\n",
      "\n",
      "Topic #6:\n",
      "['distribution', 'probability', 'prior', 'variable', 'gaussian', 'density', 'mixture', 'bayesian', 'estimate', 'likelihood', 'approximation', 'sample', 'log', 'component', 'em', 'step', 'posterior', 'variance', 'probabilistic', 'estimation']\n",
      "\n",
      "Topic #7:\n",
      "['image', 'object', 'feature', 'pixel', 'view', 'face', 'visual', 'region', 'edge', 'shape', 'recognition', 'representation', 'surface', 'scale', 'contour', 'scene', 'vision', 'location', 'part', 'texture']\n",
      "\n",
      "Topic #8:\n",
      "['state', 'control', 'action', 'step', 'policy', 'controller', 'reinforcement_learning', 'environment', 'optimal', 'task', 'goal', 'transition', 'current', 'reward', 'robot', 'td', 'agent', 'trial', 'dynamic', 'adaptive']\n",
      "\n",
      "Topic #9:\n",
      "['training', 'hidden_unit', 'rule', 'net', 'task', 'trained', 'architecture', 'recurrent', 'learn', 'back_propagation', 'expert', 'generalization', 'hidden_layer', 'hidden', 'learned', 'backpropagation', 'prediction', 'training_set', 'epoch', 'language']\n",
      "\n",
      "Topic #10:\n",
      "['motion', 'direction', 'map', 'position', 'field', 'control', 'velocity', 'movement', 'location', 'trajectory', 'motor', 'target', 'visual', 'hand', 'change', 'arm', 'eye', 'coordinate', 'head', 'sensory']\n",
      "\n",
      "Topic #11:\n",
      "['bound', 'theorem', 'class', 'proof', 'theory', 'threshold', 'linear', 'size', 'defined', 'complexity', 'probability', 'definition', 'assume', 'bounded', 'condition', 'define', 'polynomial', 'xi', 'constant', 'property']\n",
      "\n",
      "Topic #12:\n",
      "['equation', 'dynamic', 'rate', 'convergence', 'eq', 'solution', 'gradient', 'matrix', 'vector', 'state', 'fixed_point', 'rule', 'line', 'theory', 'limit', 'curve', 'attractor', 'noise', 'eigenvalue', 'symmetric']\n",
      "\n",
      "Topic #13:\n",
      "['vector', 'memory', 'code', 'bit', 'pattern', 'capacity', 'state', 'matrix', 'binary', 'probability', 'random', 'size', 'hopfield', 'search', 'coding', 'stored', 'solution', 'temperature', 'energy', 'element']\n",
      "\n",
      "Topic #14:\n",
      "['constraint', 'distance', 'cluster', 'solution', 'transformation', 'structure', 'map', 'clustering', 'vector', 'local', 'graph', 'energy', 'mapping', 'region', 'neighborhood', 'optimization', 'matching', 'matrix', 'manifold', 'find']\n",
      "\n",
      "Topic #15:\n",
      "['node', 'class', 'classification', 'classifier', 'training', 'tree', 'pattern', 'feature', 'sample', 'test', 'accuracy', 'training_set', 'database', 'error_rate', 'probability', 'decision', 'labeled', 'nearest_neighbor', 'label', 'mlp']\n",
      "\n",
      "Topic #16:\n",
      "['unit', 'layer', 'pattern', 'activation', 'connection', 'structure', 'representation', 'module', 'architecture', 'level', 'activity', 'represent', 'processing', 'connectionist', 'type', 'part', 'role', 'step', 'representing', 'local']\n",
      "\n",
      "Topic #17:\n",
      "['signal', 'noise', 'filter', 'source', 'channel', 'component', 'frequency', 'correlation', 'pca', 'ica', 'phase', 'independent', 'linear', 'distribution', 'eeg', 'separation', 'entropy', 'basis', 'change', 'amplitude']\n",
      "\n",
      "Topic #18:\n",
      "['circuit', 'chip', 'current', 'neuron', 'analog', 'voltage', 'neural', 'implementation', 'gain', 'device', 'design', 'signal', 'synapse', 'digital', 'array', 'transistor', 'pulse', 'hardware', 'implemented', 'bit']\n",
      "\n",
      "Topic #19:\n",
      "['training', 'prediction', 'training_set', 'test', 'average', 'selection', 'kernel', 'machine', 'size', 'ensemble', 'query', 'optimal', 'noise', 'experiment', 'estimate', 'loss', 'expected', 'generalization', 'distribution', 'bias']\n",
      "\n",
      "Topic #20:\n",
      "['rate', 'application', 'user', 'table', 'computer', 'experiment', 'processor', 'run', 'block', 'program', 'speed', 'path', 'size', 'search', 'machine', 'technique', 'call', 'type', 'factor', 'schedule']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view all the 20 topics generated by selected best model\n",
    "topics = [[(term, round(wt, 3)) \n",
    "           for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "              for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>linear</td>\n",
       "      <td>cell</td>\n",
       "      <td>neuron</td>\n",
       "      <td>word</td>\n",
       "      <td>representation</td>\n",
       "      <td>distribution</td>\n",
       "      <td>image</td>\n",
       "      <td>state</td>\n",
       "      <td>training</td>\n",
       "      <td>motion</td>\n",
       "      <td>bound</td>\n",
       "      <td>equation</td>\n",
       "      <td>vector</td>\n",
       "      <td>constraint</td>\n",
       "      <td>node</td>\n",
       "      <td>unit</td>\n",
       "      <td>signal</td>\n",
       "      <td>circuit</td>\n",
       "      <td>training</td>\n",
       "      <td>rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>nonlinear</td>\n",
       "      <td>response</td>\n",
       "      <td>cell</td>\n",
       "      <td>recognition</td>\n",
       "      <td>task</td>\n",
       "      <td>probability</td>\n",
       "      <td>object</td>\n",
       "      <td>control</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>direction</td>\n",
       "      <td>theorem</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>memory</td>\n",
       "      <td>distance</td>\n",
       "      <td>class</td>\n",
       "      <td>layer</td>\n",
       "      <td>noise</td>\n",
       "      <td>chip</td>\n",
       "      <td>prediction</td>\n",
       "      <td>application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>vector</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>spike</td>\n",
       "      <td>speech</td>\n",
       "      <td>human</td>\n",
       "      <td>prior</td>\n",
       "      <td>feature</td>\n",
       "      <td>action</td>\n",
       "      <td>rule</td>\n",
       "      <td>map</td>\n",
       "      <td>class</td>\n",
       "      <td>rate</td>\n",
       "      <td>code</td>\n",
       "      <td>cluster</td>\n",
       "      <td>classification</td>\n",
       "      <td>pattern</td>\n",
       "      <td>filter</td>\n",
       "      <td>current</td>\n",
       "      <td>training_set</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>approximation</td>\n",
       "      <td>receptive_field</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>sequence</td>\n",
       "      <td>target</td>\n",
       "      <td>variable</td>\n",
       "      <td>pixel</td>\n",
       "      <td>step</td>\n",
       "      <td>net</td>\n",
       "      <td>position</td>\n",
       "      <td>proof</td>\n",
       "      <td>convergence</td>\n",
       "      <td>bit</td>\n",
       "      <td>solution</td>\n",
       "      <td>classifier</td>\n",
       "      <td>activation</td>\n",
       "      <td>source</td>\n",
       "      <td>neuron</td>\n",
       "      <td>test</td>\n",
       "      <td>table</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>prediction</td>\n",
       "      <td>visual</td>\n",
       "      <td>activity</td>\n",
       "      <td>training</td>\n",
       "      <td>subject</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>view</td>\n",
       "      <td>policy</td>\n",
       "      <td>task</td>\n",
       "      <td>field</td>\n",
       "      <td>theory</td>\n",
       "      <td>eq</td>\n",
       "      <td>pattern</td>\n",
       "      <td>transformation</td>\n",
       "      <td>training</td>\n",
       "      <td>connection</td>\n",
       "      <td>channel</td>\n",
       "      <td>analog</td>\n",
       "      <td>average</td>\n",
       "      <td>computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>estimate</td>\n",
       "      <td>cortical</td>\n",
       "      <td>firing</td>\n",
       "      <td>character</td>\n",
       "      <td>similarity</td>\n",
       "      <td>density</td>\n",
       "      <td>face</td>\n",
       "      <td>controller</td>\n",
       "      <td>trained</td>\n",
       "      <td>control</td>\n",
       "      <td>threshold</td>\n",
       "      <td>solution</td>\n",
       "      <td>capacity</td>\n",
       "      <td>structure</td>\n",
       "      <td>tree</td>\n",
       "      <td>structure</td>\n",
       "      <td>component</td>\n",
       "      <td>voltage</td>\n",
       "      <td>selection</td>\n",
       "      <td>experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>estimation</td>\n",
       "      <td>spatial</td>\n",
       "      <td>neural</td>\n",
       "      <td>context</td>\n",
       "      <td>trial</td>\n",
       "      <td>mixture</td>\n",
       "      <td>visual</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "      <td>architecture</td>\n",
       "      <td>velocity</td>\n",
       "      <td>linear</td>\n",
       "      <td>gradient</td>\n",
       "      <td>state</td>\n",
       "      <td>map</td>\n",
       "      <td>pattern</td>\n",
       "      <td>representation</td>\n",
       "      <td>frequency</td>\n",
       "      <td>neural</td>\n",
       "      <td>kernel</td>\n",
       "      <td>processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>local</td>\n",
       "      <td>cortex</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>hmm</td>\n",
       "      <td>effect</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>region</td>\n",
       "      <td>environment</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>movement</td>\n",
       "      <td>size</td>\n",
       "      <td>matrix</td>\n",
       "      <td>matrix</td>\n",
       "      <td>clustering</td>\n",
       "      <td>feature</td>\n",
       "      <td>module</td>\n",
       "      <td>correlation</td>\n",
       "      <td>implementation</td>\n",
       "      <td>machine</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>dimensional</td>\n",
       "      <td>orientation</td>\n",
       "      <td>response</td>\n",
       "      <td>letter</td>\n",
       "      <td>study</td>\n",
       "      <td>estimate</td>\n",
       "      <td>edge</td>\n",
       "      <td>optimal</td>\n",
       "      <td>learn</td>\n",
       "      <td>location</td>\n",
       "      <td>defined</td>\n",
       "      <td>vector</td>\n",
       "      <td>binary</td>\n",
       "      <td>vector</td>\n",
       "      <td>sample</td>\n",
       "      <td>architecture</td>\n",
       "      <td>pca</td>\n",
       "      <td>gain</td>\n",
       "      <td>size</td>\n",
       "      <td>block</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>regression</td>\n",
       "      <td>activity</td>\n",
       "      <td>frequency</td>\n",
       "      <td>frame</td>\n",
       "      <td>theory</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>shape</td>\n",
       "      <td>task</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>complexity</td>\n",
       "      <td>state</td>\n",
       "      <td>probability</td>\n",
       "      <td>local</td>\n",
       "      <td>test</td>\n",
       "      <td>level</td>\n",
       "      <td>ica</td>\n",
       "      <td>device</td>\n",
       "      <td>ensemble</td>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>kernel</td>\n",
       "      <td>contrast</td>\n",
       "      <td>et_al</td>\n",
       "      <td>speaker</td>\n",
       "      <td>cue</td>\n",
       "      <td>approximation</td>\n",
       "      <td>recognition</td>\n",
       "      <td>goal</td>\n",
       "      <td>expert</td>\n",
       "      <td>motor</td>\n",
       "      <td>probability</td>\n",
       "      <td>fixed_point</td>\n",
       "      <td>random</td>\n",
       "      <td>graph</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>activity</td>\n",
       "      <td>phase</td>\n",
       "      <td>design</td>\n",
       "      <td>query</td>\n",
       "      <td>speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>rbf</td>\n",
       "      <td>pattern</td>\n",
       "      <td>threshold</td>\n",
       "      <td>feature</td>\n",
       "      <td>component</td>\n",
       "      <td>sample</td>\n",
       "      <td>representation</td>\n",
       "      <td>transition</td>\n",
       "      <td>generalization</td>\n",
       "      <td>target</td>\n",
       "      <td>definition</td>\n",
       "      <td>rule</td>\n",
       "      <td>size</td>\n",
       "      <td>energy</td>\n",
       "      <td>training_set</td>\n",
       "      <td>represent</td>\n",
       "      <td>independent</td>\n",
       "      <td>signal</td>\n",
       "      <td>optimal</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>matrix</td>\n",
       "      <td>center</td>\n",
       "      <td>brain</td>\n",
       "      <td>state</td>\n",
       "      <td>location</td>\n",
       "      <td>log</td>\n",
       "      <td>surface</td>\n",
       "      <td>current</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>visual</td>\n",
       "      <td>assume</td>\n",
       "      <td>line</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>mapping</td>\n",
       "      <td>database</td>\n",
       "      <td>processing</td>\n",
       "      <td>linear</td>\n",
       "      <td>synapse</td>\n",
       "      <td>noise</td>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>time_series</td>\n",
       "      <td>neuron</td>\n",
       "      <td>rate</td>\n",
       "      <td>speech_recognition</td>\n",
       "      <td>experiment</td>\n",
       "      <td>component</td>\n",
       "      <td>scale</td>\n",
       "      <td>reward</td>\n",
       "      <td>hidden</td>\n",
       "      <td>hand</td>\n",
       "      <td>bounded</td>\n",
       "      <td>theory</td>\n",
       "      <td>search</td>\n",
       "      <td>region</td>\n",
       "      <td>error_rate</td>\n",
       "      <td>connectionist</td>\n",
       "      <td>distribution</td>\n",
       "      <td>digital</td>\n",
       "      <td>experiment</td>\n",
       "      <td>search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>operator</td>\n",
       "      <td>region</td>\n",
       "      <td>pattern</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>feature</td>\n",
       "      <td>em</td>\n",
       "      <td>contour</td>\n",
       "      <td>robot</td>\n",
       "      <td>learned</td>\n",
       "      <td>change</td>\n",
       "      <td>condition</td>\n",
       "      <td>limit</td>\n",
       "      <td>coding</td>\n",
       "      <td>neighborhood</td>\n",
       "      <td>probability</td>\n",
       "      <td>type</td>\n",
       "      <td>eeg</td>\n",
       "      <td>array</td>\n",
       "      <td>estimate</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>gaussian</td>\n",
       "      <td>correlation</td>\n",
       "      <td>phase</td>\n",
       "      <td>trained</td>\n",
       "      <td>condition</td>\n",
       "      <td>step</td>\n",
       "      <td>scene</td>\n",
       "      <td>td</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>arm</td>\n",
       "      <td>define</td>\n",
       "      <td>curve</td>\n",
       "      <td>stored</td>\n",
       "      <td>optimization</td>\n",
       "      <td>decision</td>\n",
       "      <td>part</td>\n",
       "      <td>separation</td>\n",
       "      <td>transistor</td>\n",
       "      <td>loss</td>\n",
       "      <td>technique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>technique</td>\n",
       "      <td>effect</td>\n",
       "      <td>current</td>\n",
       "      <td>digit</td>\n",
       "      <td>structure</td>\n",
       "      <td>posterior</td>\n",
       "      <td>vision</td>\n",
       "      <td>agent</td>\n",
       "      <td>prediction</td>\n",
       "      <td>eye</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>attractor</td>\n",
       "      <td>solution</td>\n",
       "      <td>matching</td>\n",
       "      <td>labeled</td>\n",
       "      <td>role</td>\n",
       "      <td>entropy</td>\n",
       "      <td>pulse</td>\n",
       "      <td>expected</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>sample</td>\n",
       "      <td>property</td>\n",
       "      <td>oscillator</td>\n",
       "      <td>window</td>\n",
       "      <td>pair</td>\n",
       "      <td>variance</td>\n",
       "      <td>location</td>\n",
       "      <td>trial</td>\n",
       "      <td>training_set</td>\n",
       "      <td>coordinate</td>\n",
       "      <td>xi</td>\n",
       "      <td>noise</td>\n",
       "      <td>temperature</td>\n",
       "      <td>matrix</td>\n",
       "      <td>nearest_neighbor</td>\n",
       "      <td>step</td>\n",
       "      <td>basis</td>\n",
       "      <td>hardware</td>\n",
       "      <td>generalization</td>\n",
       "      <td>type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>basis_function</td>\n",
       "      <td>connection</td>\n",
       "      <td>neuronal</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>item</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>part</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>epoch</td>\n",
       "      <td>head</td>\n",
       "      <td>constant</td>\n",
       "      <td>eigenvalue</td>\n",
       "      <td>energy</td>\n",
       "      <td>manifold</td>\n",
       "      <td>label</td>\n",
       "      <td>representing</td>\n",
       "      <td>change</td>\n",
       "      <td>implemented</td>\n",
       "      <td>distribution</td>\n",
       "      <td>factor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>dimension</td>\n",
       "      <td>area</td>\n",
       "      <td>fig</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>response</td>\n",
       "      <td>estimation</td>\n",
       "      <td>texture</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>language</td>\n",
       "      <td>sensory</td>\n",
       "      <td>property</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>element</td>\n",
       "      <td>find</td>\n",
       "      <td>mlp</td>\n",
       "      <td>local</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>bit</td>\n",
       "      <td>bias</td>\n",
       "      <td>schedule</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Topic 1          Topic 2     Topic 3             Topic 4  \\\n",
       "Term1           linear             cell      neuron                word   \n",
       "Term2        nonlinear         response        cell         recognition   \n",
       "Term3           vector         stimulus       spike              speech   \n",
       "Term4    approximation  receptive_field    synaptic            sequence   \n",
       "Term5       prediction           visual    activity            training   \n",
       "Term6         estimate         cortical      firing           character   \n",
       "Term7       estimation          spatial      neural             context   \n",
       "Term8            local           cortex    synapsis                 hmm   \n",
       "Term9      dimensional      orientation    response              letter   \n",
       "Term10      regression         activity   frequency               frame   \n",
       "Term11          kernel         contrast       et_al             speaker   \n",
       "Term12             rbf          pattern   threshold             feature   \n",
       "Term13          matrix           center       brain               state   \n",
       "Term14     time_series           neuron        rate  speech_recognition   \n",
       "Term15        operator           region     pattern             phoneme   \n",
       "Term16        gaussian      correlation       phase             trained   \n",
       "Term17       technique           effect     current               digit   \n",
       "Term18          sample         property  oscillator              window   \n",
       "Term19  basis_function       connection    neuronal        segmentation   \n",
       "Term20       dimension             area         fig            acoustic   \n",
       "\n",
       "               Topic 5        Topic 6         Topic 7                 Topic 8  \\\n",
       "Term1   representation   distribution           image                   state   \n",
       "Term2             task    probability          object                 control   \n",
       "Term3            human          prior         feature                  action   \n",
       "Term4           target       variable           pixel                    step   \n",
       "Term5          subject       gaussian            view                  policy   \n",
       "Term6       similarity        density            face              controller   \n",
       "Term7            trial        mixture          visual  reinforcement_learning   \n",
       "Term8           effect       bayesian          region             environment   \n",
       "Term9            study       estimate            edge                 optimal   \n",
       "Term10          theory     likelihood           shape                    task   \n",
       "Term11             cue  approximation     recognition                    goal   \n",
       "Term12       component         sample  representation              transition   \n",
       "Term13        location            log         surface                 current   \n",
       "Term14      experiment      component           scale                  reward   \n",
       "Term15         feature             em         contour                   robot   \n",
       "Term16       condition           step           scene                      td   \n",
       "Term17       structure      posterior          vision                   agent   \n",
       "Term18            pair       variance        location                   trial   \n",
       "Term19            item  probabilistic            part                 dynamic   \n",
       "Term20        response     estimation         texture                adaptive   \n",
       "\n",
       "                 Topic 9    Topic 10     Topic 11     Topic 12     Topic 13  \\\n",
       "Term1           training      motion        bound     equation       vector   \n",
       "Term2        hidden_unit   direction      theorem      dynamic       memory   \n",
       "Term3               rule         map        class         rate         code   \n",
       "Term4                net    position        proof  convergence          bit   \n",
       "Term5               task       field       theory           eq      pattern   \n",
       "Term6            trained     control    threshold     solution     capacity   \n",
       "Term7       architecture    velocity       linear     gradient        state   \n",
       "Term8          recurrent    movement         size       matrix       matrix   \n",
       "Term9              learn    location      defined       vector       binary   \n",
       "Term10  back_propagation  trajectory   complexity        state  probability   \n",
       "Term11            expert       motor  probability  fixed_point       random   \n",
       "Term12    generalization      target   definition         rule         size   \n",
       "Term13      hidden_layer      visual       assume         line     hopfield   \n",
       "Term14            hidden        hand      bounded       theory       search   \n",
       "Term15           learned      change    condition        limit       coding   \n",
       "Term16   backpropagation         arm       define        curve       stored   \n",
       "Term17        prediction         eye   polynomial    attractor     solution   \n",
       "Term18      training_set  coordinate           xi        noise  temperature   \n",
       "Term19             epoch        head     constant   eigenvalue       energy   \n",
       "Term20          language     sensory     property    symmetric      element   \n",
       "\n",
       "              Topic 14          Topic 15        Topic 16      Topic 17  \\\n",
       "Term1       constraint              node            unit        signal   \n",
       "Term2         distance             class           layer         noise   \n",
       "Term3          cluster    classification         pattern        filter   \n",
       "Term4         solution        classifier      activation        source   \n",
       "Term5   transformation          training      connection       channel   \n",
       "Term6        structure              tree       structure     component   \n",
       "Term7              map           pattern  representation     frequency   \n",
       "Term8       clustering           feature          module   correlation   \n",
       "Term9           vector            sample    architecture           pca   \n",
       "Term10           local              test           level           ica   \n",
       "Term11           graph          accuracy        activity         phase   \n",
       "Term12          energy      training_set       represent   independent   \n",
       "Term13         mapping          database      processing        linear   \n",
       "Term14          region        error_rate   connectionist  distribution   \n",
       "Term15    neighborhood       probability            type           eeg   \n",
       "Term16    optimization          decision            part    separation   \n",
       "Term17        matching           labeled            role       entropy   \n",
       "Term18          matrix  nearest_neighbor            step         basis   \n",
       "Term19        manifold             label    representing        change   \n",
       "Term20            find               mlp           local     amplitude   \n",
       "\n",
       "              Topic 18        Topic 19     Topic 20  \n",
       "Term1          circuit        training         rate  \n",
       "Term2             chip      prediction  application  \n",
       "Term3          current    training_set         user  \n",
       "Term4           neuron            test        table  \n",
       "Term5           analog         average     computer  \n",
       "Term6          voltage       selection   experiment  \n",
       "Term7           neural          kernel    processor  \n",
       "Term8   implementation         machine          run  \n",
       "Term9             gain            size        block  \n",
       "Term10          device        ensemble      program  \n",
       "Term11          design           query        speed  \n",
       "Term12          signal         optimal         path  \n",
       "Term13         synapse           noise         size  \n",
       "Term14         digital      experiment       search  \n",
       "Term15           array        estimate      machine  \n",
       "Term16      transistor            loss    technique  \n",
       "Term17           pulse        expected         call  \n",
       "Term18        hardware  generalization         type  \n",
       "Term19     implemented    distribution       factor  \n",
       "Term20             bit            bias     schedule  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build term topic dataframe\n",
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns=['Term'+str(i) for i in range(1,21)], \n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>linear, nonlinear, vector, approximation, prediction, estimate, estimation, local, dimensional, regression, kernel, rbf, matrix, time_series, operator, gaussian, technique, sample, basis_function, dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>cell, response, stimulus, receptive_field, visual, cortical, spatial, cortex, orientation, activity, contrast, pattern, center, neuron, region, correlation, effect, property, connection, area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>neuron, cell, spike, synaptic, activity, firing, neural, synapsis, response, frequency, et_al, threshold, brain, rate, pattern, phase, current, oscillator, neuronal, fig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>word, recognition, speech, sequence, training, character, context, hmm, letter, frame, speaker, feature, state, speech_recognition, phoneme, trained, digit, window, segmentation, acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>representation, task, human, target, subject, similarity, trial, effect, study, theory, cue, component, location, experiment, feature, condition, structure, pair, item, response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>distribution, probability, prior, variable, gaussian, density, mixture, bayesian, estimate, likelihood, approximation, sample, log, component, em, step, posterior, variance, probabilistic, estimation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>image, object, feature, pixel, view, face, visual, region, edge, shape, recognition, representation, surface, scale, contour, scene, vision, location, part, texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>state, control, action, step, policy, controller, reinforcement_learning, environment, optimal, task, goal, transition, current, reward, robot, td, agent, trial, dynamic, adaptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>training, hidden_unit, rule, net, task, trained, architecture, recurrent, learn, back_propagation, expert, generalization, hidden_layer, hidden, learned, backpropagation, prediction, training_set, epoch, language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>motion, direction, map, position, field, control, velocity, movement, location, trajectory, motor, target, visual, hand, change, arm, eye, coordinate, head, sensory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>bound, theorem, class, proof, theory, threshold, linear, size, defined, complexity, probability, definition, assume, bounded, condition, define, polynomial, xi, constant, property</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>equation, dynamic, rate, convergence, eq, solution, gradient, matrix, vector, state, fixed_point, rule, line, theory, limit, curve, attractor, noise, eigenvalue, symmetric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>vector, memory, code, bit, pattern, capacity, state, matrix, binary, probability, random, size, hopfield, search, coding, stored, solution, temperature, energy, element</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>constraint, distance, cluster, solution, transformation, structure, map, clustering, vector, local, graph, energy, mapping, region, neighborhood, optimization, matching, matrix, manifold, find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>node, class, classification, classifier, training, tree, pattern, feature, sample, test, accuracy, training_set, database, error_rate, probability, decision, labeled, nearest_neighbor, label, mlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>unit, layer, pattern, activation, connection, structure, representation, module, architecture, level, activity, represent, processing, connectionist, type, part, role, step, representing, local</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>signal, noise, filter, source, channel, component, frequency, correlation, pca, ica, phase, independent, linear, distribution, eeg, separation, entropy, basis, change, amplitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>circuit, chip, current, neuron, analog, voltage, neural, implementation, gain, device, design, signal, synapse, digital, array, transistor, pulse, hardware, implemented, bit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>training, prediction, training_set, test, average, selection, kernel, machine, size, ensemble, query, optimal, noise, experiment, estimate, loss, expected, generalization, distribution, bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>rate, application, user, table, computer, experiment, processor, run, block, program, speed, path, size, search, machine, technique, call, type, factor, schedule</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                              Terms per Topic\n",
       "Topic1   linear, nonlinear, vector, approximation, prediction, estimate, estimation, local, dimensional, regression, kernel, rbf, matrix, time_series, operator, gaussian, technique, sample, basis_function, dimension      \n",
       "Topic2   cell, response, stimulus, receptive_field, visual, cortical, spatial, cortex, orientation, activity, contrast, pattern, center, neuron, region, correlation, effect, property, connection, area                     \n",
       "Topic3   neuron, cell, spike, synaptic, activity, firing, neural, synapsis, response, frequency, et_al, threshold, brain, rate, pattern, phase, current, oscillator, neuronal, fig                                           \n",
       "Topic4   word, recognition, speech, sequence, training, character, context, hmm, letter, frame, speaker, feature, state, speech_recognition, phoneme, trained, digit, window, segmentation, acoustic                         \n",
       "Topic5   representation, task, human, target, subject, similarity, trial, effect, study, theory, cue, component, location, experiment, feature, condition, structure, pair, item, response                                   \n",
       "Topic6   distribution, probability, prior, variable, gaussian, density, mixture, bayesian, estimate, likelihood, approximation, sample, log, component, em, step, posterior, variance, probabilistic, estimation             \n",
       "Topic7   image, object, feature, pixel, view, face, visual, region, edge, shape, recognition, representation, surface, scale, contour, scene, vision, location, part, texture                                                \n",
       "Topic8   state, control, action, step, policy, controller, reinforcement_learning, environment, optimal, task, goal, transition, current, reward, robot, td, agent, trial, dynamic, adaptive                                 \n",
       "Topic9   training, hidden_unit, rule, net, task, trained, architecture, recurrent, learn, back_propagation, expert, generalization, hidden_layer, hidden, learned, backpropagation, prediction, training_set, epoch, language\n",
       "Topic10  motion, direction, map, position, field, control, velocity, movement, location, trajectory, motor, target, visual, hand, change, arm, eye, coordinate, head, sensory                                                \n",
       "Topic11  bound, theorem, class, proof, theory, threshold, linear, size, defined, complexity, probability, definition, assume, bounded, condition, define, polynomial, xi, constant, property                                 \n",
       "Topic12  equation, dynamic, rate, convergence, eq, solution, gradient, matrix, vector, state, fixed_point, rule, line, theory, limit, curve, attractor, noise, eigenvalue, symmetric                                         \n",
       "Topic13  vector, memory, code, bit, pattern, capacity, state, matrix, binary, probability, random, size, hopfield, search, coding, stored, solution, temperature, energy, element                                            \n",
       "Topic14  constraint, distance, cluster, solution, transformation, structure, map, clustering, vector, local, graph, energy, mapping, region, neighborhood, optimization, matching, matrix, manifold, find                    \n",
       "Topic15  node, class, classification, classifier, training, tree, pattern, feature, sample, test, accuracy, training_set, database, error_rate, probability, decision, labeled, nearest_neighbor, label, mlp                 \n",
       "Topic16  unit, layer, pattern, activation, connection, structure, representation, module, architecture, level, activity, represent, processing, connectionist, type, part, role, step, representing, local                   \n",
       "Topic17  signal, noise, filter, source, channel, component, frequency, correlation, pca, ica, phase, independent, linear, distribution, eeg, separation, entropy, basis, change, amplitude                                   \n",
       "Topic18  circuit, chip, current, neuron, analog, voltage, neural, implementation, gain, device, design, signal, synapse, digital, array, transistor, pulse, hardware, implemented, bit                                       \n",
       "Topic19  training, prediction, training_set, test, average, selection, kernel, machine, size, ensemble, query, optimal, noise, experiment, estimate, loss, expected, generalization, distribution, bias                      \n",
       "Topic20  rate, application, user, table, computer, experiment, processor, run, block, program, speed, path, size, search, machine, technique, call, type, factor, schedule                                                   "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create topic term dataframe: each topic represented in a row with terms of topic\n",
    "# represented as comma-separated string\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) \n",
    "                              for topic in topics], \n",
    "                         columns=['Terms per Topic'], \n",
    "                         index=['Topic'+str(t) for t in range (1, best_lda_model.num_topics+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpreting Topic Model Results\n",
    "tm_results = best_lda_model[bow_corpus]\n",
    "\n",
    "# get most dominant topic per research paper\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in tm_results]\n",
    "corpus_topics[:5]\n",
    "\n",
    "# construct master dataframe that holds base statistics\n",
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(papers))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Paper'] = papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dominant Topics Distribution Across Corpus\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg(\n",
    "    {'Dominant Topic': {'Doc Count': np.size, '% Total Docs': np.size }})\n",
    "\n",
    "topic_stats_df = topic_stats_df['Dominant Topic'].reset_index()\n",
    "topic_stats_df['% Total Docs'] = topic_stats_df['% Total Docs'].\n",
    "apply(lambda row: round((row*100) / len(papers), 2))\n",
    "topic_stats_df['Topic Desc'] = [topics_df.iloc[t]['Terms per Topic'] \n",
    "    for t in range(len(topic_stats_df))]\n",
    "topic_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dominant Topics in Specific Research Papers\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "(corpus_topic_df[corpus_topic_df['Document'].\n",
    "    isin([681, 9, 392, 1622, 17, 906, 996, 503, 13, 733])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relevant Research Papers per Topic Based on Dominance\n",
    "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set:\n",
    "    (topic_set.sort_values(by=['Contribution %'], ascending=False).iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predicting Topics for New Research Papers\n",
    "import glob\n",
    "# papers manually downloaded from NIPS 16\n",
    "# https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
    "\n",
    "new_paper_files = glob.glob('nips16*.txt')\n",
    "new_papers = []\n",
    "for fn in new_paper_files:\n",
    "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "        data = f.read()\n",
    "        new_papers.append(data)\n",
    "print('Total New Papers', len(new_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build text wrangling and feature engineering pipeline\n",
    "def text_preprocessing_pipeline(documents, normalizer_fn, bigram_model):\n",
    "    norm_docs = normalizer_fn(documents)\n",
    "    norm_docs_bigrams = bigram_model[norm_docs]\n",
    "    return norm_docs_bigrams\n",
    "\n",
    "def bow_features_pipeline(tokenized_docs, dictionary):\n",
    "    paper_bow_features = [dictionary.doc2bow(text) \n",
    "        for text in tokenized_docs]\n",
    "    return paper_bow_features\n",
    "\n",
    "norm_new_papers = text_preprocessing_pipeline(documents=new_papers, normalizer_fn=normalize_corpus, bigram_model=bigram_model)\n",
    "\n",
    "norm_bow_features = bow_features_pipeline(tokenized_docs=norm_new_papers, dictionary=dictionary)\n",
    "\n",
    "print(norm_new_papers[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_bow_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build generic fuction to extract top N topics from any research paper using trained model\n",
    "def get_topic_predictions(topic_model, corpus, topn=3):\n",
    "    topic_predictions = topic_model[corpus]\n",
    "    best_topics = [[(topic, round(wt,3)) \n",
    "                        for topic, wt in sorted(topic_predictions[i],\n",
    "                        key=lamda row: -row[1])[:topn]]\n",
    "                            for i in range(len(topic_predictions))]\n",
    "    return best_topics\n",
    "\n",
    "# putting the function in action\n",
    "topic_preds = get_topic_predictions(topic_model=best_lda_model, corpus=norm_bow_features, topn=2)\n",
    "topic_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review results for each paper\n",
    "results_df = pd.DataFrame()\n",
    "results_df['Papers'] = range(1, len(new_papers)+1)\n",
    "results_df['Dominant Topics'] = [[topic_num+1 for topic_num, wt in term] \n",
    "                                    for item in topic_preds]\n",
    "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
    "stack().reset_index(level=1, drop=True)\n",
    "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
    "results_df['Contribution %'] = [topic_wt for topic_list in [[round(wt*100,2) for topic_num, wt in item] for item in topic_preds] for topic_wt in topic_list]\n",
    "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic'] for t in results_df['Dominant Topics'].values]\n",
    "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Representation with Feature Engineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=20, max_df=0.6, ngram_range=(1,2), token_pattern=None, tokenizer=lambda doc: doc, preprocessor=lambda doc: doc)\n",
    "cv_features = cv.fit_transform(norm_papers)\n",
    "cv_features.shape\n",
    "\n",
    "# validating vocabulary size\n",
    "vocabulary = np.array(cv.get_feature_names())\n",
    "print('Total Vocabulary Size', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Latent Semantic Indexing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "TOTAL_TOPICS=20\n",
    "lsi_model = TruncatedSVD(n_components=TOTAL_TOPICS, n_iter=500, random_state=42)\n",
    "document_topics = lsi_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms = lsi_model.components_\n",
    "topic_terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reuse previously implemented code to display topics and terms\n",
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([topic_terms[row, columns] for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weight[n]\n",
    "    term_weights = sorted([(t,w) for t, w in zip(terms, weights)],\n",
    "        key = lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt,3)))\n",
    "        else:\n",
    "            print('Direction 1:', d1)\n",
    "            print('-'*50)\n",
    "            print('Direction 2:', d2)\n",
    "            print('-'*50)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract key topics for specific research papers\n",
    "dt_df = pd.DataFrame(np.round(document_topics,3), \n",
    "            columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "\n",
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(dt_df.columns[np.argsort(-np.absolute(dt_df.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Latent Dirichlet Allocation\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=TOTAL_TOPICS, max_iter=500, max_doc_update_iter=50, learning_method='online', match_size=1740, learning_offset=50., random_state=42, n_jobs=16)\n",
    "document_topics = lda_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain topic-term matrix\n",
    "# build dataframe from it to showcase topics and terms\n",
    "topic_terms = lda_model.components_\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topics = [', '.join(topic) for topic in topic_keyterms]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame(topics, column=['Terms per Topic'], index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view research papers having max contribution of each of the 20 topics\n",
    "dt_df = pd.DataFrame(document_topics, columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "pd.options.display.float_format = '{:, .5f}'.format\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "max_contrib_topics = dt_df.max(axis=0)\n",
    "dominant_topics = max_contrib_topics.index\n",
    "contrib_perc = max_contrib_topics.values\n",
    "document_numbers = [dt_df[dt_df[t] == max_contrib_topics.loc[t]].index[0]\n",
    "                        for t in dominant_topics]\n",
    "documents = [papers[i] for i in document_numbers]\n",
    "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, 'Contribution %': contrib_perc,\n",
    "                            'Paper Num': document_numbers, 'Topic': topics_df['Terms per Topic'],\n",
    "                            'Paper Name': documents})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Non-Negative Matrix Factorization\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=TOTAL_TOPICS, solver='cd', max_iter=500, random_state=42, alpha=.1, l1_ratio=.85)\n",
    "document_topics = nmf_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms = nmf_model.components_\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:,:top_terms]\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topics = [', '.join(topic) for topic in topic_keyterms]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame(topics, columns=['Terms per Topic'],\n",
    "                            index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine dominance of topics in research papers by absolute scores\n",
    "pd.options.display.float_format = '{:, .3f}'.format\n",
    "dt_df = pd.DataFrame(document_topics, columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "dt_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine most relevant paper for each topic based on topic dominance scores\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "max_score_topics = dt_df.max(axis=0)\n",
    "dominant_topics = max_score_topics.index\n",
    "term_score = max_score_topics.values\n",
    "document_numbers = [dt_df[dt_df[t] == max_score_topics.loc[t]].index[0]\n",
    "                        for t in dominant_topics]\n",
    "documents = [papers[i] for i in document_numbers]\n",
    "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, 'Max Score': term_score,\n",
    "                            'Paper Num': document_numbers, 'Topic': topics_df['Terms per Topic'],\n",
    "                            'Paper Name': documents})\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}