{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Summarization and Topic Models\n",
    "* Text Summarization and Information Extraction\n",
    "* Important Concepts\n",
    "* Keyphrase Extractions\n",
    "    1. Collocations\n",
    "    2. Weighted Tag-Based Phrase Extraction\n",
    "* Topic Modeling on Research Papers\n",
    "    1. The Main Objective\n",
    "    2. Data Retrieval\n",
    "    3. Load and View Dataset\n",
    "    4. Basic Text Wrangling\n",
    "* Topic Models with Gensim\n",
    "    1. Text Representation with Feature Engineering\n",
    "    2. Latent Semantic Indexing\n",
    "    3. Implementing LSI Topic Models from Scratch\n",
    "    4. Latent Dirichlet Allocation\n",
    "    5. LDA Models with MALLET\n",
    "    6. LDA Tuning: Finding the Optimal Number of Topics\n",
    "    7. Interpreting Topic Model Results\n",
    "    8. Predicting Topics for New Research Papers\n",
    "* Topic Models with Scikit-Learn\n",
    "    1. Text Representation with Feature Engineering\n",
    "    2. Latent Semantic Indexing\n",
    "    3. Latent Dirichlet Allocation\n",
    "    4. Non-Negative Matrix Factorization\n",
    "    5. Predicting Topics for New Research Papers\n",
    "    6. Visualizing Topic Models\n",
    "* Automated Document Summarization\n",
    "    1. Text Wrangling\n",
    "    2. Text Representation with Feature Engineering\n",
    "    3. Latent Semantic Analysis\n",
    "    4. TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading packages\n",
    "\n",
    "# if spacy doesn't run\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "\n",
    "# if nltk error\n",
    "#import nltk\n",
    "#nltk.download('all')\n",
    "\n",
    "# import gensim\n",
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure ML path\n",
    "path_to_users = '/mnt/batch/tasks/shared/LS_root/mounts/clusters/bellepracticevm/code/Users'\n",
    "path_to_nlp = path_to_users + '/LearningCode/NLP_Learning'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top k singular values and return corresponding U, S, & V matrices\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    u,s,vt = svds(matrix, k=singular_count)\n",
    "    return u,s,vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyphrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ] \n",
      " alice adventures wonderland lewis carroll\n"
     ]
    }
   ],
   "source": [
    "## Collocations\n",
    "from nltk.corpus import gutenberg\n",
    "import text_normalizer as tn\n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "\n",
    "# load corpus\n",
    "alice = gutenberg.sents(fileids='carroll-alice.txt')\n",
    "alice = [' '.join(ts) for ts in alice]\n",
    "norm_alice = list(filter(None,\n",
    "                         tn.normalize_corpus(alice, text_lemmatization=False)))\n",
    "\n",
    "# print and compare first line\n",
    "print(alice[0], '\\n', norm_alice[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (2, 3, 4)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_ngrams(sequence, n):\n",
    "    return list(\n",
    "            zip(*(sequence[index:]\n",
    "                  for index in range(n))))\n",
    "\n",
    "# test function\n",
    "compute_ngrams([1,2,3,4], 2) # bi-grams\n",
    "compute_ngrams([1,2,3,4], 3) # tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to flatten corpus into one big string of text\n",
    "def flatten_corpus(corpus):\n",
    "    return ' '.join([document.strip()\n",
    "                    for document in corpus])\n",
    "\n",
    "# get top n-grams for corpus of text\n",
    "def get_top_ngrams(corpus, ngram_val=1, limit=5):\n",
    "    corpus = flatten_corpus(corpus)\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "    \n",
    "    ngrams = compute_ngrams(tokens, ngram_val)\n",
    "    ngrams_freq_dist = nltk.FreqDist(ngrams)\n",
    "    sorted_ngrams_fd = sorted(ngrams_freq_dist.items(),\n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    sorted_ngrams = sorted_ngrams_fd[0:limit]\n",
    "    sorted_ngrams = [(' '.join(text), freq)\n",
    "                     for text, freq in sorted_ngrams]\n",
    "    return sorted_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said alice', 123),\n",
       " ('mock turtle', 56),\n",
       " ('march hare', 31),\n",
       " ('said king', 29),\n",
       " ('thought alice', 26),\n",
       " ('white rabbit', 22),\n",
       " ('said hatter', 22),\n",
       " ('said mock', 20),\n",
       " ('said caterpillar', 18),\n",
       " ('said gryphon', 18)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 bigrams\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=2, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said mock turtle', 20),\n",
       " ('said march hare', 10),\n",
       " ('poor little thing', 6),\n",
       " ('little golden key', 5),\n",
       " ('certainly said alice', 5),\n",
       " ('white kid gloves', 5),\n",
       " ('march hare said', 5),\n",
       " ('mock turtle said', 5),\n",
       " ('know said alice', 4),\n",
       " ('might well say', 4)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 trigrams\n",
    "get_top_ngrams(corpus=norm_alice, ngram_val=3, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nltk.collocations.BigramCollocationFinder at 0x7f4eb428ba90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use NLTK's collocation finders\n",
    "# bigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "\n",
    "finder = BigramCollocationFinder.from_documents([item.split() for item in norm_alice])\n",
    "finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'alice'),\n",
       " ('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'king'),\n",
       " ('thought', 'alice'),\n",
       " ('said', 'hatter'),\n",
       " ('white', 'rabbit'),\n",
       " ('said', 'mock'),\n",
       " ('said', 'caterpillar'),\n",
       " ('said', 'gryphon')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_measures = BigramAssocMeasures()\n",
    "\n",
    "# raw frequencies\n",
    "finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abide', 'figures'),\n",
       " ('acceptance', 'elegant'),\n",
       " ('accounting', 'tastes'),\n",
       " ('accustomed', 'usurpation'),\n",
       " ('act', 'crawling'),\n",
       " ('adjourn', 'immediate'),\n",
       " ('adoption', 'energetic'),\n",
       " ('affair', 'trusts'),\n",
       " ('agony', 'terror'),\n",
       " ('alarmed', 'proposal')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.collocations import TrigramAssocMeasures\n",
    "\n",
    "finder = TrigramCollocationFinder.from_documents([item.split() for item in norm_alice])\n",
    "\n",
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('said', 'march', 'hare'),\n",
       " ('poor', 'little', 'thing'),\n",
       " ('little', 'golden', 'key'),\n",
       " ('march', 'hare', 'said'),\n",
       " ('mock', 'turtle', 'said'),\n",
       " ('white', 'kid', 'gloves'),\n",
       " ('beau', 'ootiful', 'soo'),\n",
       " ('certainly', 'said', 'alice'),\n",
       " ('might', 'well', 'say')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw frequencies\n",
    "finder.nbest(trigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('apple', 'roast', 'turkey'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherry', 'tart', 'custard'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pointwise mutual information\n",
    "finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Weighted Tag-Based Phrase Extraction\n",
    "data = open('data/elephants.txt', 'r+').readlines()\n",
    "sentences = nltk.sent_tokenize(data[0])\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are large mammals of the family Elephantidae and the order Proboscidea.',\n",
       " 'Three species are currently recognised: the African bush elephant (Loxodonta africana), the African forest elephant (L. cyclotis), and the Asian elephant (Elephas maximus).',\n",
       " 'Elephants are scattered throughout sub-Saharan Africa, South Asia, and Southeast Asia.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the first three lines\n",
    "sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elephants are large mammals of the family Elephantidae and the order Proboscidea',\n",
       " 'Three species are currently recognised the African bush elephant Loxodonta africana the African forest elephant L cyclotis and the Asian elephant Elephas maximus',\n",
       " 'Elephants are scattered throughout subSaharan Africa South Asia and Southeast Asia']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_sentences = tn.normalize_corpus(sentences, text_lower_case=False, text_stemming=False,\n",
    "                                     text_lemmatization=False, stopword_removal=False)\n",
    "norm_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def get_chunks(sentences, grammar=r'NP: {<DT>? <JJ>* <NN.*>+}', stopword_list=stopwords):\n",
    "    all_chunks = []\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tagged_sents = [nltk.pos_tag(nltk.word_tokenize(sentence))]\n",
    "        chunks = [chunker.parse(tagged_sent)\n",
    "                     for tagged_sent in tagged_sents]\n",
    "        wtc_sents = [nltk.chunk.tree2conlltags(chunk)\n",
    "                        for chunk in chunks]\n",
    "        flattened_chunks = list(itertools.chain.from_iterable(wtc_sent for wtc_sent in wtc_sents))\n",
    "        valid_chunks_tagged = [(status, [wtc for wtc in chunk])\n",
    "                                    for status, chunk in itertools.groupby(flattened_chunks,\n",
    "                                                      lambda word_pos_chunk: \n",
    "                                                      word_pos_chunk[2] != 'O')]\n",
    "        valid_chunks = [' '.join(word.lower()\n",
    "                                 for word, tag, chunk in wtc_group\n",
    "                                     if word.lower() not in stopword_list)\n",
    "                                        for status, wtc_group in valid_chunks_tagged if status]\n",
    "        all_chunks.append(valid_chunks)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elephants', 'large mammals', 'family elephantidae', 'order proboscidea'],\n",
       " ['species',\n",
       "  'african bush elephant loxodonta',\n",
       "  'african forest elephant l cyclotis',\n",
       "  'asian elephant elephas maximus'],\n",
       " ['elephants', 'subsaharan africa south asia', 'southeast asia'],\n",
       " ['elephantidae',\n",
       "  'family',\n",
       "  'order proboscidea',\n",
       "  'extinct members',\n",
       "  'order',\n",
       "  'deinotheres gomphotheres mammoths',\n",
       "  'mastodons'],\n",
       " ['elephants',\n",
       "  'several distinctive features',\n",
       "  'long trunk',\n",
       "  'proboscis',\n",
       "  'many purposes',\n",
       "  'water',\n",
       "  'grasping objects'],\n",
       " ['incisors', 'tusks', 'weapons', 'tools', 'objects'],\n",
       " ['elephants', 'flaps', 'body temperature'],\n",
       " ['pillarlike legs', 'great weight'],\n",
       " ['african elephants',\n",
       "  'ears',\n",
       "  'backs',\n",
       "  'asian elephants',\n",
       "  'ears',\n",
       "  'convex',\n",
       "  'level backs'],\n",
       " ['elephants', 'different habitats', 'savannahs forests deserts', 'marshes'],\n",
       " ['water'],\n",
       " ['keystone species', 'impact', 'environments'],\n",
       " ['animals',\n",
       "  'distance',\n",
       "  'elephants',\n",
       "  'predators',\n",
       "  'lions tigers hyenas',\n",
       "  'wild dogs',\n",
       "  'young elephants',\n",
       "  'calves'],\n",
       " ['elephants', 'fissionfusion society', 'multiple family groups'],\n",
       " ['females cows',\n",
       "  'family groups',\n",
       "  'female',\n",
       "  'calves',\n",
       "  'several related females'],\n",
       " ['groups', 'individual known', 'matriarch', 'cow'],\n",
       " ['males bulls', 'family groups', 'males'],\n",
       " ['adult',\n",
       "  'family groups',\n",
       "  'mate',\n",
       "  'enter state',\n",
       "  'increased testosterone',\n",
       "  'aggression',\n",
       "  'musth',\n",
       "  'dominance',\n",
       "  'reproductive success'],\n",
       " ['calves', 'centre', 'attention', 'family groups', 'mothers', 'years'],\n",
       " ['elephants', 'years', 'wild'],\n",
       " ['touch sight smell',\n",
       "  'sound elephants',\n",
       "  'infrasound',\n",
       "  'seismic communication',\n",
       "  'long distances'],\n",
       " ['elephant intelligence', 'primates', 'cetaceans'],\n",
       " ['selfawareness', 'dead individuals', 'kind'],\n",
       " ['african elephants',\n",
       "  'international union',\n",
       "  'conservation',\n",
       "  'nature iucn',\n",
       "  'asian elephant'],\n",
       " ['threats', 'populations', 'ivory trade', 'animals', 'ivory tusks'],\n",
       " ['threats', 'elephants', 'habitat destruction', 'conflicts', 'local people'],\n",
       " ['elephants', 'animals', 'asia'],\n",
       " ['past', 'war today', 'display', 'zoos', 'entertainment', 'circuses'],\n",
       " ['elephants', 'art folklore religion literature', 'popular culture']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = get_chunks(norm_sentences)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "def get_tfidf_weighted_keyphrases(sentences, grammar=r'NP: {<DT>? <JJ>* <NN.*>+}', top_n=10):\n",
    "    valid_chunks = get_chunks(sentences, grammar=grammar)\n",
    "    \n",
    "    dictionary = corpora.Dictionary(valid_chunks)\n",
    "    corpus = [dictionary.doc2bow(chunk) for chunk in valid_chunks]\n",
    "    \n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    weighted_phrases = {dictionary.get(idx): value for doc in corpus_tfidf for idx, value in doc}\n",
    "    weighted_phrases = sorted(weighted_phrases.items(),\n",
    "                              key=itemgetter(1), reverse=True)\n",
    "    weighted_phrases = [(term, round(wt,3)) for term, wt in weighted_phrases]\n",
    "    \n",
    "    return weighted_phrases[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water', 1.0),\n",
       " ('asia', 0.807),\n",
       " ('wild', 0.764),\n",
       " ('great weight', 0.707),\n",
       " ('pillarlike legs', 0.707),\n",
       " ('southeast asia', 0.693),\n",
       " ('subsaharan africa south asia', 0.693),\n",
       " ('body temperature', 0.693),\n",
       " ('flaps', 0.693),\n",
       " ('fissionfusion society', 0.693),\n",
       " ('multiple family groups', 0.693),\n",
       " ('art folklore religion literature', 0.693),\n",
       " ('popular culture', 0.693),\n",
       " ('ears', 0.681),\n",
       " ('males', 0.653),\n",
       " ('males bulls', 0.653),\n",
       " ('family elephantidae', 0.607),\n",
       " ('large mammals', 0.607),\n",
       " ('years', 0.607),\n",
       " ('environments', 0.577),\n",
       " ('impact', 0.577),\n",
       " ('keystone species', 0.577),\n",
       " ('cetaceans', 0.577),\n",
       " ('elephant intelligence', 0.577),\n",
       " ('primates', 0.577),\n",
       " ('dead individuals', 0.577),\n",
       " ('kind', 0.577),\n",
       " ('selfawareness', 0.577),\n",
       " ('different habitats', 0.57),\n",
       " ('marshes', 0.57)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 30 tf-idf weighted keyphrases\n",
    "get_tfidf_weighted_keyphrases(sentences=norm_sentences, top_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('african bush elephant', 0.261),\n",
       " ('including', 0.141),\n",
       " ('family', 0.137),\n",
       " ('cow', 0.124),\n",
       " ('forests', 0.108),\n",
       " ('female', 0.103),\n",
       " ('asia', 0.102),\n",
       " ('objects', 0.098),\n",
       " ('sight', 0.098),\n",
       " ('ivory', 0.098),\n",
       " ('tigers', 0.098),\n",
       " ('males', 0.088),\n",
       " ('religion', 0.087),\n",
       " ('folklore', 0.087),\n",
       " ('known', 0.087),\n",
       " ('larger ears', 0.085),\n",
       " ('water', 0.075),\n",
       " ('highly recognisable', 0.075),\n",
       " ('breathing lifting', 0.074),\n",
       " ('flaps', 0.073),\n",
       " ('africa', 0.072),\n",
       " ('gomphotheres', 0.072),\n",
       " ('animals tend', 0.071),\n",
       " ('success', 0.071),\n",
       " ('south', 0.07)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "key_words = keywords(data[0], ratio=1.0, scores=True, lemmatize=True)\n",
    "[(item, round(score,3)) for item, score in key_words][:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling on Research Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Retrieval\n",
    "#!wget https://cs.nyu.edu/~roweis/data/nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract dataset\n",
    "#!tar -xzf nips12raw_str602.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['idx', 'MATLAB_NOTES', 'nips00', 'nips01', 'nips02', 'nips03', 'nips04', 'nips05', 'nips06', 'nips07', 'nips08', 'nips09', 'nips10', 'nips11', 'nips12', 'orig', 'RAW_DATA_NOTES', 'README_yann']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = path_to_users + '/nipstxt/'\n",
    "print(os.listdir(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load and View Dataset\n",
    "folders = [\"nips{0:02}\".format(i) for i in range(0,13)]\n",
    "# read all texts into a list\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    file_names = os.listdir(DATA_PATH + folder)\n",
    "    for file_name in file_names:\n",
    "        with open(DATA_PATH + folder + '/' + file_name, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "len(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "CONNECTIVITY VERSUS ENTROPY \n",
      "Yaser S. Abu-Mostafa \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "ABSTRACT \n",
      "How does the connectivity of a neural network (number of synapses per \n",
      "neuron) relate to the complexity of the problems it can handle (measured by \n",
      "the entropy)? Switching theory would suggest no relation at all, since all Boolean \n",
      "functions can be implemented using a circuit with very low connectivity (e.g., \n",
      "using two-input NAND gates). However, for a network that learns a problem \n",
      "from examples using a local learning rule, we prove that the entropy of the \n",
      "problem becomes a lower bound for the connectivity of the network. \n",
      "INTRODUCTION \n",
      "The most distinguishing feature of neural networks is their ability to spon- \n",
      "taneously learn the desired function from 'training' samples, i.e., their ability \n",
      "to program themselves. Clearly, a given neural network cannot just learn any \n",
      "function, there must be some restrictions on which networks can learn which \n",
      "functions. One obv\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740\n",
      "CPU times: user 25.6 s, sys: 0 ns, total: 25.6 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Basic Text Wrangling\n",
    "import nltk\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def normalize_corpus(papers):\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "        \n",
    "    return norm_papers\n",
    "\n",
    "norm_papers = normalize_corpus(papers)\n",
    "print(len(norm_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['connectivity', 'versus', 'entropy', 'yaser', 'abu', 'mostafa', 'california', 'institute', 'technology', 'pasadena', 'ca', 'abstract', 'doe', 'connectivity', 'neural', 'network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean', 'function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using']\n"
     ]
    }
   ],
   "source": [
    "# viewing a processed paper\n",
    "print(norm_papers[0][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['connectivity', 'versus', 'entropy', 'yaser', 'abu_mostafa', 'california_institute', 'technology_pasadena', 'ca_abstract', 'doe', 'connectivity', 'neural_network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean_function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using', 'local', 'learning', 'rule', 'prove', 'entropy', 'problem']\n"
     ]
    }
   ],
   "source": [
    "## Text Representation with Feature Engineering\n",
    "import gensim\n",
    "\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, \n",
    "                               threshold=20, delimiter=b'_') # higher threshold fewer phrases\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "# sample demonstration\n",
    "print(bigram_model[norm_papers[0]][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '0a'), (1, '2h'), (2, '2h2'), (3, '2he'), (4, '2n'), (5, '__c'), (6, '_c'), (7, '_k'), (8, 'a2'), (9, 'ability'), (10, 'abu_mostafa'), (11, 'access'), (12, 'accommodate'), (13, 'according'), (14, 'accumulated')]\n",
      "Total Vocabulary Size 78892\n"
     ]
    }
   ],
   "source": [
    "norm_corpus_bigrams = [bigram_model[doc] for doc in norm_papers]\n",
    "\n",
    "# create a dictionary representation of the documents\n",
    "dictionary = gensim.corpora.Dictionary(norm_corpus_bigrams)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 7756\n"
     ]
    }
   ],
   "source": [
    "# filer out words that occur less than 20 documents, or more than 50% of the documents\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 1), (12, 3), (14, 1), (15, 1), (16, 1), (17, 16), (20, 1), (24, 1), (26, 1), (31, 3), (35, 1), (36, 1), (40, 3), (41, 5), (42, 1), (48, 1), (53, 3), (55, 1), (56, 2), (58, 1), (60, 3), (63, 5), (64, 4), (65, 2), (73, 1), (74, 1), (75, 1), (76, 1), (77, 3), (82, 1), (83, 4), (84, 1), (85, 1), (86, 2), (94, 1), (96, 2), (97, 3), (106, 1), (110, 1), (119, 2), (120, 4), (121, 2), (124, 2), (127, 1), (128, 1), (132, 1), (133, 1), (135, 6), (136, 1), (144, 1)]\n"
     ]
    }
   ],
   "source": [
    "# transforming corpus into bag of words vectors\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in norm_corpus_bigrams]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ability', 1), ('aip', 3), ('although', 1), ('american_institute', 1), ('amount', 1), ('analog', 16), ('appears', 1), ('architecture', 1), ('aspect', 1), ('available', 3), ('become', 1), ('becomes', 1), ('binary', 3), ('biological', 5), ('bit', 1), ('cannot', 1), ('circuit', 3), ('collective', 1), ('compare', 2), ('complex', 1), ('computing', 3), ('conference', 5), ('connected', 4), ('connectivity', 2), ('define', 1), ('defined', 1), ('defines', 1), ('definition', 1), ('denker', 3), ('designed', 1), ('desired', 4), ('diagonal', 1), ('difference', 1), ('directly', 2), ('ed', 1), ('el', 2), ('element', 3), ('equivalent', 1), ('eventually', 1), ('feature', 2), ('final', 4), ('find', 2), ('fixed', 2), ('frequency', 1), ('furthermore', 1), ('generating', 1), ('get', 1), ('global', 6), ('go', 1), ('hence', 1)]\n"
     ]
    }
   ],
   "source": [
    "# viewing actual terms and their counts\n",
    "print([(dictionary[idx], freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers: 1740\n"
     ]
    }
   ],
   "source": [
    "# total papers in the corpus\n",
    "print('Total number of papers:', len(bow_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 4s, sys: 3min 40s, total: 9min 45s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Semantic Indexing\n",
    "TOTAL_TOPICS = 10\n",
    "lsi_bow = gensim.models.LsiModel(bow_corpus, id2word=dictionary, num_topics=TOTAL_TOPICS, \n",
    "                                 onepass=True, chunksize=1740, power_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.215*\"unit\" + 0.212*\"state\" + 0.187*\"training\" + 0.177*\"neuron\" + 0.162*\"pattern\" + 0.145*\"image\" + 0.140*\"vector\" + 0.125*\"feature\" + 0.122*\"cell\" + 0.110*\"layer\" + 0.101*\"task\" + 0.097*\"class\" + 0.091*\"probability\" + 0.089*\"signal\" + 0.087*\"step\" + 0.086*\"response\" + 0.085*\"representation\" + 0.083*\"noise\" + 0.082*\"rule\" + 0.081*\"distribution\"\n",
      "\n",
      "Topic #2:\n",
      "-0.487*\"neuron\" + -0.396*\"cell\" + 0.257*\"state\" + -0.191*\"response\" + 0.187*\"training\" + -0.170*\"stimulus\" + -0.117*\"activity\" + 0.109*\"class\" + -0.099*\"spike\" + -0.097*\"pattern\" + -0.096*\"circuit\" + -0.096*\"synaptic\" + 0.095*\"vector\" + -0.090*\"signal\" + -0.090*\"firing\" + -0.088*\"visual\" + 0.084*\"classifier\" + 0.083*\"action\" + 0.078*\"word\" + -0.078*\"cortical\"\n",
      "\n",
      "Topic #3:\n",
      "0.627*\"state\" + -0.395*\"image\" + 0.219*\"neuron\" + -0.209*\"feature\" + 0.188*\"action\" + -0.137*\"unit\" + -0.131*\"object\" + 0.130*\"control\" + -0.129*\"training\" + 0.109*\"policy\" + -0.103*\"classifier\" + -0.090*\"class\" + 0.081*\"step\" + 0.081*\"dynamic\" + -0.080*\"classification\" + -0.078*\"layer\" + -0.076*\"recognition\" + 0.074*\"reinforcement_learning\" + -0.069*\"representation\" + -0.068*\"pattern\"\n",
      "\n",
      "Topic #4:\n",
      "-0.686*\"unit\" + 0.433*\"image\" + -0.182*\"pattern\" + -0.131*\"layer\" + -0.123*\"hidden_unit\" + -0.121*\"net\" + -0.114*\"training\" + 0.112*\"feature\" + -0.109*\"activation\" + -0.107*\"rule\" + 0.097*\"neuron\" + -0.078*\"word\" + 0.070*\"pixel\" + -0.070*\"connection\" + 0.067*\"object\" + 0.065*\"state\" + 0.060*\"distribution\" + 0.059*\"face\" + -0.057*\"architecture\" + 0.055*\"estimate\"\n",
      "\n",
      "Topic #5:\n",
      "0.428*\"image\" + 0.348*\"state\" + -0.266*\"neuron\" + 0.264*\"unit\" + -0.181*\"training\" + -0.174*\"class\" + 0.168*\"object\" + -0.167*\"classifier\" + 0.147*\"action\" + 0.122*\"visual\" + -0.117*\"vector\" + -0.115*\"node\" + -0.105*\"distribution\" + 0.103*\"motion\" + 0.099*\"feature\" + -0.097*\"classification\" + 0.097*\"control\" + 0.095*\"task\" + 0.087*\"cell\" + 0.083*\"representation\"\n",
      "\n",
      "Topic #6:\n",
      "0.660*\"cell\" + -0.508*\"neuron\" + -0.213*\"image\" + -0.103*\"chip\" + -0.097*\"unit\" + 0.093*\"response\" + -0.090*\"object\" + 0.083*\"rat\" + 0.076*\"distribution\" + -0.070*\"circuit\" + 0.069*\"probability\" + 0.064*\"stimulus\" + -0.061*\"memory\" + -0.058*\"analog\" + -0.058*\"activation\" + 0.055*\"class\" + -0.053*\"bit\" + -0.052*\"net\" + 0.051*\"cortical\" + 0.050*\"firing\"\n",
      "\n",
      "Topic #7:\n",
      "-0.353*\"word\" + 0.281*\"unit\" + -0.272*\"training\" + -0.257*\"classifier\" + -0.177*\"recognition\" + 0.159*\"distribution\" + -0.152*\"feature\" + -0.144*\"state\" + -0.142*\"pattern\" + 0.141*\"vector\" + -0.128*\"cell\" + -0.128*\"task\" + 0.122*\"approximation\" + 0.121*\"variable\" + 0.110*\"equation\" + -0.107*\"classification\" + 0.106*\"noise\" + -0.103*\"class\" + 0.101*\"matrix\" + -0.098*\"neuron\"\n",
      "\n",
      "Topic #8:\n",
      "0.303*\"pattern\" + -0.243*\"signal\" + -0.236*\"control\" + -0.202*\"training\" + 0.181*\"rule\" + 0.178*\"state\" + -0.167*\"noise\" + 0.166*\"class\" + -0.162*\"word\" + 0.155*\"cell\" + 0.154*\"feature\" + -0.147*\"motion\" + -0.140*\"task\" + 0.127*\"node\" + 0.124*\"neuron\" + -0.116*\"target\" + -0.114*\"circuit\" + 0.114*\"probability\" + 0.110*\"classifier\" + 0.109*\"image\"\n",
      "\n",
      "Topic #9:\n",
      "0.472*\"node\" + 0.254*\"circuit\" + -0.214*\"word\" + 0.201*\"chip\" + -0.190*\"neuron\" + -0.172*\"stimulus\" + 0.160*\"classifier\" + 0.152*\"current\" + -0.147*\"feature\" + 0.146*\"voltage\" + -0.145*\"distribution\" + 0.141*\"control\" + 0.124*\"rule\" + 0.110*\"layer\" + 0.105*\"analog\" + 0.091*\"tree\" + -0.084*\"response\" + -0.080*\"state\" + -0.079*\"probability\" + -0.079*\"estimate\"\n",
      "\n",
      "Topic #10:\n",
      "-0.518*\"word\" + 0.254*\"training\" + -0.236*\"vector\" + 0.222*\"task\" + 0.194*\"pattern\" + 0.156*\"classifier\" + -0.149*\"node\" + -0.146*\"recognition\" + 0.139*\"control\" + -0.138*\"sequence\" + 0.126*\"rule\" + -0.125*\"circuit\" + -0.123*\"cell\" + 0.113*\"action\" + 0.105*\"neuron\" + -0.094*\"hmm\" + -0.093*\"character\" + -0.088*\"chip\" + -0.088*\"matrix\" + -0.085*\"structure\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic in lsi_bow.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.215), ('state', 0.212), ('training', 0.187), ('neuron', 0.177), ('pattern', 0.162), ('image', 0.145), ('vector', 0.14), ('feature', 0.125), ('cell', 0.122), ('layer', 0.11), ('task', 0.101), ('class', 0.097), ('probability', 0.091), ('signal', 0.089), ('step', 0.087), ('response', 0.086), ('representation', 0.085), ('noise', 0.083), ('rule', 0.082), ('distribution', 0.081)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.257), ('training', 0.187), ('class', 0.109), ('vector', 0.095), ('classifier', 0.084), ('action', 0.083), ('word', 0.078)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.487), ('cell', -0.396), ('response', -0.191), ('stimulus', -0.17), ('activity', -0.117), ('spike', -0.099), ('pattern', -0.097), ('circuit', -0.096), ('synaptic', -0.096), ('signal', -0.09), ('firing', -0.09), ('visual', -0.088), ('cortical', -0.078)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.627), ('neuron', 0.219), ('action', 0.188), ('control', 0.13), ('policy', 0.109), ('step', 0.081), ('dynamic', 0.081), ('reinforcement_learning', 0.074)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.395), ('feature', -0.209), ('unit', -0.137), ('object', -0.131), ('training', -0.129), ('classifier', -0.103), ('class', -0.09), ('classification', -0.08), ('layer', -0.078), ('recognition', -0.076), ('representation', -0.069), ('pattern', -0.068)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.433), ('feature', 0.112), ('neuron', 0.097), ('pixel', 0.07), ('object', 0.067), ('state', 0.065), ('distribution', 0.06), ('face', 0.059), ('estimate', 0.055)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -0.686), ('pattern', -0.182), ('layer', -0.131), ('hidden_unit', -0.123), ('net', -0.121), ('training', -0.114), ('activation', -0.109), ('rule', -0.107), ('word', -0.078), ('connection', -0.07), ('architecture', -0.057)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.428), ('state', 0.348), ('unit', 0.264), ('object', 0.168), ('action', 0.147), ('visual', 0.122), ('motion', 0.103), ('feature', 0.099), ('control', 0.097), ('task', 0.095), ('cell', 0.087), ('representation', 0.083)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.266), ('training', -0.181), ('class', -0.174), ('classifier', -0.167), ('vector', -0.117), ('node', -0.115), ('distribution', -0.105), ('classification', -0.097)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.66), ('response', 0.093), ('rat', 0.083), ('distribution', 0.076), ('probability', 0.069), ('stimulus', 0.064), ('class', 0.055), ('cortical', 0.051), ('firing', 0.05)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.508), ('image', -0.213), ('chip', -0.103), ('unit', -0.097), ('object', -0.09), ('circuit', -0.07), ('memory', -0.061), ('analog', -0.058), ('activation', -0.058), ('bit', -0.053), ('net', -0.052)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('unit', 0.281), ('distribution', 0.159), ('vector', 0.141), ('approximation', 0.122), ('variable', 0.121), ('equation', 0.11), ('noise', 0.106), ('matrix', 0.101)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.353), ('training', -0.272), ('classifier', -0.257), ('recognition', -0.177), ('feature', -0.152), ('state', -0.144), ('pattern', -0.142), ('cell', -0.128), ('task', -0.128), ('classification', -0.107), ('class', -0.103), ('neuron', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('pattern', 0.303), ('rule', 0.181), ('state', 0.178), ('class', 0.166), ('cell', 0.155), ('feature', 0.154), ('node', 0.127), ('neuron', 0.124), ('probability', 0.114), ('classifier', 0.11), ('image', 0.109)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('signal', -0.243), ('control', -0.236), ('training', -0.202), ('noise', -0.167), ('word', -0.162), ('motion', -0.147), ('task', -0.14), ('target', -0.116), ('circuit', -0.114)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('node', 0.472), ('circuit', 0.254), ('chip', 0.201), ('classifier', 0.16), ('current', 0.152), ('voltage', 0.146), ('control', 0.141), ('rule', 0.124), ('layer', 0.11), ('analog', 0.105), ('tree', 0.091)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.214), ('neuron', -0.19), ('stimulus', -0.172), ('feature', -0.147), ('distribution', -0.145), ('response', -0.084), ('state', -0.08), ('probability', -0.079), ('estimate', -0.079)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('training', 0.254), ('task', 0.222), ('pattern', 0.194), ('classifier', 0.156), ('control', 0.139), ('rule', 0.126), ('action', 0.113), ('neuron', 0.105)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.518), ('vector', -0.236), ('node', -0.149), ('recognition', -0.146), ('sequence', -0.138), ('circuit', -0.125), ('cell', -0.123), ('hmm', -0.094), ('character', -0.093), ('chip', -0.088), ('matrix', -0.088), ('structure', -0.085)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    for term, wt in lsi_bow.show_topic(n, topn=20):\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt,3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt,3)))\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get U, S, VT matrices from topic model\n",
    "term_topic = lsi_bow.projection.u\n",
    "singular_values = lsi_bow.projection.s\n",
    "topic_document = (gensim.matutils.corpus2dense(lsi_bow[bow_corpus], len(singular_values)).T / singular_values).T\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3     T4     T5     T6     T7     T8     T9    T10\n",
       "0  0.016 -0.017  0.013  0.008 -0.024 -0.028  0.000  0.019 -0.008  0.006\n",
       "1  0.041 -0.030  0.019 -0.021 -0.019 -0.056  0.018 -0.009  0.018  0.011\n",
       "2  0.022  0.000  0.022  0.008 -0.011 -0.016  0.013  0.017 -0.001 -0.007\n",
       "3  0.032 -0.036  0.011 -0.014 -0.035 -0.052 -0.016  0.043 -0.010  0.029\n",
       "4  0.035  0.002  0.017 -0.008 -0.016 -0.017  0.032  0.022  0.050 -0.029"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document topic matrix for our LSI model\n",
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_topics.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T3', 'T8', 'T9']\n",
      "Paper Summary:\n",
      "137 \n",
      "On the \n",
      "Power of Neural Networks for \n",
      "Solving Hard Problems \n",
      "Jehoshua Bruck \n",
      "Joseph W. Goodman \n",
      "Information Systems Laboratory \n",
      "Department of Electrical Engineering \n",
      "Stanford University \n",
      "Stanford, CA 94305 \n",
      "Abstract \n",
      "This paper deals with a neural network model in which each neuron \n",
      "performs a threshold logic function. An important property of the model \n",
      "is that it always converges to a stable state when operating in a serial \n",
      "mode [2,5]. This property is the basis of the potential applicat\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T9', 'T8', 'T1']\n",
      "Paper Summary:\n",
      "542 Kassebaum, Tenorio and Schaefers \n",
      "The Cocktail Party Problem: \n",
      "Speech/Data Signal Separation Comparison \n",
      "between Backpropagation and SONN \n",
      "John Kassebaum \n",
      "jakec.ecn.purdue.edu \n",
      "Manoel Fernando Tenorio \n",
      "tenorioee.ecn.purdue.edu \n",
      "Chrlstoph Schaefers \n",
      "Parallel Distributed Structures Laboratory \n",
      "School of Electrical Engineering \n",
      "Purdue University \n",
      "W. Lafayette, IN. 47907 \n",
      "ABSTRACT \n",
      "This work introduces a new method called Self Organizing Neural \n",
      "Network (SONN) algorithm and compares its perfor\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T1', 'T10', 'T7']\n",
      "Paper Summary:\n",
      "Learning Global Direct Inverse Kinematics \n",
      "David DeMers* \n",
      "Computer Science & Eng. \n",
      "UC San Diego \n",
      "La Jolla, CA 92093-0114 \n",
      "Kenneth Kreutz-Deigado I \n",
      "Electrical & Computer Eng. \n",
      "UC San Diego \n",
      "La Jolla, CA 92093-0407 \n",
      "Abstract \n",
      "We introduce and demonstrate a bootstrap method for construction of an in- \n",
      "verse function for the robot kinematic mapping using only sample configuration- \n",
      "space/workspace data. Unsupervised learning (clustering) techniques are used on \n",
      "pre-image neighborhoods in order to l\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_numbers = [13, 250, 500]\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.\n",
    "                      columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7756, 1740)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Implementing LSI Topic Models from Scratch\n",
    "td_matrix = gensim.matutils.corpus2dense(corpus=bow_corpus, num_terms=len(dictionary))\n",
    "print(td_matrix.shape)\n",
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 7756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2n', '_c', 'a2', ..., 'support_vector', 'mozer_jordan',\n",
       "       'kearns_solla'], dtype='<U28')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = np.array(list(dictionary.values()))\n",
    "print('Total vocabulary size:', len(vocabulary))\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7756, 10), (10,), (10, 1740))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "u, s, vt = svds(td_matrix, k=TOTAL_TOPICS, maxiter=10000)\n",
    "term_topic = u\n",
    "singular_values = s\n",
    "topic_document = vt\n",
    "term_topic.shape, singular_values.shape, topic_document.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7756)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_weights = term_topic.transpose() * singular_values[:,None]\n",
    "tt_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('word', 188.487), ('vector', 85.974), ('node', 54.378), ('recognition', 53.231), ('sequence', 50.351), ('circuit', 45.395), ('cell', 44.811), ('hmm', 34.085), ('character', 34.022), ('chip', 32.161), ('matrix', 32.093), ('structure', 30.993)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('training', -92.619), ('task', -80.732), ('pattern', -70.619), ('classifier', -56.988), ('control', -50.676), ('rule', -45.926), ('action', -41.202), ('neuron', -38.195)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('node', 173.276), ('circuit', 92.999), ('chip', 73.593), ('classifier', 58.717), ('current', 55.844), ('voltage', 53.489), ('control', 51.709), ('rule', 45.294), ('layer', 40.265), ('analog', 38.344), ('tree', 33.483)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -78.349), ('neuron', -69.793), ('stimulus', -63.233), ('feature', -53.819), ('distribution', -53.119), ('response', -30.954), ('state', -29.343), ('probability', -29.1), ('estimate', -28.908)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('pattern', 116.971), ('rule', 69.783), ('state', 68.605), ('class', 64.259), ('cell', 59.979), ('feature', 59.606), ('node', 49.176), ('neuron', 47.998), ('probability', 43.812), ('classifier', 42.612), ('image', 42.061)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('signal', -93.805), ('control', -91.041), ('training', -77.88), ('noise', -64.397), ('word', -62.392), ('motion', -56.699), ('task', -53.883), ('target', -44.765), ('circuit', -44.129)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('word', 147.792), ('training', 113.693), ('classifier', 107.386), ('recognition', 73.948), ('feature', 63.454), ('state', 60.126), ('pattern', 59.561), ('cell', 53.769), ('task', 53.693), ('classification', 44.936), ('class', 43.161), ('neuron', 41.092)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -117.727), ('distribution', -66.719), ('vector', -58.881), ('approximation', -50.931), ('variable', -50.83), ('equation', -46.229), ('noise', -44.247), ('matrix', -42.214)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('cell', 285.803), ('response', 40.216), ('rat', 35.975), ('distribution', 33.085), ('probability', 29.79), ('stimulus', 27.789), ('class', 24.02), ('cortical', 22.185), ('firing', 21.66)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -220.116), ('image', -92.391), ('chip', -44.422), ('unit', -41.922), ('object', -39.001), ('circuit', -30.444), ('memory', -26.475), ('analog', -25.207), ('activation', -24.953), ('bit', -22.997), ('net', -22.699)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('image', 209.796), ('state', 170.208), ('unit', 129.104), ('object', 82.186), ('action', 72.136), ('visual', 59.503), ('motion', 50.605), ('feature', 48.665), ('control', 47.427), ('task', 46.496), ('cell', 42.367), ('representation', 40.563)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -130.053), ('training', -88.669), ('class', -85.213), ('classifier', -81.92), ('vector', -57.531), ('node', -56.341), ('distribution', -51.622), ('classification', -47.645)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('image', 215.855), ('feature', 55.647), ('neuron', 48.496), ('pixel', 35.095), ('object', 33.584), ('state', 32.542), ('distribution', 29.978), ('face', 29.256), ('estimate', 27.556)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('unit', -341.83), ('pattern', -90.771), ('layer', -65.337), ('hidden_unit', -61.12), ('net', -60.035), ('training', -56.741), ('activation', -54.268), ('rule', -53.377), ('word', -38.903), ('connection', -34.618), ('architecture', -28.439)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('state', 364.388), ('neuron', 127.022), ('action', 109.245), ('control', 75.369), ('policy', 63.103), ('step', 47.226), ('dynamic', 46.907), ('reinforcement_learning', 42.747)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -229.287), ('feature', -121.397), ('unit', -79.44), ('object', -76.204), ('training', -75.153), ('classifier', -59.872), ('class', -52.527), ('classification', -46.696), ('layer', -45.149), ('recognition', -44.192), ('representation', -40.179), ('pattern', -39.252)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('state', 161.465), ('training', 117.319), ('class', 68.732), ('vector', 59.558), ('classifier', 52.589), ('action', 52.113), ('word', 49.239)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -306.151), ('cell', -249.243), ('response', -119.758), ('stimulus', -106.762), ('activity', -73.499), ('spike', -62.039), ('pattern', -60.957), ('circuit', -60.602), ('synaptic', -60.282), ('signal', -56.665), ('firing', -56.597), ('visual', -55.571), ('cortical', -48.867)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('unit', 260.793), ('state', 258.146), ('training', 227.312), ('neuron', 215.681), ('pattern', 197.232), ('image', 175.735), ('vector', 170.154), ('feature', 151.547), ('cell', 148.138), ('layer', 133.593), ('task', 122.389), ('class', 117.849), ('probability', 110.526), ('signal', 108.232), ('step', 105.202), ('response', 104.465), ('representation', 103.255), ('noise', 100.573), ('rule', 99.611), ('distribution', 98.973)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(tt_weights), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([tt_weights[row, columns]\n",
    "                                 for row, columns in list(zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weights[n]\n",
    "    term_weights = sorted([(t,w) for t, w in zip(terms, weights)], key=lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt, 3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T8', 'T3', 'T2']\n",
      "Paper Summary:\n",
      "137 \n",
      "On the \n",
      "Power of Neural Networks for \n",
      "Solving Hard Problems \n",
      "Jehoshua Bruck \n",
      "Joseph W. Goodman \n",
      "Information Systems Laboratory \n",
      "Department of Electrical Engineering \n",
      "Stanford University \n",
      "Stanford, CA 94305 \n",
      "Abstract \n",
      "This paper deals with a neural network model in which each neuron \n",
      "performs a threshold logic function. An important property of the model \n",
      "is that it always converges to a stable state when operating in a serial \n",
      "mode [2,5]. This property is the basis of the potential applicat\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T2', 'T3', 'T10']\n",
      "Paper Summary:\n",
      "542 Kassebaum, Tenorio and Schaefers \n",
      "The Cocktail Party Problem: \n",
      "Speech/Data Signal Separation Comparison \n",
      "between Backpropagation and SONN \n",
      "John Kassebaum \n",
      "jakec.ecn.purdue.edu \n",
      "Manoel Fernando Tenorio \n",
      "tenorioee.ecn.purdue.edu \n",
      "Chrlstoph Schaefers \n",
      "Parallel Distributed Structures Laboratory \n",
      "School of Electrical Engineering \n",
      "Purdue University \n",
      "W. Lafayette, IN. 47907 \n",
      "ABSTRACT \n",
      "This work introduces a new method called Self Organizing Neural \n",
      "Network (SONN) algorithm and compares its perfor\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T10', 'T1', 'T4']\n",
      "Paper Summary:\n",
      "Learning Global Direct Inverse Kinematics \n",
      "David DeMers* \n",
      "Computer Science & Eng. \n",
      "UC San Diego \n",
      "La Jolla, CA 92093-0114 \n",
      "Kenneth Kreutz-Deigado I \n",
      "Electrical & Computer Eng. \n",
      "UC San Diego \n",
      "La Jolla, CA 92093-0407 \n",
      "Abstract \n",
      "We introduce and demonstrate a bootstrap method for construction of an in- \n",
      "verse function for the robot kinematic mapping using only sample configuration- \n",
      "space/workspace data. Unsupervised learning (clustering) techniques are used on \n",
      "pre-image neighborhoods in order to l\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_topics = pd.DataFrame(np.round(topic_document.T, 3), \n",
    "                               columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(document_topics.\n",
    "                      columns[np.argsort(-np.absolute(document_topics.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 4.33 s, total: 1min 28s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Dirichlet Allocation\n",
    "lda_model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, \n",
    "                                   chunksize=1740, alpha='auto', eta='auto', random_state=42, \n",
    "                                   iterations=500, num_topics=TOTAL_TOPICS, \n",
    "                                   passes=20, eval_every=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "0.013*\"circuit\" + 0.012*\"chip\" + 0.008*\"neuron\" + 0.008*\"analog\" + 0.007*\"current\" + 0.007*\"bit\" + 0.006*\"voltage\" + 0.005*\"node\" + 0.005*\"word\" + 0.005*\"vector\" + 0.005*\"processor\" + 0.004*\"implementation\" + 0.004*\"threshold\" + 0.004*\"computation\" + 0.004*\"element\" + 0.004*\"signal\" + 0.004*\"pattern\" + 0.004*\"design\" + 0.004*\"memory\" + 0.004*\"parallel\"\n",
      "\n",
      "Topic #2:\n",
      "0.030*\"image\" + 0.012*\"object\" + 0.011*\"feature\" + 0.006*\"pixel\" + 0.006*\"visual\" + 0.005*\"representation\" + 0.005*\"recognition\" + 0.005*\"unit\" + 0.005*\"motion\" + 0.005*\"face\" + 0.005*\"task\" + 0.004*\"view\" + 0.004*\"layer\" + 0.004*\"human\" + 0.004*\"training\" + 0.004*\"position\" + 0.004*\"location\" + 0.004*\"region\" + 0.004*\"character\" + 0.003*\"vector\"\n",
      "\n",
      "Topic #3:\n",
      "0.020*\"neuron\" + 0.017*\"cell\" + 0.012*\"response\" + 0.010*\"stimulus\" + 0.007*\"spike\" + 0.007*\"signal\" + 0.006*\"activity\" + 0.006*\"synaptic\" + 0.005*\"firing\" + 0.005*\"frequency\" + 0.005*\"pattern\" + 0.004*\"current\" + 0.004*\"effect\" + 0.004*\"neural\" + 0.004*\"change\" + 0.004*\"et_al\" + 0.004*\"channel\" + 0.004*\"synapsis\" + 0.003*\"motion\" + 0.003*\"unit\"\n",
      "\n",
      "Topic #4:\n",
      "0.013*\"neuron\" + 0.009*\"cell\" + 0.009*\"pattern\" + 0.008*\"activity\" + 0.007*\"map\" + 0.006*\"unit\" + 0.006*\"dynamic\" + 0.006*\"visual\" + 0.005*\"layer\" + 0.005*\"receptive_field\" + 0.005*\"orientation\" + 0.005*\"connection\" + 0.005*\"cortical\" + 0.005*\"correlation\" + 0.004*\"response\" + 0.004*\"feature\" + 0.004*\"cortex\" + 0.004*\"stimulus\" + 0.004*\"phase\" + 0.004*\"neural\"\n",
      "\n",
      "Topic #5:\n",
      "0.020*\"unit\" + 0.011*\"state\" + 0.010*\"training\" + 0.008*\"rule\" + 0.007*\"net\" + 0.006*\"word\" + 0.006*\"pattern\" + 0.006*\"sequence\" + 0.006*\"node\" + 0.006*\"layer\" + 0.006*\"hidden_unit\" + 0.005*\"activation\" + 0.005*\"architecture\" + 0.005*\"recurrent\" + 0.004*\"recognition\" + 0.004*\"task\" + 0.004*\"vector\" + 0.004*\"trained\" + 0.004*\"context\" + 0.004*\"connection\"\n",
      "\n",
      "Topic #6:\n",
      "0.017*\"signal\" + 0.013*\"memory\" + 0.010*\"noise\" + 0.009*\"control\" + 0.008*\"trajectory\" + 0.007*\"dynamic\" + 0.007*\"state\" + 0.006*\"movement\" + 0.005*\"motor\" + 0.005*\"mapping\" + 0.004*\"pattern\" + 0.004*\"feedback\" + 0.004*\"capacity\" + 0.004*\"position\" + 0.004*\"speech\" + 0.004*\"training\" + 0.004*\"target\" + 0.004*\"arm\" + 0.004*\"vector\" + 0.004*\"change\"\n",
      "\n",
      "Topic #7:\n",
      "0.007*\"vector\" + 0.006*\"equation\" + 0.005*\"let\" + 0.005*\"linear\" + 0.005*\"distribution\" + 0.005*\"approximation\" + 0.005*\"matrix\" + 0.004*\"theorem\" + 0.004*\"convergence\" + 0.004*\"bound\" + 0.004*\"class\" + 0.004*\"training\" + 0.004*\"optimal\" + 0.004*\"theory\" + 0.004*\"consider\" + 0.004*\"solution\" + 0.004*\"probability\" + 0.004*\"estimate\" + 0.004*\"noise\" + 0.003*\"rate\"\n",
      "\n",
      "Topic #8:\n",
      "0.010*\"distribution\" + 0.009*\"probability\" + 0.009*\"variable\" + 0.008*\"mixture\" + 0.006*\"gaussian\" + 0.006*\"tree\" + 0.006*\"prior\" + 0.006*\"structure\" + 0.006*\"component\" + 0.006*\"node\" + 0.005*\"density\" + 0.005*\"class\" + 0.004*\"likelihood\" + 0.004*\"bayesian\" + 0.004*\"estimate\" + 0.004*\"sample\" + 0.004*\"step\" + 0.004*\"log\" + 0.004*\"source\" + 0.003*\"approximation\"\n",
      "\n",
      "Topic #9:\n",
      "0.017*\"training\" + 0.010*\"classifier\" + 0.008*\"classification\" + 0.008*\"class\" + 0.006*\"pattern\" + 0.006*\"feature\" + 0.006*\"test\" + 0.006*\"training_set\" + 0.005*\"vector\" + 0.005*\"prediction\" + 0.004*\"kernel\" + 0.004*\"experiment\" + 0.004*\"trained\" + 0.004*\"linear\" + 0.003*\"technique\" + 0.003*\"rbf\" + 0.003*\"task\" + 0.003*\"size\" + 0.003*\"table\" + 0.003*\"sample\"\n",
      "\n",
      "Topic #10:\n",
      "0.026*\"state\" + 0.013*\"action\" + 0.012*\"control\" + 0.008*\"policy\" + 0.007*\"task\" + 0.007*\"step\" + 0.006*\"reinforcement_learning\" + 0.006*\"controller\" + 0.006*\"environment\" + 0.005*\"optimal\" + 0.005*\"robot\" + 0.004*\"goal\" + 0.004*\"reward\" + 0.003*\"agent\" + 0.003*\"td\" + 0.003*\"current\" + 0.003*\"trial\" + 0.003*\"cost\" + 0.003*\"rate\" + 0.003*\"reinforcement\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view topics in trained topic model\n",
    "for topic_id, topic in lda_model.print_topics(num_topics=10, num_words=20):\n",
    "    print('Topic #'+str(topic_id+1)+':')\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score: -0.9858031202745918\n"
     ]
    }
   ],
   "source": [
    "# view overall mean coherence score of model\n",
    "topics_coherences = lda_model.top_topics(bow_corpus, topn=20)\n",
    "avg_coherence_score = np.mean([item[1] for item in topics_coherences])\n",
    "print('Avg. Coherence Score:', avg_coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics with Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "[('vector', 0.007), ('equation', 0.006), ('let', 0.005), ('linear', 0.005), ('distribution', 0.005), ('approximation', 0.005), ('matrix', 0.005), ('theorem', 0.004), ('convergence', 0.004), ('bound', 0.004), ('class', 0.004), ('training', 0.004), ('optimal', 0.004), ('theory', 0.004), ('consider', 0.004), ('solution', 0.004), ('probability', 0.004), ('estimate', 0.004), ('noise', 0.004), ('rate', 0.003)]\n",
      "\n",
      "Topic #2:\n",
      "[('training', 0.017), ('classifier', 0.01), ('classification', 0.008), ('class', 0.008), ('pattern', 0.006), ('feature', 0.006), ('test', 0.006), ('training_set', 0.006), ('vector', 0.005), ('prediction', 0.005), ('kernel', 0.004), ('experiment', 0.004), ('trained', 0.004), ('linear', 0.004), ('technique', 0.003), ('rbf', 0.003), ('task', 0.003), ('size', 0.003), ('table', 0.003), ('sample', 0.003)]\n",
      "\n",
      "Topic #3:\n",
      "[('neuron', 0.02), ('cell', 0.017), ('response', 0.012), ('stimulus', 0.01), ('spike', 0.007), ('signal', 0.007), ('activity', 0.006), ('synaptic', 0.006), ('firing', 0.005), ('frequency', 0.005), ('pattern', 0.005), ('current', 0.004), ('effect', 0.004), ('neural', 0.004), ('change', 0.004), ('et_al', 0.004), ('channel', 0.004), ('synapsis', 0.004), ('motion', 0.003), ('unit', 0.003)]\n",
      "\n",
      "Topic #4:\n",
      "[('unit', 0.02), ('state', 0.011), ('training', 0.01), ('rule', 0.008), ('net', 0.007), ('word', 0.006), ('pattern', 0.006), ('sequence', 0.006), ('node', 0.006), ('layer', 0.006), ('hidden_unit', 0.006), ('activation', 0.005), ('architecture', 0.005), ('recurrent', 0.005), ('recognition', 0.004), ('task', 0.004), ('vector', 0.004), ('trained', 0.004), ('context', 0.004), ('connection', 0.004)]\n",
      "\n",
      "Topic #5:\n",
      "[('circuit', 0.013), ('chip', 0.012), ('neuron', 0.008), ('analog', 0.008), ('current', 0.007), ('bit', 0.007), ('voltage', 0.006), ('node', 0.005), ('word', 0.005), ('vector', 0.005), ('processor', 0.005), ('implementation', 0.004), ('threshold', 0.004), ('computation', 0.004), ('element', 0.004), ('signal', 0.004), ('pattern', 0.004), ('design', 0.004), ('memory', 0.004), ('parallel', 0.004)]\n",
      "\n",
      "Topic #6:\n",
      "[('neuron', 0.013), ('cell', 0.009), ('pattern', 0.009), ('activity', 0.008), ('map', 0.007), ('unit', 0.006), ('dynamic', 0.006), ('visual', 0.006), ('layer', 0.005), ('receptive_field', 0.005), ('orientation', 0.005), ('connection', 0.005), ('cortical', 0.005), ('correlation', 0.005), ('response', 0.004), ('feature', 0.004), ('cortex', 0.004), ('stimulus', 0.004), ('phase', 0.004), ('neural', 0.004)]\n",
      "\n",
      "Topic #7:\n",
      "[('image', 0.03), ('object', 0.012), ('feature', 0.011), ('pixel', 0.006), ('visual', 0.006), ('representation', 0.005), ('recognition', 0.005), ('unit', 0.005), ('motion', 0.005), ('face', 0.005), ('task', 0.005), ('view', 0.004), ('layer', 0.004), ('human', 0.004), ('training', 0.004), ('position', 0.004), ('location', 0.004), ('region', 0.004), ('character', 0.004), ('vector', 0.003)]\n",
      "\n",
      "Topic #8:\n",
      "[('distribution', 0.01), ('probability', 0.009), ('variable', 0.009), ('mixture', 0.008), ('gaussian', 0.006), ('tree', 0.006), ('prior', 0.006), ('structure', 0.006), ('component', 0.006), ('node', 0.006), ('density', 0.005), ('class', 0.005), ('likelihood', 0.004), ('bayesian', 0.004), ('estimate', 0.004), ('sample', 0.004), ('step', 0.004), ('log', 0.004), ('source', 0.004), ('approximation', 0.003)]\n",
      "\n",
      "Topic #9:\n",
      "[('signal', 0.017), ('memory', 0.013), ('noise', 0.01), ('control', 0.009), ('trajectory', 0.008), ('dynamic', 0.007), ('state', 0.007), ('movement', 0.006), ('motor', 0.005), ('mapping', 0.005), ('pattern', 0.004), ('feedback', 0.004), ('capacity', 0.004), ('position', 0.004), ('speech', 0.004), ('training', 0.004), ('target', 0.004), ('arm', 0.004), ('vector', 0.004), ('change', 0.004)]\n",
      "\n",
      "Topic #10:\n",
      "[('state', 0.026), ('action', 0.013), ('control', 0.012), ('policy', 0.008), ('task', 0.007), ('step', 0.007), ('reinforcement_learning', 0.006), ('controller', 0.006), ('environment', 0.006), ('optimal', 0.005), ('robot', 0.005), ('goal', 0.004), ('reward', 0.004), ('agent', 0.003), ('td', 0.003), ('current', 0.003), ('trial', 0.003), ('cost', 0.003), ('rate', 0.003), ('reinforcement', 0.003)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output of topic models as tuples of terms and weights\n",
    "topics_with_wts = [item[0] for item in topics_coherences]\n",
    "print('LDA Topics with Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([(term, round(wt,3)) for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topics without Weights\n",
      "==================================================\n",
      "Topic #1:\n",
      "['vector', 'equation', 'let', 'linear', 'distribution', 'approximation', 'matrix', 'theorem', 'convergence', 'bound', 'class', 'training', 'optimal', 'theory', 'consider', 'solution', 'probability', 'estimate', 'noise', 'rate']\n",
      "\n",
      "Topic #2:\n",
      "['training', 'classifier', 'classification', 'class', 'pattern', 'feature', 'test', 'training_set', 'vector', 'prediction', 'kernel', 'experiment', 'trained', 'linear', 'technique', 'rbf', 'task', 'size', 'table', 'sample']\n",
      "\n",
      "Topic #3:\n",
      "['neuron', 'cell', 'response', 'stimulus', 'spike', 'signal', 'activity', 'synaptic', 'firing', 'frequency', 'pattern', 'current', 'effect', 'neural', 'change', 'et_al', 'channel', 'synapsis', 'motion', 'unit']\n",
      "\n",
      "Topic #4:\n",
      "['unit', 'state', 'training', 'rule', 'net', 'word', 'pattern', 'sequence', 'node', 'layer', 'hidden_unit', 'activation', 'architecture', 'recurrent', 'recognition', 'task', 'vector', 'trained', 'context', 'connection']\n",
      "\n",
      "Topic #5:\n",
      "['circuit', 'chip', 'neuron', 'analog', 'current', 'bit', 'voltage', 'node', 'word', 'vector', 'processor', 'implementation', 'threshold', 'computation', 'element', 'signal', 'pattern', 'design', 'memory', 'parallel']\n",
      "\n",
      "Topic #6:\n",
      "['neuron', 'cell', 'pattern', 'activity', 'map', 'unit', 'dynamic', 'visual', 'layer', 'receptive_field', 'orientation', 'connection', 'cortical', 'correlation', 'response', 'feature', 'cortex', 'stimulus', 'phase', 'neural']\n",
      "\n",
      "Topic #7:\n",
      "['image', 'object', 'feature', 'pixel', 'visual', 'representation', 'recognition', 'unit', 'motion', 'face', 'task', 'view', 'layer', 'human', 'training', 'position', 'location', 'region', 'character', 'vector']\n",
      "\n",
      "Topic #8:\n",
      "['distribution', 'probability', 'variable', 'mixture', 'gaussian', 'tree', 'prior', 'structure', 'component', 'node', 'density', 'class', 'likelihood', 'bayesian', 'estimate', 'sample', 'step', 'log', 'source', 'approximation']\n",
      "\n",
      "Topic #9:\n",
      "['signal', 'memory', 'noise', 'control', 'trajectory', 'dynamic', 'state', 'movement', 'motor', 'mapping', 'pattern', 'feedback', 'capacity', 'position', 'speech', 'training', 'target', 'arm', 'vector', 'change']\n",
      "\n",
      "Topic #10:\n",
      "['state', 'action', 'control', 'policy', 'task', 'step', 'reinforcement_learning', 'controller', 'environment', 'optimal', 'robot', 'goal', 'reward', 'agent', 'td', 'current', 'trial', 'cost', 'rate', 'reinforcement']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view topics as a list of terms without weights, understand context or theme of each topic\n",
    "print('LDA Topics without Weights')\n",
    "print('='*50)\n",
    "for idx, topic in enumerate(topics_with_wts):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for wt, term in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.4930044902277785\n",
      "Avg. Coherence Score (UMass): -0.9858031202745918\n",
      "Model Perplexity: -7.787864102055722\n"
     ]
    }
   ],
   "source": [
    "# use perplexity and coherence scores as measures to evaluate topic model\n",
    "cv_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                      texts=norm_corpus_bigrams, \n",
    "                                                      dictionary=dictionary, coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda.get_coherence()\n",
    "umass_coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, \n",
    "                                                         texts=norm_corpus_bigrams, \n",
    "                                                         dictionary=dictionary, coherence='u_mass')\n",
    "avg_coherence_umass = umass_coherence_model_lda.get_coherence()\n",
    "\n",
    "perplexity = lda_model.log_perplexity(bow_corpus)\n",
    "\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA Models with MALLET\n",
    "# download MALLET framework\n",
    "# !wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract contents from archive\n",
    "# !unzip -q mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['circuit', 'chip', 'bit', 'current', 'memory', 'analog', 'neuron', 'voltage', 'code', 'vector', 'implementation', 'design', 'signal', 'operation', 'parallel', 'computation', 'connection', 'processor', 'element', 'neural']\n",
      "\n",
      "Topic #2:\n",
      "['class', 'bound', 'size', 'tree', 'linear', 'vector', 'theorem', 'probability', 'node', 'theory', 'complexity', 'defined', 'threshold', 'xi', 'loss', 'distribution', 'proof', 'condition', 'machine', 'constant']\n",
      "\n",
      "Topic #3:\n",
      "['state', 'action', 'step', 'optimal', 'policy', 'rate', 'search', 'cost', 'task', 'reinforcement_learning', 'convergence', 'environment', 'goal', 'iteration', 'solution', 'trial', 'gradient', 'update', 'stochastic', 'probability']\n",
      "\n",
      "Topic #4:\n",
      "['distribution', 'matrix', 'estimate', 'equation', 'variable', 'gaussian', 'vector', 'approximation', 'noise', 'prior', 'solution', 'variance', 'component', 'density', 'mixture', 'linear', 'estimation', 'sample', 'bayesian', 'probability']\n",
      "\n",
      "Topic #5:\n",
      "['unit', 'training', 'pattern', 'rule', 'layer', 'hidden_unit', 'net', 'activation', 'task', 'node', 'architecture', 'trained', 'training_set', 'generalization', 'back_propagation', 'hidden_layer', 'connection', 'backpropagation', 'learn', 'connectionist']\n",
      "\n",
      "Topic #6:\n",
      "['training', 'classification', 'class', 'word', 'classifier', 'recognition', 'feature', 'test', 'experiment', 'speech', 'trained', 'table', 'character', 'context', 'probability', 'training_set', 'accuracy', 'hmm', 'test_set', 'pattern']\n",
      "\n",
      "Topic #7:\n",
      "['image', 'feature', 'object', 'representation', 'structure', 'vector', 'cluster', 'pixel', 'distance', 'local', 'view', 'face', 'region', 'surface', 'transformation', 'clustering', 'part', 'scale', 'level', 'shape']\n",
      "\n",
      "Topic #8:\n",
      "['state', 'control', 'dynamic', 'sequence', 'recurrent', 'trajectory', 'memory', 'module', 'controller', 'equation', 'position', 'architecture', 'attractor', 'adaptive', 'symbol', 'transition', 'behavior', 'hand', 'mapping', 'nonlinear']\n",
      "\n",
      "Topic #9:\n",
      "['cell', 'response', 'visual', 'motion', 'stimulus', 'map', 'unit', 'direction', 'layer', 'activity', 'spatial', 'receptive_field', 'location', 'field', 'target', 'orientation', 'eye', 'pattern', 'cortex', 'cortical']\n",
      "\n",
      "Topic #10:\n",
      "['neuron', 'signal', 'cell', 'synaptic', 'frequency', 'spike', 'activity', 'pattern', 'response', 'channel', 'firing', 'noise', 'phase', 'neural', 'rate', 'synapsis', 'effect', 'stimulus', 'threshold', 'temporal']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MALLET_PATH = path_to_users + '/mallet-2.0.8/bin/mallet'\n",
    "lda_mallet = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, corpus=bow_corpus,\n",
    "                                              num_topics=TOTAL_TOPICS, id2word=dictionary, \n",
    "                                              iterations=500, workers=16)\n",
    "\n",
    "topics=[[(term, round(wt,3)) \n",
    "         for term, wt in lda_mallet.show_topic(n, topn=20)]\n",
    "             for n in range(0, TOTAL_TOPICS)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Coherence Score (Cv): 0.5178652299067867\n",
      "Avg. Coherence Score (UMass): -1.046357075604323\n",
      "Model Perplexity: -8.53533\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using perplexity and coherence metrics\n",
    "cv_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, corpus=bow_corpus, \n",
    "                                                             texts=norm_corpus_bigrams, \n",
    "                                                             dictionary=dictionary, \n",
    "                                                             coherence='c_v')\n",
    "avg_coherence_cv = cv_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "umass_coherence_model_lda_mallet = gensim.models.CoherenceModel(model=lda_mallet, \n",
    "                                                                corpus=bow_corpus, \n",
    "                                                                texts=norm_corpus_bigrams, \n",
    "                                                                dictionary=dictionary, \n",
    "                                                                coherence='u_mass')\n",
    "\n",
    "avg_coherence_umass = umass_coherence_model_lda_mallet.get_coherence()\n",
    "\n",
    "# from STDOUT: <500> LL/token: -8.53533\n",
    "perplexity = -8.53533\n",
    "print('Avg. Coherence Score (Cv):', avg_coherence_cv)\n",
    "print('Avg. Coherence Score (UMass):', avg_coherence_umass)\n",
    "print('Model Perplexity:', perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA Tuning: Finding the Optimal Number of Topics\n",
    "from tqdm import tqdm\n",
    "\n",
    "# iterate and build several models with differing number of topics\n",
    "# select one that has highest coherence score\n",
    "def topic_model_coherence_generator(corpus, texts, dictionary, start_topic_count=2, \n",
    "                                    end_topic_count=10, step=1, cpus=1):\n",
    "    models = []\n",
    "    coherence_scores = []\n",
    "    for topic_nums in tqdm(range(start_topic_count, end_topic_count+1, step)):\n",
    "        mallet_lda_model = gensim.models.wrappers.LdaMallet(mallet_path=MALLET_PATH, \n",
    "                                                            corpus=corpus, num_topics=topic_nums, \n",
    "                                                            id2word=dictionary, iterations=500, \n",
    "                                                            workers=cpus)\n",
    "        cv_coherence_model_mallet_lda = gensim.models.CoherenceModel(model=mallet_lda_model, \n",
    "                                                                     corpus=corpus, texts=texts, \n",
    "                                                                     dictionary=dictionary, \n",
    "                                                                     coherence='c_v')\n",
    "        coherence_score = cv_coherence_model_mallet_lda.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "        models.append(mallet_lda_model)\n",
    "    \n",
    "    return models, coherence_scores\n",
    "\n",
    "#lda_models, coherence_scores = topic_model_coherence_generator(corpus=bow_corpus, \n",
    "#                                                               texts=norm_corpus_bigrams, \n",
    "#                                                               dictionary=dictionary, \n",
    "#                                                               start_topic_count=2, \n",
    "#                                                               end_topic_count=30, step=1, \n",
    "#                                                               cpus=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "\n",
    "# save model for later use\n",
    "#filename = path_to_users + '/LearningCode/NLP_Learning/lda_models.sav'\n",
    "#pickle.dump(lda_models, open(filename, 'wb'))\n",
    "\n",
    "# save coherence scores\n",
    "#np.savetxt(\"coherence_scores.csv\", coherence_scores, delimiter=\",\")#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and scores\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "filename = path_to_users + '/LearningCode/NLP_Learning/lda_models.sav'\n",
    "lda_models = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "coherence_scores = np.genfromtxt('data/coherence_scores.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Coherence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>0.5421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>0.5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.5369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.5361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.5357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.5340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.5305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.5294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.5293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of Topics  Coherence Score\n",
       "26                28           0.5421\n",
       "24                26           0.5405\n",
       "23                25           0.5378\n",
       "15                17           0.5369\n",
       "17                19           0.5361\n",
       "20                22           0.5357\n",
       "9                 11           0.5340\n",
       "13                15           0.5305\n",
       "11                13           0.5294\n",
       "6                  8           0.5293"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherence_df = pd.DataFrame({'Number of Topics': range(2, 31, 1), \n",
    "                             'Coherence Score': np.round(coherence_scores, 4)})\n",
    "coherence_df.sort_values(by=['Coherence Score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot graph showing number of topics per model and corresponding coherence scores\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "x_ax = range(2,31,1)\n",
    "y_ax = coherence_scores\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(x_ax, y_ax,c='r')\n",
    "plt.axhline(y=0.535, c='k', linestyle='--', linewidth=2)\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "x1 = plt.xlabel('Number of Topics')\n",
    "y1 = plt.ylabel('Coherence Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on graph, choose optimal number of topics as 20\n",
    "# retrieve best model\n",
    "best_model_idx = coherence_df[coherence_df['Number of Topics'] == 20].index[0]\n",
    "best_lda_model = lda_models[best_model_idx]\n",
    "best_lda_model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['node', 'rule', 'structure', 'representation', 'tree', 'level', 'symbol', 'string', 'graph', 'language', 'connectionist', 'sequence', 'represented', 'part', 'role', 'activation', 'represent', 'note', 'mapping', 'grammar']\n",
      "\n",
      "Topic #2:\n",
      "['unit', 'training', 'layer', 'net', 'hidden_unit', 'pattern', 'architecture', 'task', 'trained', 'activation', 'back_propagation', 'hidden_layer', 'hidden', 'connection', 'learn', 'generalization', 'backpropagation', 'training_set', 'epoch', 'target']\n",
      "\n",
      "Topic #3:\n",
      "['neuron', 'spike', 'synaptic', 'firing', 'cell', 'synapsis', 'activity', 'response', 'threshold', 'current', 'neural', 'neuronal', 'stimulus', 'firing_rate', 'et_al', 'effect', 'constant', 'level', 'pattern', 'biological']\n",
      "\n",
      "Topic #4:\n",
      "['motion', 'direction', 'visual', 'response', 'target', 'location', 'velocity', 'stimulus', 'position', 'cue', 'light', 'task', 'sensory', 'unit', 'moving', 'eye', 'spatial', 'head', 'stage', 'sensor']\n",
      "\n",
      "Topic #5:\n",
      "['prediction', 'training', 'test', 'regression', 'experiment', 'selection', 'expert', 'rbf', 'trained', 'sample', 'training_set', 'local', 'estimate', 'table', 'technique', 'linear', 'time_series', 'cross_validation', 'nonlinear', 'fit']\n",
      "\n",
      "Topic #6:\n",
      "['kernel', 'loss', 'sample', 'class', 'machine', 'distribution', 'hypothesis', 'training', 'concept', 'estimate', 'query', 'xi', 'generalization', 'target', 'probability', 'bound', 'margin', 'optimal', 'support_vector', 'regularization']\n",
      "\n",
      "Topic #7:\n",
      "['distribution', 'probability', 'prior', 'gaussian', 'variable', 'mixture', 'density', 'bayesian', 'estimate', 'approximation', 'likelihood', 'log', 'component', 'sample', 'em', 'estimation', 'posterior', 'variance', 'probabilistic', 'step']\n",
      "\n",
      "Topic #8:\n",
      "['cell', 'activity', 'stimulus', 'response', 'layer', 'pattern', 'map', 'receptive_field', 'cortical', 'cortex', 'orientation', 'connection', 'unit', 'region', 'contrast', 'center', 'visual', 'spatial', 'effect', 'brain']\n",
      "\n",
      "Topic #9:\n",
      "['theorem', 'bound', 'threshold', 'approximation', 'class', 'proof', 'size', 'polynomial', 'complexity', 'definition', 'bounded', 'probability', 'assume', 'linear', 'constant', 'computation', 'defined', 'theory', 'property', 'arbitrary']\n",
      "\n",
      "Topic #10:\n",
      "['circuit', 'chip', 'current', 'analog', 'voltage', 'neuron', 'implementation', 'processor', 'design', 'bit', 'device', 'neural', 'digital', 'array', 'parallel', 'synapse', 'computation', 'operation', 'hardware', 'implemented']\n",
      "\n",
      "Topic #11:\n",
      "['vector', 'matrix', 'linear', 'solution', 'equation', 'convergence', 'gradient', 'constraint', 'nonlinear', 'iteration', 'optimization', 'optimal', 'eq', 'update', 'minimum', 'energy', 'operator', 'gradient_descent', 'dimensional', 'quadratic']\n",
      "\n",
      "Topic #12:\n",
      "['signal', 'filter', 'source', 'frequency', 'channel', 'noise', 'component', 'detection', 'sound', 'auditory', 'ica', 'response', 'phase', 'temporal', 'amplitude', 'correlation', 'eeg', 'separation', 'processing', 'spectral']\n",
      "\n",
      "Topic #13:\n",
      "['noise', 'equation', 'rate', 'curve', 'average', 'theory', 'correlation', 'distribution', 'limit', 'stochastic', 'optimal', 'solution', 'eq', 'line', 'generalization_error', 'teacher', 'asymptotic', 'temperature', 'effect', 'size']\n",
      "\n",
      "Topic #14:\n",
      "['control', 'position', 'character', 'trajectory', 'human', 'hand', 'field', 'subject', 'task', 'mapping', 'movement', 'forward', 'user', 'arm', 'target', 'change', 'force', 'joint', 'motor', 'feedback']\n",
      "\n",
      "Topic #15:\n",
      "['search', 'code', 'rate', 'bit', 'solution', 'cost', 'size', 'feature', 'path', 'block', 'high', 'table', 'call', 'application', 'probability', 'machine', 'run', 'random', 'program', 'experiment']\n",
      "\n",
      "Topic #16:\n",
      "['image', 'object', 'feature', 'pixel', 'region', 'view', 'edge', 'surface', 'local', 'shape', 'contour', 'scale', 'part', 'recognition', 'visual', 'scene', 'representation', 'location', 'vision', 'texture']\n",
      "\n",
      "Topic #17:\n",
      "['state', 'dynamic', 'memory', 'pattern', 'recurrent', 'sequence', 'attractor', 'module', 'phase', 'hopfield', 'delay', 'connection', 'transition', 'capacity', 'fixed_point', 'equation', 'neural', 'stable', 'behavior', 'oscillator']\n",
      "\n",
      "Topic #18:\n",
      "['class', 'classification', 'classifier', 'feature', 'vector', 'pattern', 'cluster', 'distance', 'face', 'clustering', 'transformation', 'database', 'digit', 'training', 'nearest_neighbor', 'training_set', 'pca', 'test', 'template', 'experiment']\n",
      "\n",
      "Topic #19:\n",
      "['word', 'recognition', 'sequence', 'speech', 'training', 'context', 'hmm', 'state', 'frame', 'letter', 'speaker', 'speech_recognition', 'feature', 'phoneme', 'experiment', 'vowel', 'probability', 'trained', 'segmentation', 'hybrid']\n",
      "\n",
      "Topic #20:\n",
      "['state', 'action', 'control', 'step', 'policy', 'controller', 'reinforcement_learning', 'task', 'environment', 'optimal', 'goal', 'robot', 'reward', 'td', 'agent', 'current', 'trial', 'rl', 'reinforcement', 'transition']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view all the 20 topics generated by selected best model\n",
    "topics = [[(term, round(wt, 3)) \n",
    "           for term, wt in best_lda_model.show_topic(n, topn=20)] \n",
    "              for n in range(0, best_lda_model.num_topics)]\n",
    "\n",
    "for idx, topic in enumerate(topics):\n",
    "    print('Topic #'+str(idx+1)+':')\n",
    "    print([term for term, wt in topic])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Term1</th>\n",
       "      <td>node</td>\n",
       "      <td>unit</td>\n",
       "      <td>neuron</td>\n",
       "      <td>motion</td>\n",
       "      <td>prediction</td>\n",
       "      <td>kernel</td>\n",
       "      <td>distribution</td>\n",
       "      <td>cell</td>\n",
       "      <td>theorem</td>\n",
       "      <td>circuit</td>\n",
       "      <td>vector</td>\n",
       "      <td>signal</td>\n",
       "      <td>noise</td>\n",
       "      <td>control</td>\n",
       "      <td>search</td>\n",
       "      <td>image</td>\n",
       "      <td>state</td>\n",
       "      <td>class</td>\n",
       "      <td>word</td>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term2</th>\n",
       "      <td>rule</td>\n",
       "      <td>training</td>\n",
       "      <td>spike</td>\n",
       "      <td>direction</td>\n",
       "      <td>training</td>\n",
       "      <td>loss</td>\n",
       "      <td>probability</td>\n",
       "      <td>activity</td>\n",
       "      <td>bound</td>\n",
       "      <td>chip</td>\n",
       "      <td>matrix</td>\n",
       "      <td>filter</td>\n",
       "      <td>equation</td>\n",
       "      <td>position</td>\n",
       "      <td>code</td>\n",
       "      <td>object</td>\n",
       "      <td>dynamic</td>\n",
       "      <td>classification</td>\n",
       "      <td>recognition</td>\n",
       "      <td>action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term3</th>\n",
       "      <td>structure</td>\n",
       "      <td>layer</td>\n",
       "      <td>synaptic</td>\n",
       "      <td>visual</td>\n",
       "      <td>test</td>\n",
       "      <td>sample</td>\n",
       "      <td>prior</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>threshold</td>\n",
       "      <td>current</td>\n",
       "      <td>linear</td>\n",
       "      <td>source</td>\n",
       "      <td>rate</td>\n",
       "      <td>character</td>\n",
       "      <td>rate</td>\n",
       "      <td>feature</td>\n",
       "      <td>memory</td>\n",
       "      <td>classifier</td>\n",
       "      <td>sequence</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term4</th>\n",
       "      <td>representation</td>\n",
       "      <td>net</td>\n",
       "      <td>firing</td>\n",
       "      <td>response</td>\n",
       "      <td>regression</td>\n",
       "      <td>class</td>\n",
       "      <td>gaussian</td>\n",
       "      <td>response</td>\n",
       "      <td>approximation</td>\n",
       "      <td>analog</td>\n",
       "      <td>solution</td>\n",
       "      <td>frequency</td>\n",
       "      <td>curve</td>\n",
       "      <td>trajectory</td>\n",
       "      <td>bit</td>\n",
       "      <td>pixel</td>\n",
       "      <td>pattern</td>\n",
       "      <td>feature</td>\n",
       "      <td>speech</td>\n",
       "      <td>step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term5</th>\n",
       "      <td>tree</td>\n",
       "      <td>hidden_unit</td>\n",
       "      <td>cell</td>\n",
       "      <td>target</td>\n",
       "      <td>experiment</td>\n",
       "      <td>machine</td>\n",
       "      <td>variable</td>\n",
       "      <td>layer</td>\n",
       "      <td>class</td>\n",
       "      <td>voltage</td>\n",
       "      <td>equation</td>\n",
       "      <td>channel</td>\n",
       "      <td>average</td>\n",
       "      <td>human</td>\n",
       "      <td>solution</td>\n",
       "      <td>region</td>\n",
       "      <td>recurrent</td>\n",
       "      <td>vector</td>\n",
       "      <td>training</td>\n",
       "      <td>policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term6</th>\n",
       "      <td>level</td>\n",
       "      <td>pattern</td>\n",
       "      <td>synapsis</td>\n",
       "      <td>location</td>\n",
       "      <td>selection</td>\n",
       "      <td>distribution</td>\n",
       "      <td>mixture</td>\n",
       "      <td>pattern</td>\n",
       "      <td>proof</td>\n",
       "      <td>neuron</td>\n",
       "      <td>convergence</td>\n",
       "      <td>noise</td>\n",
       "      <td>theory</td>\n",
       "      <td>hand</td>\n",
       "      <td>cost</td>\n",
       "      <td>view</td>\n",
       "      <td>sequence</td>\n",
       "      <td>pattern</td>\n",
       "      <td>context</td>\n",
       "      <td>controller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term7</th>\n",
       "      <td>symbol</td>\n",
       "      <td>architecture</td>\n",
       "      <td>activity</td>\n",
       "      <td>velocity</td>\n",
       "      <td>expert</td>\n",
       "      <td>hypothesis</td>\n",
       "      <td>density</td>\n",
       "      <td>map</td>\n",
       "      <td>size</td>\n",
       "      <td>implementation</td>\n",
       "      <td>gradient</td>\n",
       "      <td>component</td>\n",
       "      <td>correlation</td>\n",
       "      <td>field</td>\n",
       "      <td>size</td>\n",
       "      <td>edge</td>\n",
       "      <td>attractor</td>\n",
       "      <td>cluster</td>\n",
       "      <td>hmm</td>\n",
       "      <td>reinforcement_learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term8</th>\n",
       "      <td>string</td>\n",
       "      <td>task</td>\n",
       "      <td>response</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>rbf</td>\n",
       "      <td>training</td>\n",
       "      <td>bayesian</td>\n",
       "      <td>receptive_field</td>\n",
       "      <td>polynomial</td>\n",
       "      <td>processor</td>\n",
       "      <td>constraint</td>\n",
       "      <td>detection</td>\n",
       "      <td>distribution</td>\n",
       "      <td>subject</td>\n",
       "      <td>feature</td>\n",
       "      <td>surface</td>\n",
       "      <td>module</td>\n",
       "      <td>distance</td>\n",
       "      <td>state</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term9</th>\n",
       "      <td>graph</td>\n",
       "      <td>trained</td>\n",
       "      <td>threshold</td>\n",
       "      <td>position</td>\n",
       "      <td>trained</td>\n",
       "      <td>concept</td>\n",
       "      <td>estimate</td>\n",
       "      <td>cortical</td>\n",
       "      <td>complexity</td>\n",
       "      <td>design</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>sound</td>\n",
       "      <td>limit</td>\n",
       "      <td>task</td>\n",
       "      <td>path</td>\n",
       "      <td>local</td>\n",
       "      <td>phase</td>\n",
       "      <td>face</td>\n",
       "      <td>frame</td>\n",
       "      <td>environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term10</th>\n",
       "      <td>language</td>\n",
       "      <td>activation</td>\n",
       "      <td>current</td>\n",
       "      <td>cue</td>\n",
       "      <td>sample</td>\n",
       "      <td>estimate</td>\n",
       "      <td>approximation</td>\n",
       "      <td>cortex</td>\n",
       "      <td>definition</td>\n",
       "      <td>bit</td>\n",
       "      <td>iteration</td>\n",
       "      <td>auditory</td>\n",
       "      <td>stochastic</td>\n",
       "      <td>mapping</td>\n",
       "      <td>block</td>\n",
       "      <td>shape</td>\n",
       "      <td>hopfield</td>\n",
       "      <td>clustering</td>\n",
       "      <td>letter</td>\n",
       "      <td>optimal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term11</th>\n",
       "      <td>connectionist</td>\n",
       "      <td>back_propagation</td>\n",
       "      <td>neural</td>\n",
       "      <td>light</td>\n",
       "      <td>training_set</td>\n",
       "      <td>query</td>\n",
       "      <td>likelihood</td>\n",
       "      <td>orientation</td>\n",
       "      <td>bounded</td>\n",
       "      <td>device</td>\n",
       "      <td>optimization</td>\n",
       "      <td>ica</td>\n",
       "      <td>optimal</td>\n",
       "      <td>movement</td>\n",
       "      <td>high</td>\n",
       "      <td>contour</td>\n",
       "      <td>delay</td>\n",
       "      <td>transformation</td>\n",
       "      <td>speaker</td>\n",
       "      <td>goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term12</th>\n",
       "      <td>sequence</td>\n",
       "      <td>hidden_layer</td>\n",
       "      <td>neuronal</td>\n",
       "      <td>task</td>\n",
       "      <td>local</td>\n",
       "      <td>xi</td>\n",
       "      <td>log</td>\n",
       "      <td>connection</td>\n",
       "      <td>probability</td>\n",
       "      <td>neural</td>\n",
       "      <td>optimal</td>\n",
       "      <td>response</td>\n",
       "      <td>solution</td>\n",
       "      <td>forward</td>\n",
       "      <td>table</td>\n",
       "      <td>scale</td>\n",
       "      <td>connection</td>\n",
       "      <td>database</td>\n",
       "      <td>speech_recognition</td>\n",
       "      <td>robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term13</th>\n",
       "      <td>represented</td>\n",
       "      <td>hidden</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>sensory</td>\n",
       "      <td>estimate</td>\n",
       "      <td>generalization</td>\n",
       "      <td>component</td>\n",
       "      <td>unit</td>\n",
       "      <td>assume</td>\n",
       "      <td>digital</td>\n",
       "      <td>eq</td>\n",
       "      <td>phase</td>\n",
       "      <td>eq</td>\n",
       "      <td>user</td>\n",
       "      <td>call</td>\n",
       "      <td>part</td>\n",
       "      <td>transition</td>\n",
       "      <td>digit</td>\n",
       "      <td>feature</td>\n",
       "      <td>reward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term14</th>\n",
       "      <td>part</td>\n",
       "      <td>connection</td>\n",
       "      <td>firing_rate</td>\n",
       "      <td>unit</td>\n",
       "      <td>table</td>\n",
       "      <td>target</td>\n",
       "      <td>sample</td>\n",
       "      <td>region</td>\n",
       "      <td>linear</td>\n",
       "      <td>array</td>\n",
       "      <td>update</td>\n",
       "      <td>temporal</td>\n",
       "      <td>line</td>\n",
       "      <td>arm</td>\n",
       "      <td>application</td>\n",
       "      <td>recognition</td>\n",
       "      <td>capacity</td>\n",
       "      <td>training</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>td</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term15</th>\n",
       "      <td>role</td>\n",
       "      <td>learn</td>\n",
       "      <td>et_al</td>\n",
       "      <td>moving</td>\n",
       "      <td>technique</td>\n",
       "      <td>probability</td>\n",
       "      <td>em</td>\n",
       "      <td>contrast</td>\n",
       "      <td>constant</td>\n",
       "      <td>parallel</td>\n",
       "      <td>minimum</td>\n",
       "      <td>amplitude</td>\n",
       "      <td>generalization_error</td>\n",
       "      <td>target</td>\n",
       "      <td>probability</td>\n",
       "      <td>visual</td>\n",
       "      <td>fixed_point</td>\n",
       "      <td>nearest_neighbor</td>\n",
       "      <td>experiment</td>\n",
       "      <td>agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term16</th>\n",
       "      <td>activation</td>\n",
       "      <td>generalization</td>\n",
       "      <td>effect</td>\n",
       "      <td>eye</td>\n",
       "      <td>linear</td>\n",
       "      <td>bound</td>\n",
       "      <td>estimation</td>\n",
       "      <td>center</td>\n",
       "      <td>computation</td>\n",
       "      <td>synapse</td>\n",
       "      <td>energy</td>\n",
       "      <td>correlation</td>\n",
       "      <td>teacher</td>\n",
       "      <td>change</td>\n",
       "      <td>machine</td>\n",
       "      <td>scene</td>\n",
       "      <td>equation</td>\n",
       "      <td>training_set</td>\n",
       "      <td>vowel</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term17</th>\n",
       "      <td>represent</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>constant</td>\n",
       "      <td>spatial</td>\n",
       "      <td>time_series</td>\n",
       "      <td>margin</td>\n",
       "      <td>posterior</td>\n",
       "      <td>visual</td>\n",
       "      <td>defined</td>\n",
       "      <td>computation</td>\n",
       "      <td>operator</td>\n",
       "      <td>eeg</td>\n",
       "      <td>asymptotic</td>\n",
       "      <td>force</td>\n",
       "      <td>run</td>\n",
       "      <td>representation</td>\n",
       "      <td>neural</td>\n",
       "      <td>pca</td>\n",
       "      <td>probability</td>\n",
       "      <td>trial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term18</th>\n",
       "      <td>note</td>\n",
       "      <td>training_set</td>\n",
       "      <td>level</td>\n",
       "      <td>head</td>\n",
       "      <td>cross_validation</td>\n",
       "      <td>optimal</td>\n",
       "      <td>variance</td>\n",
       "      <td>spatial</td>\n",
       "      <td>theory</td>\n",
       "      <td>operation</td>\n",
       "      <td>gradient_descent</td>\n",
       "      <td>separation</td>\n",
       "      <td>temperature</td>\n",
       "      <td>joint</td>\n",
       "      <td>random</td>\n",
       "      <td>location</td>\n",
       "      <td>stable</td>\n",
       "      <td>test</td>\n",
       "      <td>trained</td>\n",
       "      <td>rl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term19</th>\n",
       "      <td>mapping</td>\n",
       "      <td>epoch</td>\n",
       "      <td>pattern</td>\n",
       "      <td>stage</td>\n",
       "      <td>nonlinear</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>probabilistic</td>\n",
       "      <td>effect</td>\n",
       "      <td>property</td>\n",
       "      <td>hardware</td>\n",
       "      <td>dimensional</td>\n",
       "      <td>processing</td>\n",
       "      <td>effect</td>\n",
       "      <td>motor</td>\n",
       "      <td>program</td>\n",
       "      <td>vision</td>\n",
       "      <td>behavior</td>\n",
       "      <td>template</td>\n",
       "      <td>segmentation</td>\n",
       "      <td>reinforcement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term20</th>\n",
       "      <td>grammar</td>\n",
       "      <td>target</td>\n",
       "      <td>biological</td>\n",
       "      <td>sensor</td>\n",
       "      <td>fit</td>\n",
       "      <td>regularization</td>\n",
       "      <td>step</td>\n",
       "      <td>brain</td>\n",
       "      <td>arbitrary</td>\n",
       "      <td>implemented</td>\n",
       "      <td>quadratic</td>\n",
       "      <td>spectral</td>\n",
       "      <td>size</td>\n",
       "      <td>feedback</td>\n",
       "      <td>experiment</td>\n",
       "      <td>texture</td>\n",
       "      <td>oscillator</td>\n",
       "      <td>experiment</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>transition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Topic 1           Topic 2      Topic 3    Topic 4  \\\n",
       "Term1             node              unit       neuron     motion   \n",
       "Term2             rule          training        spike  direction   \n",
       "Term3        structure             layer     synaptic     visual   \n",
       "Term4   representation               net       firing   response   \n",
       "Term5             tree       hidden_unit         cell     target   \n",
       "Term6            level           pattern     synapsis   location   \n",
       "Term7           symbol      architecture     activity   velocity   \n",
       "Term8           string              task     response   stimulus   \n",
       "Term9            graph           trained    threshold   position   \n",
       "Term10        language        activation      current        cue   \n",
       "Term11   connectionist  back_propagation       neural      light   \n",
       "Term12        sequence      hidden_layer     neuronal       task   \n",
       "Term13     represented            hidden     stimulus    sensory   \n",
       "Term14            part        connection  firing_rate       unit   \n",
       "Term15            role             learn        et_al     moving   \n",
       "Term16      activation    generalization       effect        eye   \n",
       "Term17       represent   backpropagation     constant    spatial   \n",
       "Term18            note      training_set        level       head   \n",
       "Term19         mapping             epoch      pattern      stage   \n",
       "Term20         grammar            target   biological     sensor   \n",
       "\n",
       "                 Topic 5         Topic 6        Topic 7          Topic 8  \\\n",
       "Term1         prediction          kernel   distribution             cell   \n",
       "Term2           training            loss    probability         activity   \n",
       "Term3               test          sample          prior         stimulus   \n",
       "Term4         regression           class       gaussian         response   \n",
       "Term5         experiment         machine       variable            layer   \n",
       "Term6          selection    distribution        mixture          pattern   \n",
       "Term7             expert      hypothesis        density              map   \n",
       "Term8                rbf        training       bayesian  receptive_field   \n",
       "Term9            trained         concept       estimate         cortical   \n",
       "Term10            sample        estimate  approximation           cortex   \n",
       "Term11      training_set           query     likelihood      orientation   \n",
       "Term12             local              xi            log       connection   \n",
       "Term13          estimate  generalization      component             unit   \n",
       "Term14             table          target         sample           region   \n",
       "Term15         technique     probability             em         contrast   \n",
       "Term16            linear           bound     estimation           center   \n",
       "Term17       time_series          margin      posterior           visual   \n",
       "Term18  cross_validation         optimal       variance          spatial   \n",
       "Term19         nonlinear  support_vector  probabilistic           effect   \n",
       "Term20               fit  regularization           step            brain   \n",
       "\n",
       "              Topic 9        Topic 10          Topic 11     Topic 12  \\\n",
       "Term1         theorem         circuit            vector       signal   \n",
       "Term2           bound            chip            matrix       filter   \n",
       "Term3       threshold         current            linear       source   \n",
       "Term4   approximation          analog          solution    frequency   \n",
       "Term5           class         voltage          equation      channel   \n",
       "Term6           proof          neuron       convergence        noise   \n",
       "Term7            size  implementation          gradient    component   \n",
       "Term8      polynomial       processor        constraint    detection   \n",
       "Term9      complexity          design         nonlinear        sound   \n",
       "Term10     definition             bit         iteration     auditory   \n",
       "Term11        bounded          device      optimization          ica   \n",
       "Term12    probability          neural           optimal     response   \n",
       "Term13         assume         digital                eq        phase   \n",
       "Term14         linear           array            update     temporal   \n",
       "Term15       constant        parallel           minimum    amplitude   \n",
       "Term16    computation         synapse            energy  correlation   \n",
       "Term17        defined     computation          operator          eeg   \n",
       "Term18         theory       operation  gradient_descent   separation   \n",
       "Term19       property        hardware       dimensional   processing   \n",
       "Term20      arbitrary     implemented         quadratic     spectral   \n",
       "\n",
       "                    Topic 13    Topic 14     Topic 15        Topic 16  \\\n",
       "Term1                  noise     control       search           image   \n",
       "Term2               equation    position         code          object   \n",
       "Term3                   rate   character         rate         feature   \n",
       "Term4                  curve  trajectory          bit           pixel   \n",
       "Term5                average       human     solution          region   \n",
       "Term6                 theory        hand         cost            view   \n",
       "Term7            correlation       field         size            edge   \n",
       "Term8           distribution     subject      feature         surface   \n",
       "Term9                  limit        task         path           local   \n",
       "Term10            stochastic     mapping        block           shape   \n",
       "Term11               optimal    movement         high         contour   \n",
       "Term12              solution     forward        table           scale   \n",
       "Term13                    eq        user         call            part   \n",
       "Term14                  line         arm  application     recognition   \n",
       "Term15  generalization_error      target  probability          visual   \n",
       "Term16               teacher      change      machine           scene   \n",
       "Term17            asymptotic       force          run  representation   \n",
       "Term18           temperature       joint       random        location   \n",
       "Term19                effect       motor      program          vision   \n",
       "Term20                  size    feedback   experiment         texture   \n",
       "\n",
       "           Topic 17          Topic 18            Topic 19  \\\n",
       "Term1         state             class                word   \n",
       "Term2       dynamic    classification         recognition   \n",
       "Term3        memory        classifier            sequence   \n",
       "Term4       pattern           feature              speech   \n",
       "Term5     recurrent            vector            training   \n",
       "Term6      sequence           pattern             context   \n",
       "Term7     attractor           cluster                 hmm   \n",
       "Term8        module          distance               state   \n",
       "Term9         phase              face               frame   \n",
       "Term10     hopfield        clustering              letter   \n",
       "Term11        delay    transformation             speaker   \n",
       "Term12   connection          database  speech_recognition   \n",
       "Term13   transition             digit             feature   \n",
       "Term14     capacity          training             phoneme   \n",
       "Term15  fixed_point  nearest_neighbor          experiment   \n",
       "Term16     equation      training_set               vowel   \n",
       "Term17       neural               pca         probability   \n",
       "Term18       stable              test             trained   \n",
       "Term19     behavior          template        segmentation   \n",
       "Term20   oscillator        experiment              hybrid   \n",
       "\n",
       "                      Topic 20  \n",
       "Term1                    state  \n",
       "Term2                   action  \n",
       "Term3                  control  \n",
       "Term4                     step  \n",
       "Term5                   policy  \n",
       "Term6               controller  \n",
       "Term7   reinforcement_learning  \n",
       "Term8                     task  \n",
       "Term9              environment  \n",
       "Term10                 optimal  \n",
       "Term11                    goal  \n",
       "Term12                   robot  \n",
       "Term13                  reward  \n",
       "Term14                      td  \n",
       "Term15                   agent  \n",
       "Term16                 current  \n",
       "Term17                   trial  \n",
       "Term18                      rl  \n",
       "Term19           reinforcement  \n",
       "Term20              transition  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build term topic dataframe\n",
    "topics_df = pd.DataFrame([[term for term, wt in topic] \n",
    "                              for topic in topics], \n",
    "                         columns=['Term'+str(i) for i in range(1,21)], \n",
    "                         index=['Topic '+str(t) for t in range(1, best_lda_model.num_topics+1)]).T\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>node, rule, structure, representation, tree, level, symbol, string, graph, language, connectionist, sequence, represented, part, role, activation, represent, note, mapping, grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>unit, training, layer, net, hidden_unit, pattern, architecture, task, trained, activation, back_propagation, hidden_layer, hidden, connection, learn, generalization, backpropagation, training_set, epoch, target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>neuron, spike, synaptic, firing, cell, synapsis, activity, response, threshold, current, neural, neuronal, stimulus, firing_rate, et_al, effect, constant, level, pattern, biological</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>motion, direction, visual, response, target, location, velocity, stimulus, position, cue, light, task, sensory, unit, moving, eye, spatial, head, stage, sensor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>prediction, training, test, regression, experiment, selection, expert, rbf, trained, sample, training_set, local, estimate, table, technique, linear, time_series, cross_validation, nonlinear, fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>kernel, loss, sample, class, machine, distribution, hypothesis, training, concept, estimate, query, xi, generalization, target, probability, bound, margin, optimal, support_vector, regularization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, likelihood, log, component, sample, em, estimation, posterior, variance, probabilistic, step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>cell, activity, stimulus, response, layer, pattern, map, receptive_field, cortical, cortex, orientation, connection, unit, region, contrast, center, visual, spatial, effect, brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>theorem, bound, threshold, approximation, class, proof, size, polynomial, complexity, definition, bounded, probability, assume, linear, constant, computation, defined, theory, property, arbitrary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>circuit, chip, current, analog, voltage, neuron, implementation, processor, design, bit, device, neural, digital, array, parallel, synapse, computation, operation, hardware, implemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>vector, matrix, linear, solution, equation, convergence, gradient, constraint, nonlinear, iteration, optimization, optimal, eq, update, minimum, energy, operator, gradient_descent, dimensional, quadratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>signal, filter, source, frequency, channel, noise, component, detection, sound, auditory, ica, response, phase, temporal, amplitude, correlation, eeg, separation, processing, spectral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>noise, equation, rate, curve, average, theory, correlation, distribution, limit, stochastic, optimal, solution, eq, line, generalization_error, teacher, asymptotic, temperature, effect, size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>control, position, character, trajectory, human, hand, field, subject, task, mapping, movement, forward, user, arm, target, change, force, joint, motor, feedback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>search, code, rate, bit, solution, cost, size, feature, path, block, high, table, call, application, probability, machine, run, random, program, experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>image, object, feature, pixel, region, view, edge, surface, local, shape, contour, scale, part, recognition, visual, scene, representation, location, vision, texture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>state, dynamic, memory, pattern, recurrent, sequence, attractor, module, phase, hopfield, delay, connection, transition, capacity, fixed_point, equation, neural, stable, behavior, oscillator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>class, classification, classifier, feature, vector, pattern, cluster, distance, face, clustering, transformation, database, digit, training, nearest_neighbor, training_set, pca, test, template, experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>word, recognition, sequence, speech, training, context, hmm, state, frame, letter, speaker, speech_recognition, feature, phoneme, experiment, vowel, probability, trained, segmentation, hybrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>state, action, control, step, policy, controller, reinforcement_learning, task, environment, optimal, goal, robot, reward, td, agent, current, trial, rl, reinforcement, transition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                            Terms per Topic\n",
       "Topic1   node, rule, structure, representation, tree, level, symbol, string, graph, language, connectionist, sequence, represented, part, role, activation, represent, note, mapping, grammar                              \n",
       "Topic2   unit, training, layer, net, hidden_unit, pattern, architecture, task, trained, activation, back_propagation, hidden_layer, hidden, connection, learn, generalization, backpropagation, training_set, epoch, target\n",
       "Topic3   neuron, spike, synaptic, firing, cell, synapsis, activity, response, threshold, current, neural, neuronal, stimulus, firing_rate, et_al, effect, constant, level, pattern, biological                             \n",
       "Topic4   motion, direction, visual, response, target, location, velocity, stimulus, position, cue, light, task, sensory, unit, moving, eye, spatial, head, stage, sensor                                                   \n",
       "Topic5   prediction, training, test, regression, experiment, selection, expert, rbf, trained, sample, training_set, local, estimate, table, technique, linear, time_series, cross_validation, nonlinear, fit               \n",
       "Topic6   kernel, loss, sample, class, machine, distribution, hypothesis, training, concept, estimate, query, xi, generalization, target, probability, bound, margin, optimal, support_vector, regularization               \n",
       "Topic7   distribution, probability, prior, gaussian, variable, mixture, density, bayesian, estimate, approximation, likelihood, log, component, sample, em, estimation, posterior, variance, probabilistic, step           \n",
       "Topic8   cell, activity, stimulus, response, layer, pattern, map, receptive_field, cortical, cortex, orientation, connection, unit, region, contrast, center, visual, spatial, effect, brain                               \n",
       "Topic9   theorem, bound, threshold, approximation, class, proof, size, polynomial, complexity, definition, bounded, probability, assume, linear, constant, computation, defined, theory, property, arbitrary               \n",
       "Topic10  circuit, chip, current, analog, voltage, neuron, implementation, processor, design, bit, device, neural, digital, array, parallel, synapse, computation, operation, hardware, implemented                         \n",
       "Topic11  vector, matrix, linear, solution, equation, convergence, gradient, constraint, nonlinear, iteration, optimization, optimal, eq, update, minimum, energy, operator, gradient_descent, dimensional, quadratic       \n",
       "Topic12  signal, filter, source, frequency, channel, noise, component, detection, sound, auditory, ica, response, phase, temporal, amplitude, correlation, eeg, separation, processing, spectral                           \n",
       "Topic13  noise, equation, rate, curve, average, theory, correlation, distribution, limit, stochastic, optimal, solution, eq, line, generalization_error, teacher, asymptotic, temperature, effect, size                    \n",
       "Topic14  control, position, character, trajectory, human, hand, field, subject, task, mapping, movement, forward, user, arm, target, change, force, joint, motor, feedback                                                 \n",
       "Topic15  search, code, rate, bit, solution, cost, size, feature, path, block, high, table, call, application, probability, machine, run, random, program, experiment                                                       \n",
       "Topic16  image, object, feature, pixel, region, view, edge, surface, local, shape, contour, scale, part, recognition, visual, scene, representation, location, vision, texture                                             \n",
       "Topic17  state, dynamic, memory, pattern, recurrent, sequence, attractor, module, phase, hopfield, delay, connection, transition, capacity, fixed_point, equation, neural, stable, behavior, oscillator                    \n",
       "Topic18  class, classification, classifier, feature, vector, pattern, cluster, distance, face, clustering, transformation, database, digit, training, nearest_neighbor, training_set, pca, test, template, experiment      \n",
       "Topic19  word, recognition, sequence, speech, training, context, hmm, state, frame, letter, speaker, speech_recognition, feature, phoneme, experiment, vowel, probability, trained, segmentation, hybrid                   \n",
       "Topic20  state, action, control, step, policy, controller, reinforcement_learning, task, environment, optimal, goal, robot, reward, td, agent, current, trial, rl, reinforcement, transition                               "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create topic term dataframe: each topic represented in a row with terms of topic\n",
    "# represented as comma-separated string\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) \n",
    "                              for topic in topics], \n",
    "                         columns=['Terms per Topic'], \n",
    "                         index=['Topic'+str(t) for t in range (1, best_lda_model.num_topics+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '/mnt/batch/tasks/shared/LS_root/mounts/clusters/bellepracticevm/code/Users/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/9db6d6_corpus.txt --output /tmp/9db6d6_corpus.mallet.infer --use-pipe-from /tmp/9db6d6_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1f39ef2ab1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Interpreting Topic Model Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtm_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_lda_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbow_corpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get most dominant topic per research paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorpus_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtm_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, iterations)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' infer-topics --input %s --inferencer %s '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '/mnt/batch/tasks/shared/LS_root/mounts/clusters/bellepracticevm/code/Users/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/9db6d6_corpus.txt --output /tmp/9db6d6_corpus.mallet.infer --use-pipe-from /tmp/9db6d6_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "## Interpreting Topic Model Results\n",
    "tm_results = best_lda_model[bow_corpus]\n",
    "\n",
    "# get most dominant topic per research paper\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in tm_results]\n",
    "corpus_topics[:5]\n",
    "\n",
    "# construct master dataframe that holds base statistics\n",
    "corpus_topic_df = pd.DataFrame()\n",
    "corpus_topic_df['Document'] = range(0, len(papers))\n",
    "corpus_topic_df['Dominant Topic'] = [item[0]+1 for item in corpus_topics]\n",
    "corpus_topic_df['Contribution %'] = [round(item[1]*100, 2) for item in corpus_topics]\n",
    "corpus_topic_df['Topic Desc'] = [topics_df.iloc[t[0]]['Terms per Topic'] for t in corpus_topics]\n",
    "corpus_topic_df['Paper'] = papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_topic_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-f899fc53f80d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Dominant Topics Distribution Across Corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg(\n\u001b[0m\u001b[1;32m      4\u001b[0m     {'Dominant Topic': {'Doc Count': np.size, '% Total Docs': np.size }})\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_topic_df' is not defined"
     ]
    }
   ],
   "source": [
    "## Dominant Topics Distribution Across Corpus\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "topic_stats_df = corpus_topic_df.groupby('Dominant Topic').agg(\n",
    "    {'Dominant Topic': {'Doc Count': np.size, '% Total Docs': np.size }})\n",
    "\n",
    "topic_stats_df = topic_stats_df['Dominant Topic'].reset_index()\n",
    "topic_stats_df['% Total Docs'] = topic_stats_df['% Total Docs'].apply(\n",
    "    lambda row: round((row*100) / len(papers), 2))\n",
    "\n",
    "topic_stats_df['Topic Desc'] = [topics_df.iloc[t]['Terms per Topic'] \n",
    "                                for t in range(len(topic_stats_df))]\n",
    "topic_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_topic_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-608deb277b13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Dominant Topics in Specific Research Papers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m (corpus_topic_df[corpus_topic_df['Document'].isin(\n\u001b[0m\u001b[1;32m      4\u001b[0m     [681, 9, 392, 1622, 17, 906, 996, 503, 13, 733])])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_topic_df' is not defined"
     ]
    }
   ],
   "source": [
    "## Dominant Topics in Specific Research Papers\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "(corpus_topic_df[corpus_topic_df['Document'].isin(\n",
    "    [681, 9, 392, 1622, 17, 906, 996, 503, 13, 733])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_topic_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-ebe8d3f447e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Relevant Research Papers per Topic Based on Dominance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: \n\u001b[0m\u001b[1;32m      3\u001b[0m                                                 (topic_set.sort_values(by=['Contribution %'], \n\u001b[1;32m      4\u001b[0m                                                                        ascending=False).iloc[0]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_topic_df' is not defined"
     ]
    }
   ],
   "source": [
    "## Relevant Research Papers per Topic Based on Dominance\n",
    "corpus_topic_df.groupby('Dominant Topic').apply(lambda topic_set: \n",
    "                                                (topic_set.sort_values(by=['Contribution %'], \n",
    "                                                                       ascending=False).iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total New Papers 4\n"
     ]
    }
   ],
   "source": [
    "## Predicting Topics for New Research Papers\n",
    "import glob\n",
    "# papers manually downloaded from NIPS 16\n",
    "# https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
    "\n",
    "new_paper_files = glob.glob('test_data/nips16*.txt')\n",
    "new_papers = []\n",
    "for fn in new_paper_files:\n",
    "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "        data = f.read()\n",
    "        new_papers.append(data)\n",
    "print('Total New Papers', len(new_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cooperative', 'graphical_model', 'josip', 'djolonga', 'dept_computer', 'science', 'eth', 'zurich', 'josipd', 'inf', 'ethz', 'ch', 'stefanie', 'jegelka', 'csail', 'mit', 'stefje', 'mit_edu', 'sebastian', 'tschiatschek', 'dept_computer', 'science', 'eth', 'zurich', 'stschia', 'inf', 'ethz', 'ch', 'andreas', 'krause']\n"
     ]
    }
   ],
   "source": [
    "# build text wrangling and feature engineering pipeline\n",
    "def text_preprocessing_pipeline(documents, normalizer_fn, bigram_model):\n",
    "    norm_docs = normalizer_fn(documents)\n",
    "    norm_docs_bigrams = bigram_model[norm_docs]\n",
    "    return norm_docs_bigrams\n",
    "\n",
    "def bow_features_pipeline(tokenized_docs, dictionary):\n",
    "    paper_bow_features = [dictionary.doc2bow(text) \n",
    "        for text in tokenized_docs]\n",
    "    return paper_bow_features\n",
    "\n",
    "norm_new_papers = text_preprocessing_pipeline(documents=new_papers, normalizer_fn=normalize_corpus, bigram_model=bigram_model)\n",
    "\n",
    "norm_bow_features = bow_features_pipeline(tokenized_docs=norm_new_papers, dictionary=dictionary)\n",
    "\n",
    "print(norm_new_papers[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14, 1), (16, 1), (20, 1), (21, 2), (22, 2), (23, 3), (26, 1), (27, 4), (28, 1), (29, 2), (35, 1), (37, 3), (40, 7), (56, 1), (57, 2), (58, 1), (59, 5), (60, 7), (63, 1), (68, 2), (70, 4), (71, 2), (72, 1), (73, 2), (74, 5), (78, 1), (79, 1), (80, 1), (86, 1), (91, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(norm_bow_features[0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '/mnt/batch/tasks/shared/LS_root/mounts/clusters/bellepracticevm/code/Users/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/9db6d6_corpus.txt --output /tmp/9db6d6_corpus.mallet.infer --use-pipe-from /tmp/9db6d6_corpus.mallet' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-35e6d81d76c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# putting the function in action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtopic_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_topic_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbest_lda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_bow_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtopic_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-35e6d81d76c1>\u001b[0m in \u001b[0;36mget_topic_predictions\u001b[0;34m(topic_model, corpus, topn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# build generic fuction to extract top N topics from any research paper using trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_topic_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtopic_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     best_topics = [[(topic, round(wt, 3)) \n\u001b[1;32m      5\u001b[0m                         for topic, wt in sorted(topic_predictions[i], \n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, bow, iterations)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mbow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmallet_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' infer-topics --input %s --inferencer %s '\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/gensim/models/wrappers/ldamallet.py\u001b[0m in \u001b[0;36mconvert_input\u001b[0;34m(self, corpus, infer, serialize_corpus)\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpustxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcorpusmallet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting temporary corpus to MALLET format with %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(stdout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '/mnt/batch/tasks/shared/LS_root/mounts/clusters/bellepracticevm/code/Users/mallet-2.0.8/bin/mallet import-file --preserve-case --keep-sequence --remove-stopwords --token-regex \"\\S+\" --input /tmp/9db6d6_corpus.txt --output /tmp/9db6d6_corpus.mallet.infer --use-pipe-from /tmp/9db6d6_corpus.mallet' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# build generic fuction to extract top N topics from any research paper using trained model\n",
    "def get_topic_predictions(topic_model, corpus, topn=3):\n",
    "    topic_predictions = topic_model[corpus]\n",
    "    best_topics = [[(topic, round(wt, 3)) \n",
    "                        for topic, wt in sorted(topic_predictions[i], \n",
    "                                                key=lambda row: -row[1])[:topn]] \n",
    "                            for i in range(len(topic_predictions))]\n",
    "    return best_topics\n",
    "# putting the function in action\n",
    "topic_preds = get_topic_predictions(topic_model=best_lda_model, corpus=norm_bow_features, topn=2)\n",
    "topic_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-faff091c4895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Papers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_papers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Dominant Topics'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtopic_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_preds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m res = results_df.set_index(['Papers'])['Dominant Topics'].apply(\n\u001b[1;32m      6\u001b[0m     pd.Series).stack().reset_index(level=1, drop=True)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topic_preds' is not defined"
     ]
    }
   ],
   "source": [
    "# review results for each paper\n",
    "results_df = pd.DataFrame()\n",
    "results_df['Papers'] = range(1, len(new_papers)+1)\n",
    "results_df['Dominant Topics'] = [[topic_num+1 for topic_num, wt in item] for item in topic_preds]\n",
    "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(\n",
    "    pd.Series).stack().reset_index(level=1, drop=True)\n",
    "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
    "results_df['Contribution %'] = [topic_wt for topic_list in \n",
    "                                        [[round(wt*100, 2) \n",
    "                                              for topic_num, wt in item] \n",
    "                                                 for item in topic_preds] \n",
    "                                    for topic_wt in topic_list]\n",
    "\n",
    "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic'] for t in results_df['Dominant Topics'].values]\n",
    "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Papers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Papers\n",
       "0       1\n",
       "1       2\n",
       "2       3\n",
       "3       4"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 300)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size 14408\n"
     ]
    }
   ],
   "source": [
    "## Text Representation with Feature Engineering\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=20, max_df=0.6, ngram_range=(1,2), token_pattern=None, \n",
    "                     tokenizer=lambda doc: doc, preprocessor=lambda doc: doc)\n",
    "cv_features = cv.fit_transform(norm_papers)\n",
    "cv_features.shape\n",
    "\n",
    "# validating vocabulary size\n",
    "vocabulary = np.array(cv.get_feature_names())\n",
    "print('Total Vocabulary Size', len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 1min 55s, total: 3min 38s\n",
      "Wall time: 55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Semantic Indexing\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "TOTAL_TOPICS=20\n",
    "lsi_model = TruncatedSVD(n_components=TOTAL_TOPICS, n_iter=500, random_state=42)\n",
    "document_topics = lsi_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 14408)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_terms = lsi_model.components_\n",
    "topic_terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.221), ('neuron', 0.169), ('image', 0.138), ('cell', 0.13), ('layer', 0.13), ('feature', 0.127), ('probability', 0.121), ('hidden', 0.114), ('distribution', 0.105), ('rate', 0.098), ('signal', 0.095), ('task', 0.093), ('class', 0.092), ('noise', 0.09), ('net', 0.089), ('recognition', 0.089), ('representation', 0.088), ('field', 0.082), ('rule', 0.082), ('step', 0.08)]\n",
      "--------------------------------------------------\n",
      "Direction 2: []\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #2:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.417), ('neuron', 0.39), ('response', 0.175), ('stimulus', 0.155), ('visual', 0.131), ('spike', 0.13), ('firing', 0.117), ('synaptic', 0.11), ('activity', 0.104), ('cortex', 0.097), ('field', 0.085), ('frequency', 0.085), ('direction', 0.082), ('circuit', 0.082), ('motion', 0.082)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('state', -0.289), ('probability', -0.109), ('hidden', -0.098), ('class', -0.091), ('policy', -0.081)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #3:\n",
      "==================================================\n",
      "Direction 1: [('state', 0.574), ('neuron', 0.212), ('action', 0.187), ('policy', 0.149), ('control', 0.12), ('dynamic', 0.1), ('cell', 0.083), ('reinforcement', 0.081), ('optimal', 0.075), ('reinforcement learning', 0.068)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.364), ('feature', -0.223), ('object', -0.144), ('recognition', -0.143), ('classifier', -0.111), ('class', -0.106), ('layer', -0.092), ('classification', -0.085), ('face', -0.073), ('test', -0.069)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #4:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.425), ('state', 0.326), ('object', 0.215), ('feature', 0.159), ('action', 0.147), ('visual', 0.143), ('control', 0.126), ('task', 0.111), ('policy', 0.103), ('recognition', 0.103), ('face', 0.092), ('representation', 0.086), ('motion', 0.086)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.216), ('distribution', -0.166), ('class', -0.112), ('bound', -0.109), ('probability', -0.108), ('spike', -0.104), ('variable', -0.087)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #5:\n",
      "==================================================\n",
      "Direction 1: [('layer', 0.261), ('net', 0.225), ('hidden', 0.222), ('neuron', 0.216), ('word', 0.206), ('recognition', 0.17), ('speech', 0.152), ('hidden unit', 0.11), ('architecture', 0.102), ('task', 0.094), ('activation', 0.092), ('memory', 0.091)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -0.227), ('distribution', -0.222), ('image', -0.175), ('gaussian', -0.125), ('variable', -0.112), ('density', -0.108), ('probability', -0.099), ('approximation', -0.091)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #6:\n",
      "==================================================\n",
      "Direction 1: [('cell', 0.548), ('layer', 0.139), ('word', 0.124), ('hidden', 0.111), ('classifier', 0.097), ('direction', 0.09), ('head', 0.078), ('rule', 0.073), ('rat', 0.073), ('speech', 0.071)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('neuron', -0.416), ('image', -0.336), ('circuit', -0.126), ('noise', -0.124), ('chip', -0.121), ('analog', -0.099), ('object', -0.09), ('spike', -0.075), ('signal', -0.071), ('voltage', -0.069)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #7:\n",
      "==================================================\n",
      "Direction 1: [('word', 0.294), ('recognition', 0.252), ('speech', 0.213), ('probability', 0.194), ('classifier', 0.181), ('spike', 0.179), ('state', 0.162), ('class', 0.14), ('neuron', 0.136), ('rate', 0.123), ('hmm', 0.119), ('feature', 0.112), ('classification', 0.097), ('speaker', 0.093), ('cell', 0.091)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('hidden', -0.207), ('layer', -0.179), ('hidden unit', -0.16), ('net', -0.136), ('field', -0.117)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #8:\n",
      "==================================================\n",
      "Direction 1: [('signal', 0.278), ('noise', 0.208), ('speech', 0.197), ('word', 0.165), ('hidden', 0.123), ('control', 0.117), ('motion', 0.116), ('filter', 0.108), ('frequency', 0.102)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('classifier', -0.225), ('node', -0.21), ('class', -0.197), ('feature', -0.186), ('neuron', -0.177), ('tree', -0.162), ('cell', -0.133), ('image', -0.119), ('rule', -0.115), ('object', -0.106), ('decision', -0.103)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #9:\n",
      "==================================================\n",
      "Direction 1: [('circuit', 0.244), ('control', 0.242), ('classifier', 0.229), ('chip', 0.167), ('node', 0.137), ('current', 0.132), ('analog', 0.13), ('voltage', 0.129), ('signal', 0.118), ('controller', 0.088)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('hidden', -0.27), ('neuron', -0.247), ('state', -0.175), ('distribution', -0.158), ('hidden unit', -0.143), ('layer', -0.125), ('object', -0.115), ('probability', -0.108), ('image', -0.1), ('representation', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #10:\n",
      "==================================================\n",
      "Direction 1: [('circuit', 0.245), ('cell', 0.225), ('node', 0.211), ('state', 0.183), ('image', 0.166), ('chip', 0.163), ('analog', 0.147), ('layer', 0.144), ('net', 0.12), ('voltage', 0.115)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('task', -0.201), ('rule', -0.193), ('spike', -0.166), ('feature', -0.165), ('control', -0.157), ('neuron', -0.144), ('rate', -0.134), ('stimulus', -0.116), ('classifier', -0.116), ('action', -0.112)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #11:\n",
      "==================================================\n",
      "Direction 1: [('image', 0.315), ('cell', 0.225), ('hidden', 0.205), ('spike', 0.192), ('noise', 0.163), ('rate', 0.141), ('hidden unit', 0.141), ('rule', 0.138), ('signal', 0.119), ('net', 0.111)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('field', -0.203), ('object', -0.2), ('word', -0.184), ('node', -0.161), ('motion', -0.136), ('visual', -0.134), ('neuron', -0.128), ('structure', -0.121), ('tree', -0.119), ('map', -0.107)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #12:\n",
      "==================================================\n",
      "Direction 1: [('rule', 0.581), ('representation', 0.156), ('word', 0.146), ('memory', 0.137), ('structure', 0.125), ('matrix', 0.108), ('cell', 0.086)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('classifier', -0.293), ('layer', -0.17), ('hidden', -0.16), ('motion', -0.129), ('neuron', -0.129), ('field', -0.12), ('class', -0.109), ('visual', -0.101), ('net', -0.092), ('state', -0.085), ('region', -0.084), ('hidden unit', -0.076), ('stimulus', -0.076)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #13:\n",
      "==================================================\n",
      "Direction 1: [('node', 0.396), ('tree', 0.262), ('spike', 0.226), ('stimulus', 0.208), ('signal', 0.169), ('representation', 0.147), ('motion', 0.142), ('response', 0.138), ('frequency', 0.109), ('visual', 0.1), ('rate', 0.097)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('cell', -0.231), ('feature', -0.157), ('neuron', -0.147), ('control', -0.13), ('matrix', -0.119), ('word', -0.114), ('recognition', -0.113), ('distance', -0.104), ('equation', -0.098)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #14:\n",
      "==================================================\n",
      "Direction 1: [('feature', 0.506), ('noise', 0.196), ('map', 0.171), ('signal', 0.133), ('classifier', 0.129), ('state', 0.124), ('memory', 0.122), ('orientation', 0.109), ('component', 0.103)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('image', -0.254), ('control', -0.187), ('word', -0.162), ('recognition', -0.132), ('neuron', -0.131), ('object', -0.113), ('rate', -0.105), ('character', -0.099), ('probability', -0.096), ('bound', -0.089), ('rule', -0.086)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #15:\n",
      "==================================================\n",
      "Direction 1: [('rule', 0.365), ('classifier', 0.365), ('mixture', 0.171), ('node', 0.156), ('gaussian', 0.148), ('layer', 0.128), ('neuron', 0.114), ('field', 0.109), ('control', 0.108), ('image', 0.104), ('component', 0.098)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('bound', -0.189), ('word', -0.156), ('feature', -0.136), ('threshold', -0.135), ('object', -0.125), ('representation', -0.118), ('size', -0.117), ('task', -0.098), ('theorem', -0.097)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #16:\n",
      "==================================================\n",
      "Direction 1: [('object', 0.291), ('control', 0.206), ('mixture', 0.178), ('feature', 0.158), ('task', 0.132), ('cell', 0.13), ('variable', 0.125), ('expert', 0.117), ('current', 0.117), ('circuit', 0.115), ('tree', 0.101), ('distribution', 0.098)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('word', -0.21), ('field', -0.172), ('rule', -0.138), ('rate', -0.121), ('motion', -0.116), ('character', -0.108), ('orientation', -0.107), ('image', -0.104)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #17:\n",
      "==================================================\n",
      "Direction 1: [('rule', 0.372), ('motion', 0.325), ('circuit', 0.193), ('direction', 0.175), ('neuron', 0.153), ('chip', 0.127), ('task', 0.123), ('visual', 0.113), ('velocity', 0.092), ('action', 0.091)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('memory', -0.231), ('node', -0.215), ('control', -0.182), ('dynamic', -0.148), ('spike', -0.128), ('rate', -0.116), ('matrix', -0.108), ('noise', -0.103), ('fig', -0.097), ('cell', -0.093)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #18:\n",
      "==================================================\n",
      "Direction 1: [('object', 0.419), ('signal', 0.26), ('layer', 0.258), ('rule', 0.209), ('feature', 0.164), ('view', 0.162), ('net', 0.113), ('noise', 0.112), ('bound', 0.105), ('speech', 0.1)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('memory', -0.18), ('task', -0.161), ('representation', -0.14), ('hidden', -0.137), ('image', -0.135), ('hidden unit', -0.121), ('tree', -0.117), ('structure', -0.094), ('test', -0.093), ('word', -0.092)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #19:\n",
      "==================================================\n",
      "Direction 1: [('class', 0.287), ('memory', 0.275), ('classifier', 0.144), ('response', 0.139), ('sequence', 0.112), ('component', 0.11), ('stimulus', 0.101), ('region', 0.092), ('bound', 0.088)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('node', -0.292), ('feature', -0.244), ('field', -0.202), ('rate', -0.152), ('word', -0.146), ('spike', -0.139), ('map', -0.132), ('character', -0.127), ('policy', -0.108), ('tree', -0.092), ('noise', -0.088)]\n",
      "--------------------------------------------------\n",
      "\n",
      "Topic #20:\n",
      "==================================================\n",
      "Direction 1: [('map', 0.222), ('control', 0.2), ('region', 0.181), ('ii', 0.145), ('feature', 0.132), ('image', 0.122), ('bound', 0.11), ('orientation', 0.109), ('rule', 0.109), ('threshold', 0.094), ('class', 0.092)]\n",
      "--------------------------------------------------\n",
      "Direction 2: [('object', -0.31), ('motion', -0.252), ('direction', -0.229), ('memory', -0.223), ('classifier', -0.193), ('view', -0.136), ('matrix', -0.13), ('rate', -0.121), ('distance', -0.11)]\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reuse previously implemented code to display topics and terms\n",
    "top_terms = 20\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "topic_keyterm_weights = np.array([topic_terms[row, columns] \n",
    "                                  for row, columns in list(\n",
    "                                      zip(np.arange(TOTAL_TOPICS), topic_key_term_idxs))])\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topic_keyterms_weights = list(zip(topic_keyterms, topic_keyterm_weights))\n",
    "\n",
    "for n in range(TOTAL_TOPICS):\n",
    "    print('Topic #'+str(n+1)+':')\n",
    "    print('='*50)\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    terms, weights = topic_keyterms_weights[n]\n",
    "    term_weights = sorted([(t,w) for t, w in zip(terms, weights)],\n",
    "        key = lambda row: -abs(row[1]))\n",
    "    for term, wt in term_weights:\n",
    "        if wt >= 0:\n",
    "            d1.append((term, round(wt,3)))\n",
    "        else:\n",
    "            d2.append((term, round(wt, 3)))\n",
    "        \n",
    "    print('Direction 1:', d1)\n",
    "    print('-'*50)\n",
    "    print('Direction 2:', d2)\n",
    "    print('-'*50)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document #13:\n",
      "Dominant Topics (top 3): ['T1', 'T8', 'T3']\n",
      "Paper Summary:\n",
      "137 \n",
      "On the \n",
      "Power of Neural Networks for \n",
      "Solving Hard Problems \n",
      "Jehoshua Bruck \n",
      "Joseph W. Goodman \n",
      "Information Systems Laboratory \n",
      "Department of Electrical Engineering \n",
      "Stanford University \n",
      "Stanford, CA 94305 \n",
      "Abstract \n",
      "This paper deals with a neural network model in which each neuron \n",
      "performs a threshold logic function. An important property of the model \n",
      "is that it always converges to a stable state when operating in a serial \n",
      "mode [2,5]. This property is the basis of the potential applicat\n",
      "\n",
      "Document #250:\n",
      "Dominant Topics (top 3): ['T1', 'T13', 'T5']\n",
      "Paper Summary:\n",
      "542 Kassebaum, Tenorio and Schaefers \n",
      "The Cocktail Party Problem: \n",
      "Speech/Data Signal Separation Comparison \n",
      "between Backpropagation and SONN \n",
      "John Kassebaum \n",
      "jakec.ecn.purdue.edu \n",
      "Manoel Fernando Tenorio \n",
      "tenorioee.ecn.purdue.edu \n",
      "Chrlstoph Schaefers \n",
      "Parallel Distributed Structures Laboratory \n",
      "School of Electrical Engineering \n",
      "Purdue University \n",
      "W. Lafayette, IN. 47907 \n",
      "ABSTRACT \n",
      "This work introduces a new method called Self Organizing Neural \n",
      "Network (SONN) algorithm and compares its perfor\n",
      "\n",
      "Document #500:\n",
      "Dominant Topics (top 3): ['T1', 'T9', 'T7']\n",
      "Paper Summary:\n",
      "Learning Global Direct Inverse Kinematics \n",
      "David DeMers* \n",
      "Computer Science & Eng. \n",
      "UC San Diego \n",
      "La Jolla, CA 92093-0114 \n",
      "Kenneth Kreutz-Deigado I \n",
      "Electrical & Computer Eng. \n",
      "UC San Diego \n",
      "La Jolla, CA 92093-0407 \n",
      "Abstract \n",
      "We introduce and demonstrate a bootstrap method for construction of an in- \n",
      "verse function for the robot kinematic mapping using only sample configuration- \n",
      "space/workspace data. Unsupervised learning (clustering) techniques are used on \n",
      "pre-image neighborhoods in order to l\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract key topics for specific research papers\n",
    "dt_df = pd.DataFrame(np.round(document_topics,3), \n",
    "            columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "\n",
    "document_numbers = [13, 250, 500]\n",
    "\n",
    "for document_number in document_numbers:\n",
    "    top_topics = list(dt_df.columns[np.argsort(-np.absolute(dt_df.iloc[document_number].values))[:3]])\n",
    "    print('Document #'+str(document_number)+':')\n",
    "    print('Dominant Topics (top 3):', top_topics)\n",
    "    print('Paper Summary:')\n",
    "    print(papers[document_number][:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.2 s, sys: 11 s, total: 1min 4s\n",
      "Wall time: 51min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Latent Dirichlet Allocation\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#lda_model = LatentDirichletAllocation(n_components=TOTAL_TOPICS, max_iter=500, \n",
    "                                      max_doc_update_iter=50, learning_method='online', \n",
    "                                      batch_size=1740, learning_offset=50., \n",
    "                                      random_state=42, n_jobs=16)\n",
    "#document_topics = lda_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# location of file\n",
    "filename = path_to_users + '/LearningCode/NLP_Learning/sklearn_lda_models.sav'\n",
    "\n",
    "# save model for later use\n",
    "# pickle.dump(lda_model, open(filename, 'wb'))\n",
    "\n",
    "# load model and scores\n",
    "lda_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>neuron, circuit, chip, analog, current, signal, voltage, channel, noise, bit, vlsi, implementation, pulse, processor, synapse, fig, parallel, design, connection, gain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>image, feature, state, structure, layer, neuron, distribution, local, cell, motion, matrix, recognition, object, node, net, sequence, size, gaussian, line, hidden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>motor, sound, auditory, template, frequency, acoustic, syllable, production, song, harmonic, nucleus, control, spectrogram, phase, feedback, motor learning, khz, representation, template matching, hearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>cell, neuron, response, visual, stimulus, activity, spike, field, motion, synaptic, direction, cortex, firing, signal, orientation, spatial, eye, map, rate, fig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>image, feature, recognition, layer, hidden, task, speech, object, representation, trained, test, classification, classifier, net, class, architecture, level, experiment, hidden unit, rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>state, dynamic, rule, matrix, recurrent, equation, gradient, hidden, signal, sequence, fixed, source, component, attractor, node, structure, net, fixed point, step, representation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>sequence, chain, region, structure, protein, prediction, hmms, site, receptor, gene, class, human, positive, mouse, length, window, sheet, cell, domain, secondary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>memory, word, context, similarity, item, recall, phoneme, probability, short, list, association, representation, activation, state, address, short term, phone, serial, store, term memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>activation, winner, take, behavior, competitive, winner take, connection, active, self, activation function, wta, competition, level, activity, role, binding, food, sensor, net, insect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>state, cell, distribution, neuron, probability, control, response, layer, signal, rate, architecture, task, test, random, hidden, image, change, fig, generalization, field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>field, solution, energy, cluster, constraint, graph, distance, optimization, capacity, clustering, minimum, temperature, matching, mean field, annealing, equation, local, cost, line, objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>feature, image, distribution, neuron, hidden, state, class, probability, layer, node, equation, size, line, prediction, matrix, rate, signal, et, noise, recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>image, state, cell, object, rule, layer, step, et al, distribution, neuron, signal, field, visual, dynamic, feature, probability, ii, current, solution, et</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>neuron, map, cell, state, rate, hidden, field, equation, probability, node, signal, dynamic, representation, layer, et al, sequence, test, noise, recognition, prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>distribution, probability, variable, gaussian, class, approximation, estimate, sample, density, noise, mixture, log, likelihood, matrix, optimal, prior, generalization, variance, xi, prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>state, neuron, rule, layer, probability, rate, image, memory, distribution, equation, signal, solution, response, class, theory, et, step, feature, variable, high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>state, feature, probability, image, layer, cell, field, neuron, task, rate, recognition, control, dynamic, rule, variable, distribution, equation, representation, net, class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>state, control, action, policy, reinforcement, task, optimal, step, dynamic, controller, trajectory, robot, reinforcement learning, environment, reward, path, goal, decision, value function, arm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>state, control, feature, probability, hidden, architecture, neuron, task, rate, level, estimate, et, net, local, distribution, image, response, component, signal, noise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>theorem, threshold, bound, net, proof, let, polynomial, layer, size, depth, gate, neural net, bounded, bit, binary, constant, every, assume, element, exists</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      Terms per Topic\n",
       "Topic1   neuron, circuit, chip, analog, current, signal, voltage, channel, noise, bit, vlsi, implementation, pulse, processor, synapse, fig, parallel, design, connection, gain                                      \n",
       "Topic2   image, feature, state, structure, layer, neuron, distribution, local, cell, motion, matrix, recognition, object, node, net, sequence, size, gaussian, line, hidden                                          \n",
       "Topic3   motor, sound, auditory, template, frequency, acoustic, syllable, production, song, harmonic, nucleus, control, spectrogram, phase, feedback, motor learning, khz, representation, template matching, hearing\n",
       "Topic4   cell, neuron, response, visual, stimulus, activity, spike, field, motion, synaptic, direction, cortex, firing, signal, orientation, spatial, eye, map, rate, fig                                            \n",
       "Topic5   image, feature, recognition, layer, hidden, task, speech, object, representation, trained, test, classification, classifier, net, class, architecture, level, experiment, hidden unit, rule                 \n",
       "Topic6   state, dynamic, rule, matrix, recurrent, equation, gradient, hidden, signal, sequence, fixed, source, component, attractor, node, structure, net, fixed point, step, representation                         \n",
       "Topic7   sequence, chain, region, structure, protein, prediction, hmms, site, receptor, gene, class, human, positive, mouse, length, window, sheet, cell, domain, secondary                                          \n",
       "Topic8   memory, word, context, similarity, item, recall, phoneme, probability, short, list, association, representation, activation, state, address, short term, phone, serial, store, term memory                  \n",
       "Topic9   activation, winner, take, behavior, competitive, winner take, connection, active, self, activation function, wta, competition, level, activity, role, binding, food, sensor, net, insect                    \n",
       "Topic10  state, cell, distribution, neuron, probability, control, response, layer, signal, rate, architecture, task, test, random, hidden, image, change, fig, generalization, field                                 \n",
       "Topic11  field, solution, energy, cluster, constraint, graph, distance, optimization, capacity, clustering, minimum, temperature, matching, mean field, annealing, equation, local, cost, line, objective            \n",
       "Topic12  feature, image, distribution, neuron, hidden, state, class, probability, layer, node, equation, size, line, prediction, matrix, rate, signal, et, noise, recognition                                        \n",
       "Topic13  image, state, cell, object, rule, layer, step, et al, distribution, neuron, signal, field, visual, dynamic, feature, probability, ii, current, solution, et                                                 \n",
       "Topic14  neuron, map, cell, state, rate, hidden, field, equation, probability, node, signal, dynamic, representation, layer, et al, sequence, test, noise, recognition, prediction                                   \n",
       "Topic15  distribution, probability, variable, gaussian, class, approximation, estimate, sample, density, noise, mixture, log, likelihood, matrix, optimal, prior, generalization, variance, xi, prediction           \n",
       "Topic16  state, neuron, rule, layer, probability, rate, image, memory, distribution, equation, signal, solution, response, class, theory, et, step, feature, variable, high                                          \n",
       "Topic17  state, feature, probability, image, layer, cell, field, neuron, task, rate, recognition, control, dynamic, rule, variable, distribution, equation, representation, net, class                               \n",
       "Topic18  state, control, action, policy, reinforcement, task, optimal, step, dynamic, controller, trajectory, robot, reinforcement learning, environment, reward, path, goal, decision, value function, arm          \n",
       "Topic19  state, control, feature, probability, hidden, architecture, neuron, task, rate, level, estimate, et, net, local, distribution, image, response, component, signal, noise                                    \n",
       "Topic20  theorem, threshold, bound, net, proof, let, polynomial, layer, size, depth, gate, neural net, bounded, bit, binary, constant, every, assume, element, exists                                                "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain topic-term matrix\n",
    "# build dataframe from it to showcase topics and terms\n",
    "topic_terms = lda_model.components_\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:, :top_terms]\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topics = [', '.join(topic) for topic in topic_keyterms]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame(topics, columns=['Terms per Topic'], \n",
    "                         index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Contribution %</th>\n",
       "      <th>Paper Num</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Paper Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>T1</td>\n",
       "      <td>0.99935</td>\n",
       "      <td>58</td>\n",
       "      <td>neuron, circuit, chip, analog, current, signal, voltage, channel, noise, bit, vlsi, implementation, pulse, processor, synapse, fig, parallel, design, connection, gain</td>\n",
       "      <td>564 \\nPROGRAMMABLE SYNAPTIC CHIP FOR \\nELECTRONIC NEURAL NETWORKS \\nA. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna \\nJet Propulsion Laboratory \\nCalifornia Institute of Technology \\nPa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>T2</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>image, feature, state, structure, layer, neuron, distribution, local, cell, motion, matrix, recognition, object, node, net, sequence, size, gaussian, line, hidden</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>T3</td>\n",
       "      <td>0.71411</td>\n",
       "      <td>182</td>\n",
       "      <td>motor, sound, auditory, template, frequency, acoustic, syllable, production, song, harmonic, nucleus, control, spectrogram, phase, feedback, motor learning, khz, representation, template matching,...</td>\n",
       "      <td>795 \\nSONG LEARNING IN BIRDS \\nM. Konishi \\nDivision of Biology \\nCalifornia Institute of Technology \\nABSTRACT\\nBirds sing to communicate. Male birds use song to advertise their territories and \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>T4</td>\n",
       "      <td>0.99945</td>\n",
       "      <td>1005</td>\n",
       "      <td>cell, neuron, response, visual, stimulus, activity, spike, field, motion, synaptic, direction, cortex, firing, signal, orientation, spatial, eye, map, rate, fig</td>\n",
       "      <td>Simulation of a Thalamocortical Circuit for \\nComputing Directional Heading in the Rat \\nHugh T. Blair* \\nDepartment of Psychology \\nYale University \\nNew Haven, CT 06520-8205 \\ntadb @minerva. cis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>T5</td>\n",
       "      <td>0.99783</td>\n",
       "      <td>235</td>\n",
       "      <td>image, feature, recognition, layer, hidden, task, speech, object, representation, trained, test, classification, classifier, net, class, architecture, level, experiment, hidden unit, rule</td>\n",
       "      <td>A Large-Scale Neural Network 415 \\nA LARGE-SCALE NEURAL NETWORK \\nWHICH RECOGNIZES HANDWRITTEN \\nKANJI CHARACTERS \\nYoshihiro Mori Kazuki Joe \\nATR Auditory and Visual Perception Research Laborato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>T6</td>\n",
       "      <td>0.96184</td>\n",
       "      <td>1070</td>\n",
       "      <td>state, dynamic, rule, matrix, recurrent, equation, gradient, hidden, signal, sequence, fixed, source, component, attractor, node, structure, net, fixed point, step, representation</td>\n",
       "      <td>Finite State Automata that Recurrent \\nCascade-Correlation Cannot Represent \\nStefan C. Kremer \\nDepartment of Computing Science \\nUniversity of Alberta \\nEdmonton, Alberta, CANADA T6H 5B5 \\nAbstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>T7</td>\n",
       "      <td>0.99956</td>\n",
       "      <td>236</td>\n",
       "      <td>sequence, chain, region, structure, protein, prediction, hmms, site, receptor, gene, class, human, positive, mouse, length, window, sheet, cell, domain, secondary</td>\n",
       "      <td>A Neural Network to Detect \\nHomologies in Proteins \\nYoshua Bengio \\nSchool of Computer Science \\nMcGill University \\nMontreal, Canada H3A 2A7 \\nSamy Bengio \\nDepartement d'Informatique \\nUnivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>T8</td>\n",
       "      <td>0.96245</td>\n",
       "      <td>850</td>\n",
       "      <td>memory, word, context, similarity, item, recall, phoneme, probability, short, list, association, representation, activation, state, address, short term, phone, serial, store, term memory</td>\n",
       "      <td>A solvable connectionist model of \\nimmediate recall of ordered lists \\nNell Burgess \\nDepartment of Anatomy, University College London \\nLondon WCiE 6BT, England \\n(e-mail: n .burgessucl. ac. uk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>T9</td>\n",
       "      <td>0.99938</td>\n",
       "      <td>470</td>\n",
       "      <td>activation, winner, take, behavior, competitive, winner take, connection, active, self, activation function, wta, competition, level, activity, role, binding, food, sensor, net, insect</td>\n",
       "      <td>Dynamically-Adaptive Winner-Take-All Networks \\nTret E. Lange \\nComputer Scienos Department \\nUniversity of California, Los Angeles, CA 90024 \\nAbstract \\nWinner-Take-All (WTA) networks, in which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>T10</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>state, cell, distribution, neuron, probability, control, response, layer, signal, rate, architecture, task, test, random, hidden, image, change, fig, generalization, field</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>T11</td>\n",
       "      <td>0.97772</td>\n",
       "      <td>1341</td>\n",
       "      <td>field, solution, energy, cluster, constraint, graph, distance, optimization, capacity, clustering, minimum, temperature, matching, mean field, annealing, equation, local, cost, line, objective</td>\n",
       "      <td>I I II \\nThe Storage Capacity \\nof a Fully-Connected Committee Machine \\nYuansheng Xiong \\nDepartment of Physics, Pohang Institute of Science and Technology, \\nHyoja San 31, Pohang, Kyongbuk, Kore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>T12</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>feature, image, distribution, neuron, hidden, state, class, probability, layer, node, equation, size, line, prediction, matrix, rate, signal, et, noise, recognition</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>T13</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>image, state, cell, object, rule, layer, step, et al, distribution, neuron, signal, field, visual, dynamic, feature, probability, ii, current, solution, et</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>T14</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>neuron, map, cell, state, rate, hidden, field, equation, probability, node, signal, dynamic, representation, layer, et al, sequence, test, noise, recognition, prediction</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>T15</td>\n",
       "      <td>0.99942</td>\n",
       "      <td>1487</td>\n",
       "      <td>distribution, probability, variable, gaussian, class, approximation, estimate, sample, density, noise, mixture, log, likelihood, matrix, optimal, prior, generalization, variance, xi, prediction</td>\n",
       "      <td>Learning curves for Gaussian processes \\nPeter Sollich* \\nDepartment of Physics, University of Edinburgh \\nEdinburgh EH9 3JZ, U.K. Email: P. Solliched. ac. uk \\nAbstract \\nI consider the problem o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>T16</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>state, neuron, rule, layer, probability, rate, image, memory, distribution, equation, signal, solution, response, class, theory, et, step, feature, variable, high</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>T17</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>state, feature, probability, image, layer, cell, field, neuron, task, rate, recognition, control, dynamic, rule, variable, distribution, equation, representation, net, class</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>T18</td>\n",
       "      <td>0.99953</td>\n",
       "      <td>891</td>\n",
       "      <td>state, control, action, policy, reinforcement, task, optimal, step, dynamic, controller, trajectory, robot, reinforcement learning, environment, reward, path, goal, decision, value function, arm</td>\n",
       "      <td>Finding Structure in Reinforcement Learning \\nSebastian Thrun \\nUniversity of Bonn \\nDepartment of Computer Science III \\nROmerstr. 164, D-53117 Bonn, Germany \\nE-mail: thrun @carbon.informatik.un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>T19</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>181</td>\n",
       "      <td>state, control, feature, probability, hidden, architecture, neuron, task, rate, level, estimate, et, net, local, distribution, image, response, component, signal, noise</td>\n",
       "      <td>794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>T20</td>\n",
       "      <td>0.71047</td>\n",
       "      <td>270</td>\n",
       "      <td>theorem, threshold, bound, net, proof, let, polynomial, layer, size, depth, gate, neural net, bounded, bit, binary, constant, every, assume, element, exists</td>\n",
       "      <td>702 Obradovic and Parberry \\nAnalog Neural Networks of Limited Precision I: \\nComputing with Multilinear Threshold Functions \\n(Preliminary Version) \\nZoran Obradovic and Ian Parberry \\nDepartment...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topic  Contribution %  Paper Num  \\\n",
       "Topic1              T1         0.99935         58   \n",
       "Topic2              T2         0.00033        181   \n",
       "Topic3              T3         0.71411        182   \n",
       "Topic4              T4         0.99945       1005   \n",
       "Topic5              T5         0.99783        235   \n",
       "Topic6              T6         0.96184       1070   \n",
       "Topic7              T7         0.99956        236   \n",
       "Topic8              T8         0.96245        850   \n",
       "Topic9              T9         0.99938        470   \n",
       "Topic10            T10         0.00033        181   \n",
       "Topic11            T11         0.97772       1341   \n",
       "Topic12            T12         0.00033        181   \n",
       "Topic13            T13         0.00033        181   \n",
       "Topic14            T14         0.00033        181   \n",
       "Topic15            T15         0.99942       1487   \n",
       "Topic16            T16         0.00033        181   \n",
       "Topic17            T17         0.00033        181   \n",
       "Topic18            T18         0.99953        891   \n",
       "Topic19            T19         0.00033        181   \n",
       "Topic20            T20         0.71047        270   \n",
       "\n",
       "                                                                                                                                                                                                           Topic  \\\n",
       "Topic1                                    neuron, circuit, chip, analog, current, signal, voltage, channel, noise, bit, vlsi, implementation, pulse, processor, synapse, fig, parallel, design, connection, gain   \n",
       "Topic2                                        image, feature, state, structure, layer, neuron, distribution, local, cell, motion, matrix, recognition, object, node, net, sequence, size, gaussian, line, hidden   \n",
       "Topic3   motor, sound, auditory, template, frequency, acoustic, syllable, production, song, harmonic, nucleus, control, spectrogram, phase, feedback, motor learning, khz, representation, template matching,...   \n",
       "Topic4                                          cell, neuron, response, visual, stimulus, activity, spike, field, motion, synaptic, direction, cortex, firing, signal, orientation, spatial, eye, map, rate, fig   \n",
       "Topic5               image, feature, recognition, layer, hidden, task, speech, object, representation, trained, test, classification, classifier, net, class, architecture, level, experiment, hidden unit, rule   \n",
       "Topic6                       state, dynamic, rule, matrix, recurrent, equation, gradient, hidden, signal, sequence, fixed, source, component, attractor, node, structure, net, fixed point, step, representation   \n",
       "Topic7                                        sequence, chain, region, structure, protein, prediction, hmms, site, receptor, gene, class, human, positive, mouse, length, window, sheet, cell, domain, secondary   \n",
       "Topic8                memory, word, context, similarity, item, recall, phoneme, probability, short, list, association, representation, activation, state, address, short term, phone, serial, store, term memory   \n",
       "Topic9                  activation, winner, take, behavior, competitive, winner take, connection, active, self, activation function, wta, competition, level, activity, role, binding, food, sensor, net, insect   \n",
       "Topic10                              state, cell, distribution, neuron, probability, control, response, layer, signal, rate, architecture, task, test, random, hidden, image, change, fig, generalization, field   \n",
       "Topic11         field, solution, energy, cluster, constraint, graph, distance, optimization, capacity, clustering, minimum, temperature, matching, mean field, annealing, equation, local, cost, line, objective   \n",
       "Topic12                                     feature, image, distribution, neuron, hidden, state, class, probability, layer, node, equation, size, line, prediction, matrix, rate, signal, et, noise, recognition   \n",
       "Topic13                                              image, state, cell, object, rule, layer, step, et al, distribution, neuron, signal, field, visual, dynamic, feature, probability, ii, current, solution, et   \n",
       "Topic14                                neuron, map, cell, state, rate, hidden, field, equation, probability, node, signal, dynamic, representation, layer, et al, sequence, test, noise, recognition, prediction   \n",
       "Topic15        distribution, probability, variable, gaussian, class, approximation, estimate, sample, density, noise, mixture, log, likelihood, matrix, optimal, prior, generalization, variance, xi, prediction   \n",
       "Topic16                                       state, neuron, rule, layer, probability, rate, image, memory, distribution, equation, signal, solution, response, class, theory, et, step, feature, variable, high   \n",
       "Topic17                            state, feature, probability, image, layer, cell, field, neuron, task, rate, recognition, control, dynamic, rule, variable, distribution, equation, representation, net, class   \n",
       "Topic18       state, control, action, policy, reinforcement, task, optimal, step, dynamic, controller, trajectory, robot, reinforcement learning, environment, reward, path, goal, decision, value function, arm   \n",
       "Topic19                                 state, control, feature, probability, hidden, architecture, neuron, task, rate, level, estimate, et, net, local, distribution, image, response, component, signal, noise   \n",
       "Topic20                                             theorem, threshold, bound, net, proof, let, polynomial, layer, size, depth, gate, neural net, bounded, bit, binary, constant, every, assume, element, exists   \n",
       "\n",
       "                                                                                                                                                                                                      Paper Name  \n",
       "Topic1   564 \\nPROGRAMMABLE SYNAPTIC CHIP FOR \\nELECTRONIC NEURAL NETWORKS \\nA. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna \\nJet Propulsion Laboratory \\nCalifornia Institute of Technology \\nPa...  \n",
       "Topic2   794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic3   795 \\nSONG LEARNING IN BIRDS \\nM. Konishi \\nDivision of Biology \\nCalifornia Institute of Technology \\nABSTRACT\\nBirds sing to communicate. Male birds use song to advertise their territories and \\...  \n",
       "Topic4   Simulation of a Thalamocortical Circuit for \\nComputing Directional Heading in the Rat \\nHugh T. Blair* \\nDepartment of Psychology \\nYale University \\nNew Haven, CT 06520-8205 \\ntadb @minerva. cis...  \n",
       "Topic5   A Large-Scale Neural Network 415 \\nA LARGE-SCALE NEURAL NETWORK \\nWHICH RECOGNIZES HANDWRITTEN \\nKANJI CHARACTERS \\nYoshihiro Mori Kazuki Joe \\nATR Auditory and Visual Perception Research Laborato...  \n",
       "Topic6   Finite State Automata that Recurrent \\nCascade-Correlation Cannot Represent \\nStefan C. Kremer \\nDepartment of Computing Science \\nUniversity of Alberta \\nEdmonton, Alberta, CANADA T6H 5B5 \\nAbstr...  \n",
       "Topic7   A Neural Network to Detect \\nHomologies in Proteins \\nYoshua Bengio \\nSchool of Computer Science \\nMcGill University \\nMontreal, Canada H3A 2A7 \\nSamy Bengio \\nDepartement d'Informatique \\nUnivers...  \n",
       "Topic8   A solvable connectionist model of \\nimmediate recall of ordered lists \\nNell Burgess \\nDepartment of Anatomy, University College London \\nLondon WCiE 6BT, England \\n(e-mail: n .burgessucl. ac. uk...  \n",
       "Topic9   Dynamically-Adaptive Winner-Take-All Networks \\nTret E. Lange \\nComputer Scienos Department \\nUniversity of California, Los Angeles, CA 90024 \\nAbstract \\nWinner-Take-All (WTA) networks, in which...  \n",
       "Topic10  794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic11  I I II \\nThe Storage Capacity \\nof a Fully-Connected Committee Machine \\nYuansheng Xiong \\nDepartment of Physics, Pohang Institute of Science and Technology, \\nHyoja San 31, Pohang, Kyongbuk, Kore...  \n",
       "Topic12  794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic13  794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic14  794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic15  Learning curves for Gaussian processes \\nPeter Sollich* \\nDepartment of Physics, University of Edinburgh \\nEdinburgh EH9 3JZ, U.K. Email: P. Solliched. ac. uk \\nAbstract \\nI consider the problem o...  \n",
       "Topic16  794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic17  794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic18  Finding Structure in Reinforcement Learning \\nSebastian Thrun \\nUniversity of Bonn \\nDepartment of Computer Science III \\nROmerstr. 164, D-53117 Bonn, Germany \\nE-mail: thrun @carbon.informatik.un...  \n",
       "Topic19  794 \\nNEURAL ARCHITECTURE \\nValentino Braitenberg \\nMax Planck Institute \\nFederal Republic of Germany \\nABSTRACT\\nWhile we are waiting for the ultimate biophysics of cell membranes and synapses \\...  \n",
       "Topic20  702 Obradovic and Parberry \\nAnalog Neural Networks of Limited Precision I: \\nComputing with Multilinear Threshold Functions \\n(Preliminary Version) \\nZoran Obradovic and Ian Parberry \\nDepartment...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view research papers having max contribution of each of the 20 topics\n",
    "dt_df = pd.DataFrame(document_topics, \n",
    "                     columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "max_contrib_topics = dt_df.max(axis=0)\n",
    "dominant_topics = max_contrib_topics.index\n",
    "contrib_perc = max_contrib_topics.values\n",
    "document_numbers = [dt_df[dt_df[t] == max_contrib_topics.loc[t]].index[0]\n",
    "                        for t in dominant_topics]\n",
    "documents = [papers[i] for i in document_numbers]\n",
    "\n",
    "# display using dataframe\n",
    "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, \n",
    "                           'Contribution %': contrib_perc,\n",
    "                           'Paper Num': document_numbers, \n",
    "                           'Topic': topics_df['Terms per Topic'],\n",
    "                           'Paper Name': documents}\n",
    "                         )\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 s, sys: 1.79 s, total: 17.8 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Non-Negative Matrix Factorization\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf_model = NMF(n_components=TOTAL_TOPICS, solver='cd', max_iter=500, \n",
    "                random_state=42, alpha=.1, l1_ratio=.85)\n",
    "document_topics = nmf_model.fit_transform(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Terms per Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, state, equation, et, et al, activation, fig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>state, action, policy, step, reinforcement, optimal, reinforcement learning, transition, probability, reward, value function, dynamic, markov, machine, task, agent, finite, iteration, sequence, decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, output unit, neural net, internal, generalization, learn, training set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>cell, firing, head, response, direction, rat, layer, cortex, activity, ii, spatial, synaptic, inhibitory, synapsis, simulation, cue, region, property, complex, lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>signal, noise, source, filter, frequency, component, speech, channel, sound, independent, separation, ica, phase, auditory, matrix, eeg, blind, delay, acoustic, spectrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>control, controller, trajectory, motor, movement, task, dynamic, forward, feedback, arm, inverse, position, robot, architecture, hand, force, target, change, command, adaptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>circuit, chip, current, analog, voltage, vlsi, transistor, gate, pulse, threshold, design, implementation, synapse, bit, digital, device, analog vlsi, cmos, pp, line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, change, timing, probability, correlation, temporal, distribution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>rule, learning rule, knowledge, category, condition, domain, symbolic, fuzzy, change, extraction, class, table, step, interval, expert, learn, language, activation, trained, learned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>node, tree, decision, level, graph, structure, decision tree, leaf, path, layer, variable, field, parent, routing, split, child, propagation, architecture, activation, probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>feature, map, task, search, classification, experiment, representation, part, target, feature map, attention, orientation, feature vector, location, feature space, dimensional, region, cluster, kernel, extra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>classifier, class, classification, decision, rbf, region, rate, test, error rate, center, nearest, neighbor, nearest neighbor, training set, boundary, layer, gaussian, trained, sample, mixture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>distribution, gaussian, probability, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, conditional, structure, maximum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>field, visual, motion, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, center, location, target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>object, view, recognition, representation, layer, visual, 3d, 2d, part, human, transformation, object recognition, position, scheme, image, aspect, frame, shape, rotation, viewpoint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>memory, representation, structure, capacity, sequence, associative, role, distributed, associative memory, activity, matrix, bit, stored, product, binding, connection, code, activation, local, symbol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>equation, gradient, solution, matrix, optimal, generalization, rate, local, minimum, distance, line, convergence, noise, optimization, training set, average, constraint, descent, cost, test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                         Terms per Topic\n",
       "Topic1   bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension                                               \n",
       "Topic2   neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, state, equation, et, et al, activation, fig                                       \n",
       "Topic3   state, action, policy, step, reinforcement, optimal, reinforcement learning, transition, probability, reward, value function, dynamic, markov, machine, task, agent, finite, iteration, sequence, decision                     \n",
       "Topic4   image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database                                                           \n",
       "Topic5   hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, output unit, neural net, internal, generalization, learn, training set\n",
       "Topic6   cell, firing, head, response, direction, rat, layer, cortex, activity, ii, spatial, synaptic, inhibitory, synapsis, simulation, cue, region, property, complex, lot                                                            \n",
       "Topic7   word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state                                   \n",
       "Topic8   signal, noise, source, filter, frequency, component, speech, channel, sound, independent, separation, ica, phase, auditory, matrix, eeg, blind, delay, acoustic, spectrum                                                      \n",
       "Topic9   control, controller, trajectory, motor, movement, task, dynamic, forward, feedback, arm, inverse, position, robot, architecture, hand, force, target, change, command, adaptive                                                \n",
       "Topic10  circuit, chip, current, analog, voltage, vlsi, transistor, gate, pulse, threshold, design, implementation, synapse, bit, digital, device, analog vlsi, cmos, pp, line                                                          \n",
       "Topic11  spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, change, timing, probability, correlation, temporal, distribution                               \n",
       "Topic12  rule, learning rule, knowledge, category, condition, domain, symbolic, fuzzy, change, extraction, class, table, step, interval, expert, learn, language, activation, trained, learned                                          \n",
       "Topic13  node, tree, decision, level, graph, structure, decision tree, leaf, path, layer, variable, field, parent, routing, split, child, propagation, architecture, activation, probability                                            \n",
       "Topic14  feature, map, task, search, classification, experiment, representation, part, target, feature map, attention, orientation, feature vector, location, feature space, dimensional, region, cluster, kernel, extra                \n",
       "Topic15  classifier, class, classification, decision, rbf, region, rate, test, error rate, center, nearest, neighbor, nearest neighbor, training set, boundary, layer, gaussian, trained, sample, mixture                               \n",
       "Topic16  distribution, gaussian, probability, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, conditional, structure, maximum                      \n",
       "Topic17  field, visual, motion, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, center, location, target                                     \n",
       "Topic18  object, view, recognition, representation, layer, visual, 3d, 2d, part, human, transformation, object recognition, position, scheme, image, aspect, frame, shape, rotation, viewpoint                                          \n",
       "Topic19  memory, representation, structure, capacity, sequence, associative, role, distributed, associative memory, activity, matrix, bit, stored, product, binding, connection, code, activation, local, symbol                        \n",
       "Topic20  equation, gradient, solution, matrix, optimal, generalization, rate, local, minimum, distance, line, convergence, noise, optimization, training set, average, constraint, descent, cost, test                                  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view generated topics\n",
    "topic_terms = nmf_model.components_\n",
    "topic_key_term_idxs = np.argsort(-np.absolute(topic_terms), axis=1)[:,:top_terms]\n",
    "topic_keyterms = vocabulary[topic_key_term_idxs]\n",
    "topics = [', '.join(topic) for topic in topic_keyterms]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame(topics, columns=['Terms per Topic'],\n",
    "                            index=['Topic'+str(t) for t in range(1, TOTAL_TOPICS+1)])\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>T11</th>\n",
       "      <th>T12</th>\n",
       "      <th>T13</th>\n",
       "      <th>T14</th>\n",
       "      <th>T15</th>\n",
       "      <th>T16</th>\n",
       "      <th>T17</th>\n",
       "      <th>T18</th>\n",
       "      <th>T19</th>\n",
       "      <th>T20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.322</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.065</td>\n",
       "      <td>1.525</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.259</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.396</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.325</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.119</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.184</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.899</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.949</td>\n",
       "      <td>3.047</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.185</td>\n",
       "      <td>1.301</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.197</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     T1    T2    T3    T4    T5    T6    T7    T8    T9   T10   T11   T12  \\\n",
       "0 0.521 0.988 0.059 0.002 0.000 0.000 0.000 0.000 0.020 0.099 0.000 0.104   \n",
       "1 0.000 1.322 0.261 0.000 0.300 0.000 0.000 0.970 0.181 0.930 0.000 0.524   \n",
       "2 0.130 0.595 0.454 0.008 0.167 0.035 0.000 0.123 0.105 0.022 0.000 0.234   \n",
       "3 0.065 1.525 0.000 0.046 0.000 0.000 0.309 0.620 0.228 0.168 0.000 0.964   \n",
       "4 1.259 0.271 0.355 0.000 0.446 0.000 0.000 0.000 0.000 1.396 0.000 0.325   \n",
       "5 0.119 0.133 0.000 0.000 0.595 0.008 0.016 0.000 0.010 0.000 0.000 0.068   \n",
       "6 0.000 0.000 0.000 0.007 0.007 1.184 0.015 0.000 0.000 0.000 0.088 0.072   \n",
       "7 0.048 0.093 0.175 0.000 0.675 0.000 0.000 0.000 0.000 0.036 0.042 0.685   \n",
       "8 0.000 0.969 0.177 0.000 0.000 1.037 0.000 0.000 0.034 0.949 3.047 0.000   \n",
       "9 0.185 1.301 0.000 0.000 0.000 0.000 0.000 0.288 0.000 0.000 3.197 0.118   \n",
       "\n",
       "    T13   T14   T15   T16   T17   T18   T19   T20  \n",
       "0 0.018 0.044 0.000 0.169 0.000 0.047 0.000 0.000  \n",
       "1 0.087 0.223 0.035 0.199 0.000 0.021 0.230 0.557  \n",
       "2 0.005 0.000 0.000 0.000 0.000 0.103 0.177 0.717  \n",
       "3 0.100 0.000 0.074 0.000 0.000 0.000 0.146 0.303  \n",
       "4 0.003 0.000 0.000 0.000 0.000 0.000 1.036 0.000  \n",
       "5 0.791 0.006 0.038 0.246 0.004 0.025 0.000 0.222  \n",
       "6 0.032 0.786 0.182 0.000 1.899 0.000 0.000 0.477  \n",
       "7 0.000 0.000 0.000 0.000 0.000 0.000 0.093 0.777  \n",
       "8 0.075 0.000 0.000 0.000 0.000 0.052 0.038 0.000  \n",
       "9 0.000 0.499 0.524 0.093 0.000 0.054 0.000 0.000  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine dominance of topics in research papers by absolute scores\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "dt_df = pd.DataFrame(document_topics, columns=['T'+str(i) for i in range(1, TOTAL_TOPICS+1)])\n",
    "dt_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topic</th>\n",
       "      <th>Max Score</th>\n",
       "      <th>Paper Num</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Paper Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic1</th>\n",
       "      <td>T1</td>\n",
       "      <td>1.98178</td>\n",
       "      <td>1154</td>\n",
       "      <td>bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension</td>\n",
       "      <td>For valid generalization, the size of the \\nweights is more important than the size \\nof the network \\nPeter L. Bartlett \\nDepartment of Systems Engineering \\nResearch School of Information Scienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic2</th>\n",
       "      <td>T2</td>\n",
       "      <td>3.58244</td>\n",
       "      <td>323</td>\n",
       "      <td>neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, state, equation, et, et al, activation, fig</td>\n",
       "      <td>Signal Processing by Multiplexing and \\nDemultiplexing in Neurons \\nDavid C. Tam \\nDivision of Neuroscience \\nBaylor College of Medicine \\nHouston, TX 77030 \\ndtamCnext-cns.neusc.bcm.tmc.edu \\nAb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic3</th>\n",
       "      <td>T3</td>\n",
       "      <td>5.88608</td>\n",
       "      <td>1279</td>\n",
       "      <td>state, action, policy, step, reinforcement, optimal, reinforcement learning, transition, probability, reward, value function, dynamic, markov, machine, task, agent, finite, iteration, sequence, de...</td>\n",
       "      <td>Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmhe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic4</th>\n",
       "      <td>T4</td>\n",
       "      <td>3.91592</td>\n",
       "      <td>1714</td>\n",
       "      <td>image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database</td>\n",
       "      <td>Image representations for facial expression \\ncoding \\nMarian Stewart Bartlett* \\nU.C. San Diego \\nmarnisalk. edu \\nJavier R. Movellan \\nU.C. San Diego \\nmovellancogsc. ucsd. edu \\nPaul Ekman \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic5</th>\n",
       "      <td>T5</td>\n",
       "      <td>2.99090</td>\n",
       "      <td>734</td>\n",
       "      <td>hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, output unit, neural net, internal, generali...</td>\n",
       "      <td>Generation of Internal Representation \\nby c-Transformation \\nRyotaro Kamimura \\nInformation Science Laboratory \\nTokai University \\n1117 Kitakaname Hiratsuka Kanagawa 259-12, Japan \\nAbstract \\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic6</th>\n",
       "      <td>T6</td>\n",
       "      <td>7.47698</td>\n",
       "      <td>34</td>\n",
       "      <td>cell, firing, head, response, direction, rat, layer, cortex, activity, ii, spatial, synaptic, inhibitory, synapsis, simulation, cue, region, property, complex, lot</td>\n",
       "      <td>317 \\nPARTITIONING OF SENSORY DATA BY A COPTICAI, NETWOPK  \\nRichard Granger, Jos Ambros-Ingerson, Howard Henry, Gary Lynch \\nCenter for the Neurobiology of Learning and Memory \\nUniversity of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic7</th>\n",
       "      <td>T7</td>\n",
       "      <td>4.91490</td>\n",
       "      <td>1301</td>\n",
       "      <td>word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state</td>\n",
       "      <td>Comparison of Human and Machine Word \\nRecognition \\nM. Schenkel \\nDept of Electrical Eng. \\nUniversity of Sydney \\nSydney, NSW 2006, Australia \\nschenkel@sedal.usyd.edu.au \\nC. Latimer \\nDept of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic8</th>\n",
       "      <td>T8</td>\n",
       "      <td>3.78582</td>\n",
       "      <td>213</td>\n",
       "      <td>signal, noise, source, filter, frequency, component, speech, channel, sound, independent, separation, ica, phase, auditory, matrix, eeg, blind, delay, acoustic, spectrum</td>\n",
       "      <td>232 Sejnowski, Yuhas, Goldstein and Jenkins \\nCombining Visual and \\nwith a Neural Network \\nAcoustic Speech Signals \\nImproves Intelligibility \\nT.J. Sejnowski \\nThe Salk Institute \\nand \\nDepart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic9</th>\n",
       "      <td>T9</td>\n",
       "      <td>4.86516</td>\n",
       "      <td>971</td>\n",
       "      <td>control, controller, trajectory, motor, movement, task, dynamic, forward, feedback, arm, inverse, position, robot, architecture, hand, force, target, change, command, adaptive</td>\n",
       "      <td>An Integrated Architecture of Adaptive Neural Network \\nControl for Dynamic Systems \\nLiu Ke '2 Robert L. Tokaf Brian D.McVey z \\nCenter for Nonlinear Studies, 2Applied Theoretical Physics Divis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic10</th>\n",
       "      <td>T10</td>\n",
       "      <td>2.89098</td>\n",
       "      <td>1717</td>\n",
       "      <td>circuit, chip, current, analog, voltage, vlsi, transistor, gate, pulse, threshold, design, implementation, synapse, bit, digital, device, analog vlsi, cmos, pp, line</td>\n",
       "      <td>Kirchoff Law Markov Fields for Analog \\nCircuit Design \\nRichard M. Golden * \\nRMG Consulting Inc. \\n2000 Fresno Road, Plano, Texas 75074 \\nRMG CONS UL T@A OL. COM, \\nwww. neural-network. corn \\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic11</th>\n",
       "      <td>T11</td>\n",
       "      <td>6.17181</td>\n",
       "      <td>994</td>\n",
       "      <td>spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, change, timing, probability, correlation, temporal, distribution</td>\n",
       "      <td>Information through a Spiking Neuron \\nCharles F. Stevens and Anthony Zador \\nSalk Institute MNL/S \\nLa Jolla, CA 92037 \\nzador@salk.edu \\nAbstract \\nWhile it is generally agreed that neurons tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic12</th>\n",
       "      <td>T12</td>\n",
       "      <td>6.07346</td>\n",
       "      <td>906</td>\n",
       "      <td>rule, learning rule, knowledge, category, condition, domain, symbolic, fuzzy, change, extraction, class, table, step, interval, expert, learn, language, activation, trained, learned</td>\n",
       "      <td>Extracting Rules from Artificial Neural Networks \\nwith Distributed Representations \\nSebastian Thrun \\nUniversity of Bonn \\nDepartment of Computer Science III \\nR6merstr. 164, D-53117 Bonn, Germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic13</th>\n",
       "      <td>T13</td>\n",
       "      <td>3.58858</td>\n",
       "      <td>1632</td>\n",
       "      <td>node, tree, decision, level, graph, structure, decision tree, leaf, path, layer, variable, field, parent, routing, split, child, propagation, architecture, activation, probability</td>\n",
       "      <td>Boosting with Multi-Way Branching in \\nDecision Trees \\nYishay Mansour \\nDavid McAllester \\nAT&amp;T Labs-Research \\n180 Park Ave \\nFlorham Park NJ 07932 \\n{mansour, dmac}@research.att.com \\nAbstract ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic14</th>\n",
       "      <td>T14</td>\n",
       "      <td>4.06160</td>\n",
       "      <td>217</td>\n",
       "      <td>feature, map, task, search, classification, experiment, representation, part, target, feature map, attention, orientation, feature vector, location, feature space, dimensional, region, cluster, ke...</td>\n",
       "      <td>266 Zemel, Mozer and Hinton \\nTRAFFIC: Recognizing Objects Using \\nHierarchical Reference Frame Transformations \\nRichard S. Zemel \\nComputer Science Dept. \\nUniversity of Toronto \\nToronto, ONT M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic15</th>\n",
       "      <td>T15</td>\n",
       "      <td>5.20976</td>\n",
       "      <td>205</td>\n",
       "      <td>classifier, class, classification, decision, rbf, region, rate, test, error rate, center, nearest, neighbor, nearest neighbor, training set, boundary, layer, gaussian, trained, sample, mixture</td>\n",
       "      <td>168 Lee and Lippmann \\nPractical Characteristics of Neural Network \\nand Conventional Pattern Classifiers on \\nArtificial and Speech Problems* \\nYuchun Lee \\nDigital Equipment Corp. \\n40 Old Bolto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic16</th>\n",
       "      <td>T16</td>\n",
       "      <td>2.77950</td>\n",
       "      <td>1054</td>\n",
       "      <td>distribution, gaussian, probability, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, conditional, structure, ma...</td>\n",
       "      <td>Discovering Structure in Continuous \\nVariables Using Bayesian Networks \\nReimar Hofmann and Volker Tresp* \\nSiemens AG, Central Research \\nOtto-Hahn-Ring 6 \\n81730 Mfinchen, Germany \\nAbstract \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic17</th>\n",
       "      <td>T17</td>\n",
       "      <td>3.35637</td>\n",
       "      <td>618</td>\n",
       "      <td>field, visual, motion, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, center, location, target</td>\n",
       "      <td>Filter Selection Model for Generating \\nVisual Motion Signals \\nSteven J. Nowlan* \\nCNL, The Salk Institute \\nP.O. Box 85800, San Diego, CA \\n92186-5800 \\nTerrence J. Sejnowski \\nCNL, The Salk Ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic18</th>\n",
       "      <td>T18</td>\n",
       "      <td>5.52967</td>\n",
       "      <td>484</td>\n",
       "      <td>object, view, recognition, representation, layer, visual, 3d, 2d, part, human, transformation, object recognition, position, scheme, image, aspect, frame, shape, rotation, viewpoint</td>\n",
       "      <td>Linear Operator for Object Recognition \\nPonen Basil Shimon Ullman* \\nM.I.T. Artificial Intelligence Laboratory \\nand Department of Brain and Cognitive Science \\n545 Technology Square \\nCambridge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic19</th>\n",
       "      <td>T19</td>\n",
       "      <td>6.13310</td>\n",
       "      <td>75</td>\n",
       "      <td>memory, representation, structure, capacity, sequence, associative, role, distributed, associative memory, activity, matrix, bit, stored, product, binding, connection, code, activation, local, symbol</td>\n",
       "      <td>73O \\nAnalysis of distributed representation of \\nconstituent structure in connectionist systems \\nPaul Smolensky \\nDepartment of Computer Science, University of Colorado, Boulder, CO 80309-0430 \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic20</th>\n",
       "      <td>T20</td>\n",
       "      <td>2.52369</td>\n",
       "      <td>63</td>\n",
       "      <td>equation, gradient, solution, matrix, optimal, generalization, rate, local, minimum, distance, line, convergence, noise, optimization, training set, average, constraint, descent, cost, test</td>\n",
       "      <td>612 \\nConstrained Differential Optimization \\nJohn C. Platt \\nAlan H. Ban' \\nCalifornia Institute of Technology, Pasadena, CA 91125 \\nAbstract \\nMany optimization models of neural networks need co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topic  Max Score  Paper Num  \\\n",
       "Topic1              T1    1.98178       1154   \n",
       "Topic2              T2    3.58244        323   \n",
       "Topic3              T3    5.88608       1279   \n",
       "Topic4              T4    3.91592       1714   \n",
       "Topic5              T5    2.99090        734   \n",
       "Topic6              T6    7.47698         34   \n",
       "Topic7              T7    4.91490       1301   \n",
       "Topic8              T8    3.78582        213   \n",
       "Topic9              T9    4.86516        971   \n",
       "Topic10            T10    2.89098       1717   \n",
       "Topic11            T11    6.17181        994   \n",
       "Topic12            T12    6.07346        906   \n",
       "Topic13            T13    3.58858       1632   \n",
       "Topic14            T14    4.06160        217   \n",
       "Topic15            T15    5.20976        205   \n",
       "Topic16            T16    2.77950       1054   \n",
       "Topic17            T17    3.35637        618   \n",
       "Topic18            T18    5.52967        484   \n",
       "Topic19            T19    6.13310         75   \n",
       "Topic20            T20    2.52369         63   \n",
       "\n",
       "                                                                                                                                                                                                           Topic  \\\n",
       "Topic1                          bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension   \n",
       "Topic2                  neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, state, equation, et, et al, activation, fig   \n",
       "Topic3   state, action, policy, step, reinforcement, optimal, reinforcement learning, transition, probability, reward, value function, dynamic, markov, machine, task, agent, finite, iteration, sequence, de...   \n",
       "Topic4                                      image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database   \n",
       "Topic5   hidden, layer, net, hidden unit, task, hidden layer, architecture, back, trained, propagation, connection, back propagation, activation, representation, output unit, neural net, internal, generali...   \n",
       "Topic6                                       cell, firing, head, response, direction, rat, layer, cortex, activity, ii, spatial, synaptic, inhibitory, synapsis, simulation, cue, region, property, complex, lot   \n",
       "Topic7              word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state   \n",
       "Topic8                                 signal, noise, source, filter, frequency, component, speech, channel, sound, independent, separation, ica, phase, auditory, matrix, eeg, blind, delay, acoustic, spectrum   \n",
       "Topic9                           control, controller, trajectory, motor, movement, task, dynamic, forward, feedback, arm, inverse, position, robot, architecture, hand, force, target, change, command, adaptive   \n",
       "Topic10                                    circuit, chip, current, analog, voltage, vlsi, transistor, gate, pulse, threshold, design, implementation, synapse, bit, digital, device, analog vlsi, cmos, pp, line   \n",
       "Topic11         spike, rate, firing, stimulus, train, spike train, firing rate, response, frequency, neuron, potential, current, fig, synaptic, change, timing, probability, correlation, temporal, distribution   \n",
       "Topic12                    rule, learning rule, knowledge, category, condition, domain, symbolic, fuzzy, change, extraction, class, table, step, interval, expert, learn, language, activation, trained, learned   \n",
       "Topic13                      node, tree, decision, level, graph, structure, decision tree, leaf, path, layer, variable, field, parent, routing, split, child, propagation, architecture, activation, probability   \n",
       "Topic14  feature, map, task, search, classification, experiment, representation, part, target, feature map, attention, orientation, feature vector, location, feature space, dimensional, region, cluster, ke...   \n",
       "Topic15         classifier, class, classification, decision, rbf, region, rate, test, error rate, center, nearest, neighbor, nearest neighbor, training set, boundary, layer, gaussian, trained, sample, mixture   \n",
       "Topic16  distribution, gaussian, probability, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, conditional, structure, ma...   \n",
       "Topic17               field, visual, motion, stimulus, response, direction, orientation, eye, receptive, receptive field, cortex, map, cortical, velocity, spatial, activity, position, center, location, target   \n",
       "Topic18                    object, view, recognition, representation, layer, visual, 3d, 2d, part, human, transformation, object recognition, position, scheme, image, aspect, frame, shape, rotation, viewpoint   \n",
       "Topic19  memory, representation, structure, capacity, sequence, associative, role, distributed, associative memory, activity, matrix, bit, stored, product, binding, connection, code, activation, local, symbol   \n",
       "Topic20            equation, gradient, solution, matrix, optimal, generalization, rate, local, minimum, distance, line, convergence, noise, optimization, training set, average, constraint, descent, cost, test   \n",
       "\n",
       "                                                                                                                                                                                                      Paper Name  \n",
       "Topic1   For valid generalization, the size of the \\nweights is more important than the size \\nof the network \\nPeter L. Bartlett \\nDepartment of Systems Engineering \\nResearch School of Information Scienc...  \n",
       "Topic2   Signal Processing by Multiplexing and \\nDemultiplexing in Neurons \\nDavid C. Tam \\nDivision of Neuroscience \\nBaylor College of Medicine \\nHouston, TX 77030 \\ndtamCnext-cns.neusc.bcm.tmc.edu \\nAb...  \n",
       "Topic3   Reinforcement Learning for Mixed \\nOpen-loop and Closed-loop Control \\nEric A. Hansen, Andrew G. Barto, and Shlomo Zilbersteln \\nDepartment of Computer Science \\nUniversity of Massachusetts \\nAmhe...  \n",
       "Topic4   Image representations for facial expression \\ncoding \\nMarian Stewart Bartlett* \\nU.C. San Diego \\nmarnisalk. edu \\nJavier R. Movellan \\nU.C. San Diego \\nmovellancogsc. ucsd. edu \\nPaul Ekman \\n...  \n",
       "Topic5   Generation of Internal Representation \\nby c-Transformation \\nRyotaro Kamimura \\nInformation Science Laboratory \\nTokai University \\n1117 Kitakaname Hiratsuka Kanagawa 259-12, Japan \\nAbstract \\nI...  \n",
       "Topic6   317 \\nPARTITIONING OF SENSORY DATA BY A COPTICAI, NETWOPK  \\nRichard Granger, Jos Ambros-Ingerson, Howard Henry, Gary Lynch \\nCenter for the Neurobiology of Learning and Memory \\nUniversity of...  \n",
       "Topic7   Comparison of Human and Machine Word \\nRecognition \\nM. Schenkel \\nDept of Electrical Eng. \\nUniversity of Sydney \\nSydney, NSW 2006, Australia \\nschenkel@sedal.usyd.edu.au \\nC. Latimer \\nDept of ...  \n",
       "Topic8   232 Sejnowski, Yuhas, Goldstein and Jenkins \\nCombining Visual and \\nwith a Neural Network \\nAcoustic Speech Signals \\nImproves Intelligibility \\nT.J. Sejnowski \\nThe Salk Institute \\nand \\nDepart...  \n",
       "Topic9   An Integrated Architecture of Adaptive Neural Network \\nControl for Dynamic Systems \\nLiu Ke '2 Robert L. Tokaf Brian D.McVey z \\nCenter for Nonlinear Studies, 2Applied Theoretical Physics Divis...  \n",
       "Topic10  Kirchoff Law Markov Fields for Analog \\nCircuit Design \\nRichard M. Golden * \\nRMG Consulting Inc. \\n2000 Fresno Road, Plano, Texas 75074 \\nRMG CONS UL T@A OL. COM, \\nwww. neural-network. corn \\nA...  \n",
       "Topic11  Information through a Spiking Neuron \\nCharles F. Stevens and Anthony Zador \\nSalk Institute MNL/S \\nLa Jolla, CA 92037 \\nzador@salk.edu \\nAbstract \\nWhile it is generally agreed that neurons tran...  \n",
       "Topic12  Extracting Rules from Artificial Neural Networks \\nwith Distributed Representations \\nSebastian Thrun \\nUniversity of Bonn \\nDepartment of Computer Science III \\nR6merstr. 164, D-53117 Bonn, Germa...  \n",
       "Topic13  Boosting with Multi-Way Branching in \\nDecision Trees \\nYishay Mansour \\nDavid McAllester \\nAT&T Labs-Research \\n180 Park Ave \\nFlorham Park NJ 07932 \\n{mansour, dmac}@research.att.com \\nAbstract ...  \n",
       "Topic14  266 Zemel, Mozer and Hinton \\nTRAFFIC: Recognizing Objects Using \\nHierarchical Reference Frame Transformations \\nRichard S. Zemel \\nComputer Science Dept. \\nUniversity of Toronto \\nToronto, ONT M...  \n",
       "Topic15  168 Lee and Lippmann \\nPractical Characteristics of Neural Network \\nand Conventional Pattern Classifiers on \\nArtificial and Speech Problems* \\nYuchun Lee \\nDigital Equipment Corp. \\n40 Old Bolto...  \n",
       "Topic16  Discovering Structure in Continuous \\nVariables Using Bayesian Networks \\nReimar Hofmann and Volker Tresp* \\nSiemens AG, Central Research \\nOtto-Hahn-Ring 6 \\n81730 Mfinchen, Germany \\nAbstract \\n...  \n",
       "Topic17  Filter Selection Model for Generating \\nVisual Motion Signals \\nSteven J. Nowlan* \\nCNL, The Salk Institute \\nP.O. Box 85800, San Diego, CA \\n92186-5800 \\nTerrence J. Sejnowski \\nCNL, The Salk Ins...  \n",
       "Topic18  Linear Operator for Object Recognition \\nPonen Basil Shimon Ullman* \\nM.I.T. Artificial Intelligence Laboratory \\nand Department of Brain and Cognitive Science \\n545 Technology Square \\nCambridge...  \n",
       "Topic19  73O \\nAnalysis of distributed representation of \\nconstituent structure in connectionist systems \\nPaul Smolensky \\nDepartment of Computer Science, University of Colorado, Boulder, CO 80309-0430 \\...  \n",
       "Topic20  612 \\nConstrained Differential Optimization \\nJohn C. Platt \\nAlan H. Ban' \\nCalifornia Institute of Technology, Pasadena, CA 91125 \\nAbstract \\nMany optimization models of neural networks need co...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine most relevant paper for each topic based on topic dominance scores\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "max_score_topics = dt_df.max(axis=0)\n",
    "dominant_topics = max_score_topics.index\n",
    "term_score = max_score_topics.values\n",
    "document_numbers = [dt_df[dt_df[t] == max_score_topics.loc[t]].index[0]\n",
    "                        for t in dominant_topics]\n",
    "documents = [papers[i] for i in document_numbers]\n",
    "results_df = pd.DataFrame({'Dominant Topic': dominant_topics, 'Max Score': term_score,\n",
    "                            'Paper Num': document_numbers, 'Topic': topics_df['Terms per Topic'],\n",
    "                            'Paper Name': documents})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total New Papers: 4\n"
     ]
    }
   ],
   "source": [
    "## Predicting Topics for New Research Papers\n",
    "import glob\n",
    "# papers manually downloaded from NIPS 16\n",
    "# https://papers.nips.cc/book/advances-in-neural-information-processing-systems-29-2016\n",
    "\n",
    "new_paper_files = glob.glob('test_data/nips16*.txt')\n",
    "new_papers = []\n",
    "for fn in new_paper_files:\n",
    "    with open(fn, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "        data = f.read()\n",
    "        new_papers.append(data)\n",
    "\n",
    "print('Total New Papers:', len(new_papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 14408)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess documents and extract features\n",
    "norm_new_papers = normalize_corpus(new_papers)\n",
    "cv_new_features = cv.transform(norm_new_papers)\n",
    "cv_new_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1.28), (15, 0.799)],\n",
       " [(2, 4.186), (0, 1.043)],\n",
       " [(3, 2.125), (1, 1.341)],\n",
       " [(3, 3.06), (6, 2.181)]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use NMF topic model to predict topics for new research papers \n",
    "topic_predictions = nmf_model.transform(cv_new_features)\n",
    "best_topics = [[(topic, round(sc, 3))\n",
    "                   for topic, sc in sorted(enumerate(topic_predictions[i]), \n",
    "                                           key=lambda row: -row[1])[:2]]\n",
    "                      for i in range(len(topic_predictions))]\n",
    "best_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant Topics</th>\n",
       "      <th>Topic Score</th>\n",
       "      <th>Topic Desc</th>\n",
       "      <th>Paper Desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Papers</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>128.00000</td>\n",
       "      <td>bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>79.90000</td>\n",
       "      <td>distribution, gaussian, probability, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, conditional, structure, ma...</td>\n",
       "      <td>Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>418.60000</td>\n",
       "      <td>state, action, policy, step, reinforcement, optimal, reinforcement learning, transition, probability, reward, value function, dynamic, markov, machine, task, agent, finite, iteration, sequence, de...</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>104.30000</td>\n",
       "      <td>bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension</td>\n",
       "      <td>PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>212.50000</td>\n",
       "      <td>image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>134.10000</td>\n",
       "      <td>neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, state, equation, et, et al, activation, fig</td>\n",
       "      <td>Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>306.00000</td>\n",
       "      <td>image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>218.10000</td>\n",
       "      <td>word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state</td>\n",
       "      <td>Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dominant Topics  Topic Score  \\\n",
       "Papers                                 \n",
       "1                     1    128.00000   \n",
       "1                    16     79.90000   \n",
       "2                     3    418.60000   \n",
       "2                     1    104.30000   \n",
       "3                     4    212.50000   \n",
       "3                     2    134.10000   \n",
       "4                     4    306.00000   \n",
       "4                     7    218.10000   \n",
       "\n",
       "                                                                                                                                                                                                     Topic Desc  \\\n",
       "Papers                                                                                                                                                                                                            \n",
       "1                              bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension   \n",
       "1       distribution, gaussian, probability, mixture, variable, density, likelihood, prior, bayesian, component, posterior, em, log, estimate, sample, approximation, estimation, conditional, structure, ma...   \n",
       "2       state, action, policy, step, reinforcement, optimal, reinforcement learning, transition, probability, reward, value function, dynamic, markov, machine, task, agent, finite, iteration, sequence, de...   \n",
       "2                              bound, class, threshold, theorem, let, probability, size, dimension, vc, sample, polynomial, distribution, proof, net, complexity, approximation, theory, loss, xi, vc dimension   \n",
       "3                                          image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database   \n",
       "3                      neuron, synaptic, connection, potential, dynamic, activity, synapsis, excitatory, layer, simulation, synapse, inhibitory, delay, biological, state, equation, et, et al, activation, fig   \n",
       "4                                          image, face, pixel, recognition, local, scale, texture, digit, distance, filter, scene, vision, edge, facial, pca, representation, region, visual, surface, database   \n",
       "4                  word, recognition, speech, context, hmm, speaker, speech recognition, character, phoneme, probability, frame, sequence, rate, level, test, acoustic, experiment, letter, segmentation, state   \n",
       "\n",
       "                                                                                                                                                                                                     Paper Desc  \n",
       "Papers                                                                                                                                                                                                           \n",
       "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...  \n",
       "1       Cooperative Graphical Models\\nJosip Djolonga\\nDept. of Computer Science, ETH Zurich \\njosipd@inf.ethz.ch\\nStefanie Jegelka\\nCSAIL, MIT\\nstefje@mit.edu\\nSebastian Tschiatschek\\nDept. of Computer S...  \n",
       "2       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...  \n",
       "2       PAC Reinforcement Learning with Rich Observations\\nAkshay Krishnamurthy\\nUniversity of Massachusetts, Amherst\\nAmherst, MA, 01003\\nakshay@cs.umass.edu\\nAlekh Agarwal\\nMicrosoft Research\\nNew York,...  \n",
       "3       Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...  \n",
       "3       Automated scalable segmentation of neurons from\\nmultispectral images\\nUygar Smbl\\nGrossman Center for the Statistics of Mind\\nand Dept. of Statistics, Columbia University\\nDouglas Roossien Jr.\\...  \n",
       "4       Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...  \n",
       "4       Unsupervised Learning of Spoken Language with\\nVisual Context\\nDavid Harwath, Antonio Torralba, and James R. Glass\\nComputer Science and Artificial Intelligence Laboratory\\nMassachusetts Institute...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view results\n",
    "results_df = pd.DataFrame()\n",
    "results_df['Papers'] = range(1, len(new_papers)+1)\n",
    "results_df['Dominant Topics'] = [[topic_num+1 for topic_num, sc in item]\n",
    "                                    for item in best_topics]\n",
    "res = results_df.set_index(['Papers'])['Dominant Topics'].apply(pd.Series).stack().reset_index(level=1, drop=True)\n",
    "results_df = pd.DataFrame({'Dominant Topics': res.values}, index=res.index)\n",
    "results_df['Topic Score'] = [topic_sc for topic_list in [[round(sc*100, 2)\n",
    "                                                             for topic_num, sc in item]\n",
    "                                                                for item in best_topics]\n",
    "                                         for topic_sc in topic_list]\n",
    "results_df['Topic Desc'] = [topics_df.iloc[t-1]['Terms per Topic']\n",
    "                           for t in results_df['Dominant Topics'].values]\n",
    "results_df['Paper Desc'] = [new_papers[i-1][:200] for i in results_df.index.values]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing Topic Models\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.sklearn\n",
    "#import dill\n",
    "#import warnings\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "#pyLDAvis.enable_notebook()\n",
    "\n",
    "#pyLDAvis.sklearn.prepare(nmf_model, cv_features, cv, mds='mmds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT = \"\"\"\n",
    "The Elder Scrolls V: Skyrim is an action role-playing video game developed by Bethesda Game Studios \n",
    "and published by Bethesda Softworks. It is the fifth main installment in The Elder Scrolls series, \n",
    "following The Elder Scrolls IV: Oblivion.\n",
    "The game's main story revolves around the player character's quest to defeat Alduin the World-Eater, \n",
    "a dragon who is prophesied to destroy the world. The game is set 200 years after the events of Oblivion \n",
    "and takes place in the fictional province of Skyrim. Over the course of the game, the player completes \n",
    "quests and develops the character by improving skills. The game continues the open-world tradition of \n",
    "its predecessors by allowing the player to travel anywhere in the game world at any time, and to ignore \n",
    "or postpone the main storyline indefinitely.\n",
    "The team opted for a unique and more diverse open world than Oblivion's Imperial Province of Cyrodiil, \n",
    "which game director and executive producer Todd Howard considered less interesting by comparison. \n",
    "The game was released to critical acclaim, with reviewers particularly mentioning the character advancement \n",
    "and setting, and is considered to be one of the greatest video games of all time.\n",
    "\n",
    "The Elder Scrolls V: Skyrim is an action role-playing game, playable from either a first or \n",
    "third-person perspective. The player may freely roam over the land of Skyrim which is an open world \n",
    "environment consisting of wilderness expanses, dungeons, cities, towns, fortresses, and villages. \n",
    "Players may navigate the game world more quickly by riding horses or by utilizing a fast-travel system \n",
    "which allows them to warp to previously discovered locations. The game's main quest can be completed or \n",
    "ignored at the player's preference after the first stage of the quest is finished. However, some quests \n",
    "rely on the main storyline being at least partially completed. Non-player characters (NPCs) populate the \n",
    "world and can be interacted with in a number of ways: the player may engage them in conversation, \n",
    "marry an eligible NPC, kill them or engage in a nonlethal \"brawl\". The player may \n",
    "choose to join factions which are organized groups of NPCs  for example, the Dark Brotherhood, a band \n",
    "of assassins. Each of the factions has an associated quest path to progress through. Each city and town \n",
    "in the game world has jobs that the player can engage in, such as farming.\n",
    "\n",
    "Players have the option to develop their character. At the beginning of the game, players create \n",
    "their character by selecting their sex and choosing between one of several races including humans, \n",
    "orcs, elves, and anthropomorphic cat or lizard-like creatures and then customizing their character's \n",
    "appearance. Over the course of the game, players improve their character's skills which are numerical \n",
    "representations of their ability in certain areas. There are eighteen skills divided evenly among the \n",
    "three schools of combat, magic, and stealth. When players have trained skills enough to meet the \n",
    "required experience, their character levels up. Health is depleted primarily when the player \n",
    "takes damage and the loss of all health results in death. Magicka is depleted by the use of spells, \n",
    "certain poisons and by being struck by lightning-based attacks. Stamina determines the player's \n",
    "effectiveness in combat and is depleted by sprinting, performing heavy \"power attacks\" \n",
    "and being struck by frost-based attacks. Skyrim is the first entry in The Elder Scrolls to \n",
    "include dragons in the game's wilderness. Like other creatures, dragons are generated randomly in \n",
    "the world and will engage in combat with NPCs, creatures and the player. Some dragons may attack \n",
    "cities and towns when in their proximity. The player character can absorb the souls of dragons \n",
    "in order to use powerful spells called \"dragon shouts\" or \"Thu'um\". A regeneration \n",
    "period limits the player's use of shouts in gameplay.\n",
    "\n",
    "Skyrim is set around 200 years after the events of The Elder Scrolls IV: Oblivion, although it is \n",
    "not a direct sequel. The game takes place in Skyrim, a province of the Empire on the continent of \n",
    "Tamriel, amid a civil war between two factions: the Stormcloaks, led by Ulfric Stormcloak, and the \n",
    "Imperial Legion, led by General Tullius. The player character is a Dragonborn, a mortal born with \n",
    "the soul and power of a dragon. Alduin, a large black dragon who returns to the land after being \n",
    "lost in time, serves as the game's primary antagonist. Alduin is the first dragon created by Akatosh, \n",
    "one of the series' gods, and is prophesied to destroy and consume the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "import re\n",
    "\n",
    "DOCUMENT = re.sub(r'\\n|\\r', ' ', DOCUMENT)\n",
    "DOCUMENT = re.sub(r' +', ' ', DOCUMENT)\n",
    "DOCUMENT = DOCUMENT.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The game's main story revolves around the player character's quest to defeat Alduin the World-Eater, a dragon who is prophesied to destroy the world.\n",
      "Over the course of the game, the player completes quests and develops the character by improving skills.\n",
      "The game continues the open-world tradition of its predecessors by allowing the player to travel anywhere in the game world at any time, and to ignore or postpone the main storyline indefinitely.\n",
      "The player may freely roam over the land of Skyrim which is an open world environment consisting of wilderness expanses, dungeons, cities, towns, fortresses, and villages.\n",
      "Each city and town in the game world has jobs that the player can engage in, such as farming.\n",
      "Over the course of the game, players improve their character's skills which are numerical representations of their ability in certain areas.\n",
      "Like other creatures, dragons are generated randomly in the world and will engage in combat with NPCs, creatures and the player.\n"
     ]
    }
   ],
   "source": [
    "# implement document summarization using Gensim's summarization module\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "print(summarize(DOCUMENT, ratio=0.2, split=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The game's main story revolves around the player character's quest to defeat Alduin the World-Eater, a dragon who is prophesied to destroy the world.\n",
      "Over the course of the game, the player completes quests and develops the character by improving skills.\n",
      "The player may freely roam over the land of Skyrim which is an open world environment consisting of wilderness expanses, dungeons, cities, towns, fortresses, and villages.\n"
     ]
    }
   ],
   "source": [
    "# limit summarization based on word count instead of proportions\n",
    "print(summarize(DOCUMENT, word_count=75, split=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elder',\n",
       "  'scroll',\n",
       "  'skyrim',\n",
       "  'action',\n",
       "  'role',\n",
       "  'playing',\n",
       "  'video',\n",
       "  'game',\n",
       "  'developed',\n",
       "  'bethesda',\n",
       "  'game',\n",
       "  'studio',\n",
       "  'published',\n",
       "  'bethesda',\n",
       "  'softworks'],\n",
       " ['fifth',\n",
       "  'main',\n",
       "  'installment',\n",
       "  'elder',\n",
       "  'scroll',\n",
       "  'series',\n",
       "  'following',\n",
       "  'elder',\n",
       "  'scroll',\n",
       "  'iv',\n",
       "  'oblivion'],\n",
       " ['game',\n",
       "  'main',\n",
       "  'story',\n",
       "  'revolves',\n",
       "  'around',\n",
       "  'player',\n",
       "  'character',\n",
       "  'quest',\n",
       "  'defeat',\n",
       "  'alduin',\n",
       "  'world',\n",
       "  'eater',\n",
       "  'dragon',\n",
       "  'prophesied',\n",
       "  'destroy',\n",
       "  'world']]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Text Wrangling\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalized_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "# get sentences in the document\n",
    "sentences = nltk.sent_tokenize(DOCUMENT)\n",
    "\n",
    "# normalize each sentence in the document\n",
    "norm_sentences = normalize_corpus(sentences)\n",
    "norm_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-d4c9464eeb80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdt_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdt_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \"\"\"\n\u001b[1;32m   1612\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1031\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                                tokenize)\n\u001b[1;32m    328\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 329\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "## Text Representation with Feature Engineering\n",
    "# vectorize normalized sentences using TF-IDF feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "dt_matrix = tv.fit_transform(norm_sentences)\n",
    "dt_matrix = dt_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "td_matrix = dt_matrix.T\n",
    "print(td_matrix.shape)\n",
    "pd.DataFrame(np.round(td_matrix,2), index=vocab).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7756, 3) (3,) (3, 1740)\n"
     ]
    }
   ],
   "source": [
    "## Latent Semantic Analysis\n",
    "# select number of sentences n that summary will contain\n",
    "# perform low-rank SVD\n",
    "num_sentences = 8\n",
    "num_topics = 3\n",
    "\n",
    "u, s, vt = low_rank_svd(td_matrix, singular_count=num_topics)\n",
    "print(u.shape, s.shape, vt.shape)\n",
    "term_topic_mat, singular_values, topic_document_mat = u, s, vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remore singular values below threshold\n",
    "sv_threshold = 0.5\n",
    "min_sigma_value = max(singular_values) * sv_threshold\n",
    "singular_values[singular_values < min_sigma_value] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.171356, 53.64662 , 26.859047, ..., 37.340725, 29.907743,\n",
       "       40.36577 ], dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute sentence sailency scores for each sentence (document) in game description\n",
    "salience_scores = np.sqrt(np.dot(np.square(singular_values), \n",
    "                                 np.square(topic_document_mat)))\n",
    "salience_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 187 is out of bounds for axis 0 with size 35",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-34a9cc1e2a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtop_sentence_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msalience_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_sentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_sentence_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_sentence_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 187 is out of bounds for axis 0 with size 35"
     ]
    }
   ],
   "source": [
    "# select top sentences based on saliency score\n",
    "# display summary of game description\n",
    "top_sentence_indices = (-salience_scores).argsort()[:num_sentences]\n",
    "top_sentence_indices.sort()\n",
    "print('\\n'.join(np.array(sentences)[top_sentence_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-d5dd922c5717>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# reuse document-term feature matrix from LSA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# compute document similarity matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msimilarity_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "## TextRank\n",
    "# reuse document-term feature matrix from LSA\n",
    "# compute document similarity matrix\n",
    "similarity_matrix = np.matmul(dt_matrix, dt_matrix.T)\n",
    "print(similarity_matrix.shape)\n",
    "np.round(similarity_matrix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot connected graph among all sentences from document\n",
    "import networkx\n",
    "# build similarity graph\n",
    "similarity_graph = networkx.from_numpy_array(similarity_matrix)\n",
    "similarity_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the similarity graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "networkx.draw_networkx(similarity_graph, node_color='lime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pagerank scores for all the sentences\n",
    "scores = networkx.pagerank(similarity_graph)\n",
    "ranked_sentences = sorted(((score, index) for index, score in scores.items()), reverse=True)\n",
    "ranked_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top sentence indices for our summary\n",
    "top_sentence_indices = [ranked_sentences[index][1]\n",
    "                           for index in range(num_sentences)]\n",
    "top_sentence_indices.sort()\n",
    "\n",
    "# construct the document summary\n",
    "print('\\n'.join(np.array(sentences)[top_sentence_indices]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
