{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit88832310db0f46c6ba1b97f6fce48e8e",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Model\n",
    "I will review the following topics:\n",
    "* The Algebra of the OLS Estimator\n",
    "* The Finite Sampling Properties of the OLS Estimator\n",
    "* Asymptotic Properties of the OLS Estimator\n",
    "* Regression Intervals\n",
    "* Forecast Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "import patsy\n",
    "\n",
    "# download dataset to use throughout\n",
    "hprice2 = pd.read_stata('http://fmwww.bc.edu/ec-p/data/wooldridge/hprice2.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table class=\"simpletable\">\n<tr>\n        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>     <td>0.763</td>  \n</tr>\n<tr>\n  <td>Dependent Variable:</td>      <td>lprice</td>             <td>AIC:</td>         <td>-188.7488</td>\n</tr>\n<tr>\n         <td>Date:</td>        <td>2020-03-08 19:20</td>        <td>BIC:</td>         <td>-150.7100</td>\n</tr>\n<tr>\n   <td>No. Observations:</td>         <td>506</td>         <td>Log-Likelihood:</td>    <td>103.37</td>  \n</tr>\n<tr>\n       <td>Df Model:</td>              <td>8</td>           <td>F-statistic:</td>       <td>204.8</td>  \n</tr>\n<tr>\n     <td>Df Residuals:</td>           <td>497</td>       <td>Prob (F-statistic):</td> <td>5.77e-152</td>\n</tr>\n<tr>\n      <td>R-squared:</td>            <td>0.767</td>            <td>Scale:</td>        <td>0.039616</td> \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n      <td></td>       <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n</tr>\n<tr>\n  <th>Intercept</th> <td>12.6516</td>  <td>0.3473</td>   <td>36.4288</td> <td>0.0000</td> <td>11.9693</td> <td>13.3340</td>\n</tr>\n<tr>\n  <th>lnox</th>      <td>-0.4503</td>  <td>0.0920</td>   <td>-4.8937</td> <td>0.0000</td> <td>-0.6311</td> <td>-0.2695</td>\n</tr>\n<tr>\n  <th>lproptax</th>  <td>-0.2274</td>  <td>0.0477</td>   <td>-4.7634</td> <td>0.0000</td> <td>-0.3212</td> <td>-0.1336</td>\n</tr>\n<tr>\n  <th>crime</th>     <td>-0.0113</td>  <td>0.0014</td>   <td>-8.2754</td> <td>0.0000</td> <td>-0.0139</td> <td>-0.0086</td>\n</tr>\n<tr>\n  <th>rooms</th>     <td>0.0990</td>   <td>0.0168</td>   <td>5.9008</td>  <td>0.0000</td> <td>0.0660</td>  <td>0.1320</td> \n</tr>\n<tr>\n  <th>dist</th>      <td>-0.0488</td>  <td>0.0073</td>   <td>-6.6939</td> <td>0.0000</td> <td>-0.0631</td> <td>-0.0345</td>\n</tr>\n<tr>\n  <th>radial</th>    <td>0.0115</td>   <td>0.0023</td>   <td>5.0277</td>  <td>0.0000</td> <td>0.0070</td>  <td>0.0160</td> \n</tr>\n<tr>\n  <th>stratio</th>   <td>-0.0404</td>  <td>0.0050</td>   <td>-8.1325</td> <td>0.0000</td> <td>-0.0502</td> <td>-0.0307</td>\n</tr>\n<tr>\n  <th>lowstat</th>   <td>-0.0283</td>  <td>0.0019</td>  <td>-14.7579</td> <td>0.0000</td> <td>-0.0320</td> <td>-0.0245</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n     <td>Omnibus:</td>    <td>60.676</td>  <td>Durbin-Watson:</td>    <td>1.047</td> \n</tr>\n<tr>\n  <td>Prob(Omnibus):</td>  <td>0.000</td> <td>Jarque-Bera (JB):</td> <td>204.257</td>\n</tr>\n<tr>\n       <td>Skew:</td>      <td>0.517</td>     <td>Prob(JB):</td>      <td>0.000</td> \n</tr>\n<tr>\n     <td>Kurtosis:</td>    <td>5.936</td>  <td>Condition No.:</td>    <td>1090</td>  \n</tr>\n</table>",
      "text/plain": "<class 'statsmodels.iolib.summary2.Summary'>\n\"\"\"\n                 Results: Ordinary least squares\n==================================================================\nModel:              OLS              Adj. R-squared:     0.763    \nDependent Variable: lprice           AIC:                -188.7488\nDate:               2020-03-08 19:20 BIC:                -150.7100\nNo. Observations:   506              Log-Likelihood:     103.37   \nDf Model:           8                F-statistic:        204.8    \nDf Residuals:       497              Prob (F-statistic): 5.77e-152\nR-squared:          0.767            Scale:              0.039616 \n-------------------------------------------------------------------\n               Coef.   Std.Err.     t      P>|t|    [0.025   0.975]\n-------------------------------------------------------------------\nIntercept     12.6516    0.3473   36.4288  0.0000  11.9693  13.3340\nlnox          -0.4503    0.0920   -4.8937  0.0000  -0.6311  -0.2695\nlproptax      -0.2274    0.0477   -4.7634  0.0000  -0.3212  -0.1336\ncrime         -0.0113    0.0014   -8.2754  0.0000  -0.0139  -0.0086\nrooms          0.0990    0.0168    5.9008  0.0000   0.0660   0.1320\ndist          -0.0488    0.0073   -6.6939  0.0000  -0.0631  -0.0345\nradial         0.0115    0.0023    5.0277  0.0000   0.0070   0.0160\nstratio       -0.0404    0.0050   -8.1325  0.0000  -0.0502  -0.0307\nlowstat       -0.0283    0.0019  -14.7579  0.0000  -0.0320  -0.0245\n------------------------------------------------------------------\nOmnibus:              60.676       Durbin-Watson:          1.047  \nProb(Omnibus):        0.000        Jarque-Bera (JB):       204.257\nSkew:                 0.517        Prob(JB):               0.000  \nKurtosis:             5.936        Condition No.:          1090   \n==================================================================\n* The condition number is large (1e+03). This might indicate\nstrong multicollinearity or other numerical problems.\n\"\"\""
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view first six rows of the dataset\n",
    "hprice2.head()\n",
    "\n",
    "# view data information such as count, mean, max, etc\n",
    "hprice2.describe()\n",
    "\n",
    "# specify outcome variable (y) and regressors/predictors (x) using string\n",
    "f = 'lprice ~ lnox + lproptax + crime + rooms + dist + radial + stratio + lowstat'\n",
    "\n",
    "# select columns of the dataframe as an attribute (or using brackets) - creates panda series\n",
    "hprice2.crime\n",
    "hprice2['crime']\n",
    "\n",
    "# use double brackets to select columns as a dataframe\n",
    "hprice2[['crime', 'lnox']]\n",
    "\n",
    "# create a design matrix using patsy package\n",
    "y, X = patsy.dmatrices(f, data=hprice2, return_type='dataframe')\n",
    "\n",
    "# calculate OLS, fit model to a regression, then use summary to view\n",
    "model = OLS(y,X)\n",
    "reg = model.fit()\n",
    "reg.summary()\n",
    "reg.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n      <th>y_hat</th>\n      <th>e_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.085810</td>\n      <td>10.303026</td>\n      <td>-0.217217</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9.980402</td>\n      <td>10.145426</td>\n      <td>-0.165024</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.454500</td>\n      <td>10.365117</td>\n      <td>0.089383</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.416310</td>\n      <td>10.330250</td>\n      <td>0.086060</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.496790</td>\n      <td>10.277121</td>\n      <td>0.219669</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           y      y_hat     e_hat\n0  10.085810  10.303026 -0.217217\n1   9.980402  10.145426 -0.165024\n2  10.454500  10.365117  0.089383\n3  10.416310  10.330250  0.086060\n4  10.496790  10.277121  0.219669"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary\n",
    "ols_var = {'y': hprice2.lprice, 'y_hat': reg.fittedvalues, 'e_hat': reg.resid}\n",
    "\n",
    "# print first six outcomes, fitted vales, and residuals\n",
    "ols_info = pd.DataFrame(ols_var)\n",
    "ols_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analysis of variance\n",
    "total sum of squares = explained sum of squares + residual sum of squares\n",
    "\n",
    "$\\sum_{i=1}^n (y_i - \\bar{y})^2 = \\sum_{i=1}^n (\\hat{y_i} + \\bar{y})^2 + \\sum_{i=1}^n \\hat{e_i}^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "19.689097978248622"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view OLS total sum of squares, explained sum of squares, and residual sum of squares (statsmodel site down)\n",
    "reg.ssr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coefficient of determination ($R^2$)\n",
    "\n",
    "$R^2 = \\frac{\\sum_{i=1}^n (\\hat{y_i} - \\bar{y})^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2} = 1 - \\frac{\\sum_{i=1}^n \\hat{e_i}^2}{\\sum_{i=1}^n (y_i - \\bar{y})^2}$\n",
    "\n",
    "* known as the square of sample correlation coefficient between the true and fitted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adjusted $R^2$\n",
    "\n",
    "$\\bar{R^2} = 1 - \\frac{n\\sum_{i=1}^n \\hat{e_i}^2}{(n-k-1)\\sum_{i=1}^n (y_i - \\bar{y})^2}$ \n",
    "\n",
    "* unlike $R^2$ which cannot decrease as k increases, $\\bar{R^2}$ can either increase or decrease with k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.767219563142833\n0.7634725943403031\n"
    }
   ],
   "source": [
    "# view R2\n",
    "print(reg.rsquared)\n",
    "\n",
    "# view adjusted R2\n",
    "print(reg.rsquared_adj) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leverage values\n",
    "* a measure of how far away the independent variable values of an observation are from those of the other observations\n",
    "* diagonal of hat matrix\n",
    "* hat matrix: the projection matrix that expresses the values of the observations in the independent variable, ùê≤, in terms of the linear combinations of the column vectors of the model matrix\n",
    "* This entry in the hat matrix will have a direct influence on the way entry $y_i$ will result in $\\hat{y_i}$( high-leverage of the ùëñ-th observation $y_i$ in determining its own prediction value $\\hat{y_i})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.00465546, 0.00745928, 0.01159636, 0.01147143, 0.01015461])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create instance of influence\n",
    "reg_influence = reg.get_influence()\n",
    "\n",
    "# get leverage values\n",
    "reg_influence.hat_matrix_diag[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction error (leave one out residual or prediction residual)\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}